{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists:True\n",
      "Before removing NaN value:  (5055, 5)\n",
      "After removing NaN value:  (5055, 5)\n",
      "   review_id                                             phrase  \\\n",
      "0          0     judging previous posts used good place longer    \n",
      "1          1    four arrived noon place empty staff acted like    \n",
      "2          1  four arrived noon place empty staff acted like...   \n",
      "3          1              empty staff acted like imposing rude    \n",
      "4          2        repeated requests sugar threw dishes table    \n",
      "\n",
      "             category aspect_term  polarity  \n",
      "0  RESTAURANT#GENERAL       posts  negative  \n",
      "1     SERVICE#GENERAL       staff  negative  \n",
      "2     SERVICE#GENERAL        rude  negative  \n",
      "3     SERVICE#GENERAL        rude  negative  \n",
      "4     SERVICE#GENERAL         eat  negative  \n",
      "FOOD#QUALITY                1709\n",
      "SERVICE#GENERAL              902\n",
      "AMBIENCE#GENERAL             581\n",
      "RESTAURANT#GENERAL           535\n",
      "FOOD#STYLE_OPTIONS           379\n",
      "DRINKS#QUALITY               191\n",
      "FOOD#PRICES                  178\n",
      "RESTAURANT#MISCELLANEOUS     177\n",
      "RESTAURANT#PRICES            147\n",
      "DRINKS#STYLE_OPTIONS         100\n",
      "LOCATION#GENERAL              96\n",
      "DRINKS#PRICES                 55\n",
      "FOOD#GENERAL                   5\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if file exists\n",
    "print (\"File exists:\"+str(path.exists(\"ABSACOMBINED.csv\")))\n",
    "\n",
    "# import text and remove those with null category\n",
    "input_data = pd.read_csv(\"ABSACOMBINED.csv\")\n",
    "print('Before removing NaN value: ', input_data.shape)\n",
    "input_data = input_data.dropna(subset=['category'])\n",
    "print('After removing NaN value: ', input_data.shape)\n",
    "print(input_data.head(5))\n",
    "\n",
    "# define data grouped by review id (as dataframe)\n",
    "grouped_df = input_data.groupby('review_id')\n",
    "actual_category = grouped_df['category'].agg(lambda column: \",\".join(column))\n",
    "actual_category = actual_category.reset_index(name='category')\n",
    "\n",
    "# define x_train and y_train data\n",
    "review_id = input_data.review_id\n",
    "phrase = input_data.phrase\n",
    "category = input_data.category\n",
    "print(category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 10  # most of the phrase is within length of 10\n",
    "MAX_NB_WORDS = 400000  # I set this based on the number of words found in the glove.txt\n",
    "EMBEDDING_DIM = 100  # I tried using glove 100d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vectorize the text samples into a 2D integer tensor and padding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2890 unique tokens.\n",
      "Let's have a quick look at the word_index data..\n",
      "[('food', 1), ('great', 2), ('good', 3), ('service', 4), ('place', 5), ('best', 6), ('nice', 7), ('like', 8), ('restaurant', 9), ('excellent', 10)]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=False)\n",
    "tokenizer.fit_on_texts(phrase)\n",
    "sequences = tokenizer.texts_to_sequences(phrase)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print (\"Let's have a quick look at the word_index data..\")\n",
    "print (list(word_index.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2232 1489 2233 ...    0    0    0]\n",
      " [ 416  876 1780 ...    8    0    0]\n",
      " [ 416  876 1780 ...    8 1781  111]\n",
      " ...\n",
      " [   3    1   57 ...    0    0    0]\n",
      " [   3    1   57 ...    0    0    0]\n",
      " [   3    1   57 ...    0    0    0]]\n",
      "Shape of tokenised output: (5055, 10)\n"
     ]
    }
   ],
   "source": [
    "tokenised_sequence = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
    "print(tokenised_sequence)\n",
    "print('Shape of tokenised output:', tokenised_sequence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Filtering input data based on classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_id_list = review_id.tolist()\n",
    "category_list = category.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AMBIENCE#GENERAL', 581), ('FOOD#QUALITY', 1709), ('RESTAURANT#GENERAL', 535), ('SERVICE#GENERAL', 902)]\n",
      "[1.60370052 0.54520187 1.74158879 1.03298226]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_list = ['FOOD#QUALITY', 'SERVICE#GENERAL', 'AMBIENCE#GENERAL', 'RESTAURANT#GENERAL']\n",
    "filtered_phrase = []\n",
    "filtered_category = []\n",
    "filtered_id = []\n",
    "\n",
    "for i in range(0, len(category_list)):  # to choose the top 4 largest class\n",
    "    if category_list[i] in class_list:\n",
    "        filtered_id.append(review_id_list[i])\n",
    "        filtered_phrase.append(tokenised_sequence[i])\n",
    "        filtered_category.append(category_list[i])\n",
    "        \n",
    "np_phrase = np.array(filtered_phrase)  # So this is without oversampling, the accuracy improves from 0.2 to 0.4 but still all same prob\n",
    "np_category = np.array(filtered_category)\n",
    "print(sorted(Counter(np_category).items()))\n",
    "\n",
    "# class weight to handle imbalanced data\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(np_category),\n",
    "                                                 np_category)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transform output data into categorical index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "(3727, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(np_category)\n",
    "    \n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "print(onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tidy up all variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with 2982\n",
      "Test with 745\n"
     ]
    }
   ],
   "source": [
    "# 80% as training data\n",
    "# 20% as testing data\n",
    "import math\n",
    "\n",
    "phrase_size = np_phrase.shape[0]\n",
    "category_size = onehot_encoded.shape[0]\n",
    "assert phrase_size == category_size\n",
    "\n",
    "train_limit = math.ceil(category_size*0.8)\n",
    "test_limit = category_size\n",
    "\n",
    "x_train = np_phrase[:train_limit]\n",
    "x_test = np_phrase[train_limit:test_limit]\n",
    "y_train = onehot_encoded[:train_limit]\n",
    "y_test = onehot_encoded[train_limit:test_limit]\n",
    "id_test = filtered_id[train_limit:test_limit]\n",
    "\n",
    "print(\"Train with \" + str(train_limit))\n",
    "print(\"Test with \" + str(test_limit - train_limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "File exists:True\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "# check if file exists\n",
    "print (\"File exists:\"+str(path.exists(\"glove.6B.100d.txt\")))\n",
    "\n",
    "f = open(\"glove.6B.100d.txt\", 'rb')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    word = word.decode(\"utf-8\")\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "nb_words = len(word_index)\n",
    "embedding_matrix = np.zeros((nb_words + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(nb_words + 1,\n",
    "                            100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dense, LSTM, SpatialDropout1D\n",
    "from keras.layers import BatchNormalization\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our lstm model for Talos parameter sweeping use\n",
    "\n",
    "def lstm_model(x_train, y_train, x_test, y_test, params):\n",
    "    \n",
    "    lstm_out = params['hidden_units']\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(LSTM(lstm_out, dropout= params['dropout'], recurrent_dropout=params['dropout']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8,activation='softmax'))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer= optimizer, metrics = ['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,  # 80% as training data\n",
    "          validation_split=0.1,\n",
    "          batch_size=params['batch_size'],\n",
    "          epochs=50, class_weight = class_weights)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# different possible values for hyperparameters\n",
    "\n",
    "p = {'hidden_units':[10, 100, 300],\n",
    "     'batch_size': [32, 64],\n",
    "     'dropout': (0, 0.40, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 864us/step - loss: 1.3991 - accuracy: 0.2556 - val_loss: 1.3875 - val_accuracy: 0.2105\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 1.2930 - accuracy: 0.4398 - val_loss: 1.3110 - val_accuracy: 0.4498\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 310us/step - loss: 1.2165 - accuracy: 0.5059 - val_loss: 1.2325 - val_accuracy: 0.4833\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 314us/step - loss: 1.1567 - accuracy: 0.5724 - val_loss: 1.1760 - val_accuracy: 0.5550\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 336us/step - loss: 1.1062 - accuracy: 0.6102 - val_loss: 1.1303 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 1.0631 - accuracy: 0.6214 - val_loss: 1.1043 - val_accuracy: 0.5885\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 1.0333 - accuracy: 0.6374 - val_loss: 1.0767 - val_accuracy: 0.5933\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 325us/step - loss: 1.0054 - accuracy: 0.6592 - val_loss: 1.0892 - val_accuracy: 0.5981\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 314us/step - loss: 0.9815 - accuracy: 0.6725 - val_loss: 1.0428 - val_accuracy: 0.6268\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.9513 - accuracy: 0.6938 - val_loss: 1.0231 - val_accuracy: 0.6364\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.9297 - accuracy: 0.6997 - val_loss: 1.0177 - val_accuracy: 0.6077\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.9111 - accuracy: 0.7055 - val_loss: 1.0200 - val_accuracy: 0.6172\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 317us/step - loss: 0.8910 - accuracy: 0.7114 - val_loss: 1.0138 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 328us/step - loss: 0.8697 - accuracy: 0.7220 - val_loss: 0.9882 - val_accuracy: 0.6268\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.8448 - accuracy: 0.7380 - val_loss: 0.9762 - val_accuracy: 0.6268\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 292us/step - loss: 0.8281 - accuracy: 0.7433 - val_loss: 0.9718 - val_accuracy: 0.6268\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: 0.8170 - accuracy: 0.7412 - val_loss: 0.9627 - val_accuracy: 0.6411\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 347us/step - loss: 0.7987 - accuracy: 0.7460 - val_loss: 0.9709 - val_accuracy: 0.6268\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.7862 - accuracy: 0.7503 - val_loss: 0.9932 - val_accuracy: 0.6077\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 330us/step - loss: 0.7716 - accuracy: 0.7625 - val_loss: 0.9622 - val_accuracy: 0.6411\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 341us/step - loss: 0.7582 - accuracy: 0.7604 - val_loss: 0.9512 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.7483 - accuracy: 0.7646 - val_loss: 0.9703 - val_accuracy: 0.6172\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 317us/step - loss: 0.7398 - accuracy: 0.7646 - val_loss: 0.9586 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 0.7296 - accuracy: 0.7705 - val_loss: 0.9595 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.7224 - accuracy: 0.7646 - val_loss: 0.9569 - val_accuracy: 0.6364\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 317us/step - loss: 0.7072 - accuracy: 0.7710 - val_loss: 0.9909 - val_accuracy: 0.6172\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 345us/step - loss: 0.7124 - accuracy: 0.7678 - val_loss: 0.9634 - val_accuracy: 0.6316\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 398us/step - loss: 0.6951 - accuracy: 0.7705 - val_loss: 0.9765 - val_accuracy: 0.6268\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 347us/step - loss: 0.6900 - accuracy: 0.7742 - val_loss: 0.9778 - val_accuracy: 0.6077\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 373us/step - loss: 0.6778 - accuracy: 0.7854 - val_loss: 0.9350 - val_accuracy: 0.6459\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 355us/step - loss: 0.6765 - accuracy: 0.7758 - val_loss: 0.9560 - val_accuracy: 0.6459\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 424us/step - loss: 0.6628 - accuracy: 0.7902 - val_loss: 0.9670 - val_accuracy: 0.6220\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 299us/step - loss: 0.6624 - accuracy: 0.7870 - val_loss: 0.9382 - val_accuracy: 0.6507\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 341us/step - loss: 0.6530 - accuracy: 0.7843 - val_loss: 0.9589 - val_accuracy: 0.6364\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 371us/step - loss: 0.6483 - accuracy: 0.7902 - val_loss: 0.9730 - val_accuracy: 0.6268\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.6437 - accuracy: 0.7849 - val_loss: 0.9336 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 387us/step - loss: 0.6331 - accuracy: 0.7918 - val_loss: 0.9533 - val_accuracy: 0.6220\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 335us/step - loss: 0.6339 - accuracy: 0.7902 - val_loss: 0.9502 - val_accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 308us/step - loss: 0.6278 - accuracy: 0.7891 - val_loss: 0.9494 - val_accuracy: 0.6268\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 353us/step - loss: 0.6187 - accuracy: 0.7886 - val_loss: 0.9706 - val_accuracy: 0.6172\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 319us/step - loss: 0.6242 - accuracy: 0.7902 - val_loss: 0.9438 - val_accuracy: 0.6459\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 328us/step - loss: 0.6113 - accuracy: 0.7977 - val_loss: 0.9621 - val_accuracy: 0.6029\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 381us/step - loss: 0.6074 - accuracy: 0.8040 - val_loss: 0.9748 - val_accuracy: 0.6268\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.6048 - accuracy: 0.7971 - val_loss: 0.9687 - val_accuracy: 0.6220\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.5962 - accuracy: 0.7998 - val_loss: 0.9673 - val_accuracy: 0.6316\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 0.5920 - accuracy: 0.8009 - val_loss: 0.9581 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 283us/step - loss: 0.5938 - accuracy: 0.8003 - val_loss: 0.9826 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.5966 - accuracy: 0.7961 - val_loss: 0.9800 - val_accuracy: 0.6268\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 0.5847 - accuracy: 0.7961 - val_loss: 0.9684 - val_accuracy: 0.6411\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 0.5887 - accuracy: 0.7961 - val_loss: 0.9623 - val_accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/60 [00:33<32:51, 33.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 967us/step - loss: 1.1966 - accuracy: 0.5415 - val_loss: 1.2641 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 859us/step - loss: 1.0901 - accuracy: 0.6491 - val_loss: 1.1967 - val_accuracy: 0.4354\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0454 - accuracy: 0.6576 - val_loss: 1.1527 - val_accuracy: 0.5167\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 896us/step - loss: 1.0053 - accuracy: 0.6816 - val_loss: 1.0866 - val_accuracy: 0.6077\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 646us/step - loss: 0.9575 - accuracy: 0.7039 - val_loss: 1.0456 - val_accuracy: 0.6077\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 605us/step - loss: 0.9225 - accuracy: 0.7114 - val_loss: 1.0168 - val_accuracy: 0.6172\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 666us/step - loss: 0.9018 - accuracy: 0.7077 - val_loss: 1.0362 - val_accuracy: 0.6172\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 650us/step - loss: 0.8634 - accuracy: 0.7231 - val_loss: 0.9801 - val_accuracy: 0.6364\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 530us/step - loss: 0.8405 - accuracy: 0.7295 - val_loss: 0.9522 - val_accuracy: 0.6555\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 527us/step - loss: 0.8084 - accuracy: 0.7444 - val_loss: 0.9158 - val_accuracy: 0.6699\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 490us/step - loss: 0.7883 - accuracy: 0.7529 - val_loss: 0.9709 - val_accuracy: 0.6124\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 501us/step - loss: 0.7754 - accuracy: 0.7545 - val_loss: 0.9412 - val_accuracy: 0.6459\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 575us/step - loss: 0.7537 - accuracy: 0.7609 - val_loss: 0.9257 - val_accuracy: 0.6411\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 491us/step - loss: 0.7485 - accuracy: 0.7492 - val_loss: 0.9158 - val_accuracy: 0.6507\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 414us/step - loss: 0.7225 - accuracy: 0.7689 - val_loss: 0.8838 - val_accuracy: 0.6746\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 513us/step - loss: 0.7222 - accuracy: 0.7609 - val_loss: 0.8981 - val_accuracy: 0.6459\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.6980 - accuracy: 0.7700 - val_loss: 0.8968 - val_accuracy: 0.6555\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 428us/step - loss: 0.6812 - accuracy: 0.7796 - val_loss: 0.8773 - val_accuracy: 0.6651\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 521us/step - loss: 0.6846 - accuracy: 0.7716 - val_loss: 0.9288 - val_accuracy: 0.6364\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 485us/step - loss: 0.6686 - accuracy: 0.7780 - val_loss: 0.8500 - val_accuracy: 0.6890\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 484us/step - loss: 0.6507 - accuracy: 0.7843 - val_loss: 0.8909 - val_accuracy: 0.6603\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 419us/step - loss: 0.6549 - accuracy: 0.7764 - val_loss: 0.8833 - val_accuracy: 0.6603\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 438us/step - loss: 0.6449 - accuracy: 0.7790 - val_loss: 0.8511 - val_accuracy: 0.6699\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 427us/step - loss: 0.6188 - accuracy: 0.7875 - val_loss: 0.8367 - val_accuracy: 0.6699\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 459us/step - loss: 0.6156 - accuracy: 0.7907 - val_loss: 0.8641 - val_accuracy: 0.6794\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.6228 - accuracy: 0.7721 - val_loss: 0.8638 - val_accuracy: 0.6603\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 514us/step - loss: 0.6164 - accuracy: 0.7806 - val_loss: 0.8729 - val_accuracy: 0.6459\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 417us/step - loss: 0.6176 - accuracy: 0.7865 - val_loss: 0.9275 - val_accuracy: 0.6507\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 417us/step - loss: 0.6133 - accuracy: 0.7838 - val_loss: 0.8639 - val_accuracy: 0.6699\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 493us/step - loss: 0.5976 - accuracy: 0.7817 - val_loss: 0.8934 - val_accuracy: 0.6555\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 445us/step - loss: 0.5913 - accuracy: 0.7907 - val_loss: 0.8679 - val_accuracy: 0.6746\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 443us/step - loss: 0.5753 - accuracy: 0.7939 - val_loss: 0.8998 - val_accuracy: 0.6555\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 397us/step - loss: 0.5677 - accuracy: 0.7982 - val_loss: 0.8912 - val_accuracy: 0.6459\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 383us/step - loss: 0.5565 - accuracy: 0.7993 - val_loss: 0.8521 - val_accuracy: 0.6794\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 499us/step - loss: 0.5589 - accuracy: 0.7966 - val_loss: 0.9030 - val_accuracy: 0.6459\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 458us/step - loss: 0.5474 - accuracy: 0.7987 - val_loss: 0.8871 - val_accuracy: 0.6507\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 500us/step - loss: 0.5429 - accuracy: 0.7987 - val_loss: 0.8762 - val_accuracy: 0.6507\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 386us/step - loss: 0.5348 - accuracy: 0.8046 - val_loss: 0.9874 - val_accuracy: 0.6172\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.5481 - accuracy: 0.7977 - val_loss: 0.8919 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.5456 - accuracy: 0.7987 - val_loss: 0.9655 - val_accuracy: 0.6124\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.5357 - accuracy: 0.7987 - val_loss: 0.8399 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 435us/step - loss: 0.5372 - accuracy: 0.7971 - val_loss: 0.8891 - val_accuracy: 0.6411\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 469us/step - loss: 0.5262 - accuracy: 0.8035 - val_loss: 0.9056 - val_accuracy: 0.6411\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 447us/step - loss: 0.5265 - accuracy: 0.8094 - val_loss: 0.9283 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 462us/step - loss: 0.5236 - accuracy: 0.8024 - val_loss: 0.9300 - val_accuracy: 0.6507\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 507us/step - loss: 0.5136 - accuracy: 0.8072 - val_loss: 0.9655 - val_accuracy: 0.6603\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 468us/step - loss: 0.5200 - accuracy: 0.8030 - val_loss: 0.8896 - val_accuracy: 0.6794\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 488us/step - loss: 0.5200 - accuracy: 0.8051 - val_loss: 0.8897 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 359us/step - loss: 0.5080 - accuracy: 0.8062 - val_loss: 0.9178 - val_accuracy: 0.6507\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 461us/step - loss: 0.5030 - accuracy: 0.8083 - val_loss: 0.9255 - val_accuracy: 0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/60 [01:23<37:03, 38.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.2267 - accuracy: 0.5458 - val_loss: 1.2369 - val_accuracy: 0.4976\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1477 - accuracy: 0.6124 - val_loss: 1.1875 - val_accuracy: 0.5598\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1008 - accuracy: 0.6140 - val_loss: 1.1434 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0541 - accuracy: 0.6363 - val_loss: 1.1071 - val_accuracy: 0.5837\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0314 - accuracy: 0.6353 - val_loss: 1.0762 - val_accuracy: 0.6316\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0074 - accuracy: 0.6374 - val_loss: 1.0941 - val_accuracy: 0.5455\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9895 - accuracy: 0.6267 - val_loss: 1.0553 - val_accuracy: 0.5885\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9461 - accuracy: 0.6480 - val_loss: 1.0463 - val_accuracy: 0.6029\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9453 - accuracy: 0.6619 - val_loss: 1.0846 - val_accuracy: 0.5694\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9494 - accuracy: 0.6454 - val_loss: 1.0652 - val_accuracy: 0.5598\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9102 - accuracy: 0.6683 - val_loss: 1.0436 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8874 - accuracy: 0.6539 - val_loss: 1.0074 - val_accuracy: 0.6077\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8636 - accuracy: 0.6810 - val_loss: 0.9874 - val_accuracy: 0.6124\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8455 - accuracy: 0.7268 - val_loss: 1.0198 - val_accuracy: 0.6124\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8504 - accuracy: 0.7023 - val_loss: 1.0058 - val_accuracy: 0.6459\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8167 - accuracy: 0.7258 - val_loss: 1.0098 - val_accuracy: 0.6077\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7947 - accuracy: 0.7322 - val_loss: 0.9948 - val_accuracy: 0.6507\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7999 - accuracy: 0.7306 - val_loss: 1.0135 - val_accuracy: 0.6220\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7654 - accuracy: 0.7465 - val_loss: 1.0325 - val_accuracy: 0.5933\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7545 - accuracy: 0.7508 - val_loss: 0.9905 - val_accuracy: 0.6411\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7700 - accuracy: 0.7327 - val_loss: 0.9716 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7265 - accuracy: 0.7556 - val_loss: 0.9763 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7289 - accuracy: 0.7513 - val_loss: 0.9633 - val_accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7286 - accuracy: 0.7503 - val_loss: 0.9505 - val_accuracy: 0.6411\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6997 - accuracy: 0.7710 - val_loss: 0.9715 - val_accuracy: 0.6411\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.7657 - val_loss: 0.9322 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6749 - accuracy: 0.7668 - val_loss: 0.9401 - val_accuracy: 0.6220\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6609 - accuracy: 0.7705 - val_loss: 0.9632 - val_accuracy: 0.6364\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6442 - accuracy: 0.7801 - val_loss: 0.9617 - val_accuracy: 0.6364\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6463 - accuracy: 0.7774 - val_loss: 0.9495 - val_accuracy: 0.6364\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6303 - accuracy: 0.7780 - val_loss: 0.9246 - val_accuracy: 0.6268\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6082 - accuracy: 0.7913 - val_loss: 0.9193 - val_accuracy: 0.6411\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6203 - accuracy: 0.7796 - val_loss: 0.9210 - val_accuracy: 0.6172\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6176 - accuracy: 0.7732 - val_loss: 0.9145 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6022 - accuracy: 0.7881 - val_loss: 0.9909 - val_accuracy: 0.6029\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5770 - accuracy: 0.7891 - val_loss: 0.9316 - val_accuracy: 0.6364\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5612 - accuracy: 0.7998 - val_loss: 0.9727 - val_accuracy: 0.6172\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5630 - accuracy: 0.7971 - val_loss: 0.9602 - val_accuracy: 0.6077\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5475 - accuracy: 0.8019 - val_loss: 0.9336 - val_accuracy: 0.6172\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5399 - accuracy: 0.8030 - val_loss: 0.9293 - val_accuracy: 0.6411\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5308 - accuracy: 0.8067 - val_loss: 1.0031 - val_accuracy: 0.5933\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5352 - accuracy: 0.8024 - val_loss: 1.0432 - val_accuracy: 0.5742\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5415 - accuracy: 0.7998 - val_loss: 0.9868 - val_accuracy: 0.6268\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5444 - accuracy: 0.7923 - val_loss: 0.9912 - val_accuracy: 0.5933\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5379 - accuracy: 0.7998 - val_loss: 0.9910 - val_accuracy: 0.5981\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5071 - accuracy: 0.8099 - val_loss: 0.9787 - val_accuracy: 0.6220\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5215 - accuracy: 0.8014 - val_loss: 0.9810 - val_accuracy: 0.5885\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.5007 - accuracy: 0.8056 - val_loss: 0.9866 - val_accuracy: 0.6029\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.4986 - accuracy: 0.8099 - val_loss: 1.0081 - val_accuracy: 0.5837\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5166 - accuracy: 0.7971 - val_loss: 0.9679 - val_accuracy: 0.6172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3/60 [03:31<1:01:58, 65.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 987us/step - loss: 1.3597 - accuracy: 0.3269 - val_loss: 1.3395 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 318us/step - loss: 1.2734 - accuracy: 0.4744 - val_loss: 1.3031 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 1.1992 - accuracy: 0.5224 - val_loss: 1.2534 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 1.1353 - accuracy: 0.5703 - val_loss: 1.1982 - val_accuracy: 0.4354\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 1.0783 - accuracy: 0.6092 - val_loss: 1.1255 - val_accuracy: 0.5359\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 1.0310 - accuracy: 0.6305 - val_loss: 1.0768 - val_accuracy: 0.5933\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 345us/step - loss: 0.9923 - accuracy: 0.6613 - val_loss: 1.0600 - val_accuracy: 0.5598\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 0.9672 - accuracy: 0.6640 - val_loss: 1.0344 - val_accuracy: 0.6316\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.9328 - accuracy: 0.6826 - val_loss: 1.0247 - val_accuracy: 0.5933\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 286us/step - loss: 0.9036 - accuracy: 0.6922 - val_loss: 1.0081 - val_accuracy: 0.6029\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.8839 - accuracy: 0.6917 - val_loss: 1.0050 - val_accuracy: 0.6220\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 0.8754 - accuracy: 0.6869 - val_loss: 0.9933 - val_accuracy: 0.6411\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 0.8483 - accuracy: 0.7071 - val_loss: 0.9835 - val_accuracy: 0.6077\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.8384 - accuracy: 0.7007 - val_loss: 0.9750 - val_accuracy: 0.6268\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.8161 - accuracy: 0.7162 - val_loss: 0.9829 - val_accuracy: 0.5694\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.7995 - accuracy: 0.7199 - val_loss: 0.9720 - val_accuracy: 0.5933\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.7917 - accuracy: 0.7220 - val_loss: 0.9474 - val_accuracy: 0.6316\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.7833 - accuracy: 0.7290 - val_loss: 0.9474 - val_accuracy: 0.6077\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.7799 - accuracy: 0.7258 - val_loss: 0.9570 - val_accuracy: 0.5885\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 0.7513 - accuracy: 0.7423 - val_loss: 0.9509 - val_accuracy: 0.6077\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.7485 - accuracy: 0.7284 - val_loss: 0.9535 - val_accuracy: 0.6077\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.7381 - accuracy: 0.7423 - val_loss: 0.9389 - val_accuracy: 0.6029\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.7293 - accuracy: 0.7449 - val_loss: 0.9110 - val_accuracy: 0.6316\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 316us/step - loss: 0.7217 - accuracy: 0.7412 - val_loss: 0.9074 - val_accuracy: 0.6220\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.7131 - accuracy: 0.7386 - val_loss: 0.9086 - val_accuracy: 0.6172\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: 0.6934 - accuracy: 0.7540 - val_loss: 0.9078 - val_accuracy: 0.6220\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 0.6929 - accuracy: 0.7583 - val_loss: 0.9081 - val_accuracy: 0.6077\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 0.6839 - accuracy: 0.7513 - val_loss: 0.9459 - val_accuracy: 0.6124\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 290us/step - loss: 0.6983 - accuracy: 0.7487 - val_loss: 0.9117 - val_accuracy: 0.6077\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.6809 - accuracy: 0.7519 - val_loss: 0.9158 - val_accuracy: 0.6029\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: 0.6816 - accuracy: 0.7481 - val_loss: 0.8958 - val_accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.6780 - accuracy: 0.7513 - val_loss: 0.9080 - val_accuracy: 0.6077\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 0.6643 - accuracy: 0.7545 - val_loss: 0.9074 - val_accuracy: 0.6172\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.6721 - accuracy: 0.7449 - val_loss: 0.8982 - val_accuracy: 0.6364\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 0.6450 - accuracy: 0.7641 - val_loss: 0.9097 - val_accuracy: 0.6316\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.6438 - accuracy: 0.7657 - val_loss: 0.9146 - val_accuracy: 0.6220\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.6409 - accuracy: 0.7716 - val_loss: 0.9020 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 292us/step - loss: 0.6437 - accuracy: 0.7689 - val_loss: 0.8945 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.6336 - accuracy: 0.7694 - val_loss: 0.9002 - val_accuracy: 0.6364\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 300us/step - loss: 0.6226 - accuracy: 0.7796 - val_loss: 0.8958 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 0.6191 - accuracy: 0.7710 - val_loss: 0.9043 - val_accuracy: 0.6411\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.6266 - accuracy: 0.7646 - val_loss: 0.9029 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.6227 - accuracy: 0.7678 - val_loss: 0.8976 - val_accuracy: 0.6220\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.6163 - accuracy: 0.7652 - val_loss: 0.8879 - val_accuracy: 0.6507\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.6182 - accuracy: 0.7561 - val_loss: 0.8807 - val_accuracy: 0.6316\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 307us/step - loss: 0.6115 - accuracy: 0.7646 - val_loss: 0.9045 - val_accuracy: 0.6316\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 0.5981 - accuracy: 0.7774 - val_loss: 0.8942 - val_accuracy: 0.6507\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 303us/step - loss: 0.6167 - accuracy: 0.7657 - val_loss: 0.8853 - val_accuracy: 0.6316\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 0.6044 - accuracy: 0.7732 - val_loss: 0.8947 - val_accuracy: 0.6316\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.5952 - accuracy: 0.7801 - val_loss: 0.8812 - val_accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/60 [04:00<50:56, 54.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 957us/step - loss: 1.3336 - accuracy: 0.4105 - val_loss: 1.3520 - val_accuracy: 0.3349\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 514us/step - loss: 1.2237 - accuracy: 0.6246 - val_loss: 1.2675 - val_accuracy: 0.5502\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 461us/step - loss: 1.1577 - accuracy: 0.6395 - val_loss: 1.2170 - val_accuracy: 0.5742\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 504us/step - loss: 1.1097 - accuracy: 0.6587 - val_loss: 1.1676 - val_accuracy: 0.6029\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 461us/step - loss: 1.0713 - accuracy: 0.6757 - val_loss: 1.1047 - val_accuracy: 0.6411\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 437us/step - loss: 1.0301 - accuracy: 0.6906 - val_loss: 1.0873 - val_accuracy: 0.6507\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 456us/step - loss: 1.0026 - accuracy: 0.6928 - val_loss: 1.0850 - val_accuracy: 0.6316\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 590us/step - loss: 0.9831 - accuracy: 0.6976 - val_loss: 1.0961 - val_accuracy: 0.6124\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 551us/step - loss: 0.9460 - accuracy: 0.7045 - val_loss: 1.0394 - val_accuracy: 0.6172\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 518us/step - loss: 0.9252 - accuracy: 0.7135 - val_loss: 0.9996 - val_accuracy: 0.6603\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 454us/step - loss: 0.8984 - accuracy: 0.7173 - val_loss: 1.0485 - val_accuracy: 0.6172\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 471us/step - loss: 0.8857 - accuracy: 0.7130 - val_loss: 1.0006 - val_accuracy: 0.6459\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 514us/step - loss: 0.8737 - accuracy: 0.7130 - val_loss: 0.9898 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 551us/step - loss: 0.8498 - accuracy: 0.7231 - val_loss: 0.9620 - val_accuracy: 0.6507\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 470us/step - loss: 0.8245 - accuracy: 0.7332 - val_loss: 0.9795 - val_accuracy: 0.6364\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 467us/step - loss: 0.7961 - accuracy: 0.7433 - val_loss: 0.9121 - val_accuracy: 0.6746\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 464us/step - loss: 0.7838 - accuracy: 0.7428 - val_loss: 0.8809 - val_accuracy: 0.6794\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 491us/step - loss: 0.7736 - accuracy: 0.7439 - val_loss: 0.9094 - val_accuracy: 0.6603\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 530us/step - loss: 0.7660 - accuracy: 0.7455 - val_loss: 0.9054 - val_accuracy: 0.6507\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 514us/step - loss: 0.7284 - accuracy: 0.7572 - val_loss: 0.9353 - val_accuracy: 0.6555\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 462us/step - loss: 0.7193 - accuracy: 0.7620 - val_loss: 0.8775 - val_accuracy: 0.6746\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 424us/step - loss: 0.7172 - accuracy: 0.7583 - val_loss: 0.8858 - val_accuracy: 0.6842\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 480us/step - loss: 0.6940 - accuracy: 0.7710 - val_loss: 0.9191 - val_accuracy: 0.6699\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 467us/step - loss: 0.6816 - accuracy: 0.7726 - val_loss: 0.8917 - val_accuracy: 0.6651\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 427us/step - loss: 0.6889 - accuracy: 0.7609 - val_loss: 0.8682 - val_accuracy: 0.6890\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 443us/step - loss: 0.6714 - accuracy: 0.7726 - val_loss: 0.8728 - val_accuracy: 0.6890\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.6622 - accuracy: 0.7732 - val_loss: 0.8815 - val_accuracy: 0.6986\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 448us/step - loss: 0.6506 - accuracy: 0.7753 - val_loss: 0.9804 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 438us/step - loss: 0.6433 - accuracy: 0.7737 - val_loss: 0.9037 - val_accuracy: 0.6603\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 459us/step - loss: 0.6395 - accuracy: 0.7822 - val_loss: 0.9893 - val_accuracy: 0.6220\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 523us/step - loss: 0.6251 - accuracy: 0.7838 - val_loss: 0.9037 - val_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 527us/step - loss: 0.6290 - accuracy: 0.7780 - val_loss: 0.8808 - val_accuracy: 0.6651\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 484us/step - loss: 0.6171 - accuracy: 0.7796 - val_loss: 0.9373 - val_accuracy: 0.6507\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 453us/step - loss: 0.6055 - accuracy: 0.7923 - val_loss: 0.9268 - val_accuracy: 0.6507\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 464us/step - loss: 0.5867 - accuracy: 0.8009 - val_loss: 0.9694 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 460us/step - loss: 0.6067 - accuracy: 0.7843 - val_loss: 0.8911 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 460us/step - loss: 0.5855 - accuracy: 0.7929 - val_loss: 0.8854 - val_accuracy: 0.6842\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 456us/step - loss: 0.5818 - accuracy: 0.7929 - val_loss: 0.9178 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 443us/step - loss: 0.5782 - accuracy: 0.7929 - val_loss: 0.8853 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 450us/step - loss: 0.5619 - accuracy: 0.8046 - val_loss: 0.9295 - val_accuracy: 0.6507\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 496us/step - loss: 0.5650 - accuracy: 0.8030 - val_loss: 0.9360 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 450us/step - loss: 0.5655 - accuracy: 0.7966 - val_loss: 0.9013 - val_accuracy: 0.6651\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 435us/step - loss: 0.5603 - accuracy: 0.7897 - val_loss: 0.9251 - val_accuracy: 0.6555\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 473us/step - loss: 0.5388 - accuracy: 0.7998 - val_loss: 0.8947 - val_accuracy: 0.6746\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 472us/step - loss: 0.5327 - accuracy: 0.8056 - val_loss: 0.9745 - val_accuracy: 0.6364\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 461us/step - loss: 0.5457 - accuracy: 0.8024 - val_loss: 0.9085 - val_accuracy: 0.6794\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 476us/step - loss: 0.5400 - accuracy: 0.7934 - val_loss: 0.9492 - val_accuracy: 0.6459\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 460us/step - loss: 0.5375 - accuracy: 0.7955 - val_loss: 0.9059 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 458us/step - loss: 0.5282 - accuracy: 0.8009 - val_loss: 0.9899 - val_accuracy: 0.6411\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 520us/step - loss: 0.5193 - accuracy: 0.8110 - val_loss: 0.9335 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/60 [04:48<48:06, 52.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2264 - accuracy: 0.5202 - val_loss: 1.3008 - val_accuracy: 0.4067\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1437 - accuracy: 0.5708 - val_loss: 1.1976 - val_accuracy: 0.5646\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1114 - accuracy: 0.5836 - val_loss: 1.1876 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0804 - accuracy: 0.5942 - val_loss: 1.1194 - val_accuracy: 0.5742\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0439 - accuracy: 0.6124 - val_loss: 1.1050 - val_accuracy: 0.5694\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0383 - accuracy: 0.6108 - val_loss: 1.1106 - val_accuracy: 0.5885\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0087 - accuracy: 0.6177 - val_loss: 1.1029 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9861 - accuracy: 0.6326 - val_loss: 1.0699 - val_accuracy: 0.5885\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9581 - accuracy: 0.6528 - val_loss: 1.0538 - val_accuracy: 0.6077\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9734 - accuracy: 0.6390 - val_loss: 1.1019 - val_accuracy: 0.6172\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9361 - accuracy: 0.6613 - val_loss: 1.0450 - val_accuracy: 0.6077\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9275 - accuracy: 0.6693 - val_loss: 1.0731 - val_accuracy: 0.5981\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9116 - accuracy: 0.6741 - val_loss: 1.0974 - val_accuracy: 0.5837\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9168 - accuracy: 0.6768 - val_loss: 1.0315 - val_accuracy: 0.6316\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8895 - accuracy: 0.6842 - val_loss: 1.0050 - val_accuracy: 0.6364\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8498 - accuracy: 0.7018 - val_loss: 1.0030 - val_accuracy: 0.6411\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8507 - accuracy: 0.6917 - val_loss: 1.0417 - val_accuracy: 0.6077\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8368 - accuracy: 0.7023 - val_loss: 0.9470 - val_accuracy: 0.6268\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8101 - accuracy: 0.7167 - val_loss: 0.9304 - val_accuracy: 0.6651\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7973 - accuracy: 0.7178 - val_loss: 0.8986 - val_accuracy: 0.6794\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7817 - accuracy: 0.7306 - val_loss: 0.9434 - val_accuracy: 0.6651\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7771 - accuracy: 0.7274 - val_loss: 0.8889 - val_accuracy: 0.6890\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7549 - accuracy: 0.7364 - val_loss: 0.8706 - val_accuracy: 0.7033\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7434 - accuracy: 0.7417 - val_loss: 0.9145 - val_accuracy: 0.6746\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7358 - accuracy: 0.7481 - val_loss: 0.9268 - val_accuracy: 0.6699\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7279 - accuracy: 0.7519 - val_loss: 0.9533 - val_accuracy: 0.6555\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7165 - accuracy: 0.7465 - val_loss: 0.9287 - val_accuracy: 0.6699\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6997 - accuracy: 0.7593 - val_loss: 0.9472 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.7785 - val_loss: 0.8659 - val_accuracy: 0.6938\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6809 - accuracy: 0.7694 - val_loss: 0.9187 - val_accuracy: 0.6699\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6739 - accuracy: 0.7753 - val_loss: 0.9352 - val_accuracy: 0.6699\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6733 - accuracy: 0.7689 - val_loss: 0.9369 - val_accuracy: 0.6794\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6545 - accuracy: 0.7758 - val_loss: 0.8784 - val_accuracy: 0.7033\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6562 - accuracy: 0.7737 - val_loss: 0.9468 - val_accuracy: 0.6603\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6658 - accuracy: 0.7694 - val_loss: 0.9092 - val_accuracy: 0.6794\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6404 - accuracy: 0.7742 - val_loss: 0.9196 - val_accuracy: 0.6603\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6475 - accuracy: 0.7742 - val_loss: 0.8355 - val_accuracy: 0.6986\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6207 - accuracy: 0.7812 - val_loss: 0.8711 - val_accuracy: 0.6938\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6091 - accuracy: 0.7859 - val_loss: 0.8871 - val_accuracy: 0.6938\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6018 - accuracy: 0.7881 - val_loss: 0.9188 - val_accuracy: 0.6794\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5855 - accuracy: 0.7923 - val_loss: 0.8900 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5787 - accuracy: 0.7939 - val_loss: 0.9014 - val_accuracy: 0.6699\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.5787 - accuracy: 0.7913 - val_loss: 0.9577 - val_accuracy: 0.6842\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.5591 - accuracy: 0.7993 - val_loss: 0.8939 - val_accuracy: 0.6794\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5565 - accuracy: 0.7966 - val_loss: 0.9083 - val_accuracy: 0.6699\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5693 - accuracy: 0.7897 - val_loss: 0.9263 - val_accuracy: 0.6555\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5523 - accuracy: 0.7998 - val_loss: 0.9169 - val_accuracy: 0.6794\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.5419 - accuracy: 0.8009 - val_loss: 0.9386 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.5354 - accuracy: 0.8035 - val_loss: 0.8914 - val_accuracy: 0.6603\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5327 - accuracy: 0.7966 - val_loss: 0.9241 - val_accuracy: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 6/60 [07:12<1:12:01, 80.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 827us/step - loss: 1.3824 - accuracy: 0.2497 - val_loss: 1.3618 - val_accuracy: 0.2775\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 317us/step - loss: 1.3147 - accuracy: 0.3387 - val_loss: 1.3306 - val_accuracy: 0.4067\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 315us/step - loss: 1.2582 - accuracy: 0.4824 - val_loss: 1.2951 - val_accuracy: 0.4067\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 1.1999 - accuracy: 0.5357 - val_loss: 1.2532 - val_accuracy: 0.4306\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 316us/step - loss: 1.1524 - accuracy: 0.5437 - val_loss: 1.2065 - val_accuracy: 0.4641\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 1.1128 - accuracy: 0.5703 - val_loss: 1.1646 - val_accuracy: 0.5311\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 314us/step - loss: 1.0728 - accuracy: 0.5847 - val_loss: 1.1253 - val_accuracy: 0.5981\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 314us/step - loss: 1.0512 - accuracy: 0.5932 - val_loss: 1.1074 - val_accuracy: 0.6077\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 314us/step - loss: 1.0322 - accuracy: 0.6022 - val_loss: 1.0947 - val_accuracy: 0.6220\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 1.0063 - accuracy: 0.6166 - val_loss: 1.0857 - val_accuracy: 0.5933\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 0.9963 - accuracy: 0.6257 - val_loss: 1.0741 - val_accuracy: 0.6124\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 0.9754 - accuracy: 0.6422 - val_loss: 1.0622 - val_accuracy: 0.6077\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 0.9642 - accuracy: 0.6363 - val_loss: 1.0567 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 309us/step - loss: 0.9505 - accuracy: 0.6486 - val_loss: 1.0448 - val_accuracy: 0.6268\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 0.9290 - accuracy: 0.6470 - val_loss: 1.0448 - val_accuracy: 0.6172\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.9321 - accuracy: 0.6432 - val_loss: 1.0392 - val_accuracy: 0.6124\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.9275 - accuracy: 0.6544 - val_loss: 1.0405 - val_accuracy: 0.5981\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 248us/step - loss: 0.9231 - accuracy: 0.6475 - val_loss: 1.0359 - val_accuracy: 0.6077\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 244us/step - loss: 0.9012 - accuracy: 0.6576 - val_loss: 1.0282 - val_accuracy: 0.6364\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 241us/step - loss: 0.8877 - accuracy: 0.6693 - val_loss: 1.0148 - val_accuracy: 0.6364\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.8768 - accuracy: 0.6704 - val_loss: 1.0143 - val_accuracy: 0.6172\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 0.8722 - accuracy: 0.6731 - val_loss: 1.0163 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 356us/step - loss: 0.8551 - accuracy: 0.6933 - val_loss: 1.0071 - val_accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 0.8425 - accuracy: 0.6949 - val_loss: 1.0163 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 244us/step - loss: 0.8427 - accuracy: 0.6848 - val_loss: 0.9973 - val_accuracy: 0.6268\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.8417 - accuracy: 0.6848 - val_loss: 0.9929 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 234us/step - loss: 0.8144 - accuracy: 0.7093 - val_loss: 0.9897 - val_accuracy: 0.6411\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.8272 - accuracy: 0.6954 - val_loss: 0.9847 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.8101 - accuracy: 0.7007 - val_loss: 0.9726 - val_accuracy: 0.6220\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.7968 - accuracy: 0.7093 - val_loss: 0.9839 - val_accuracy: 0.6411\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 243us/step - loss: 0.7954 - accuracy: 0.7098 - val_loss: 0.9699 - val_accuracy: 0.6459\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 244us/step - loss: 0.7740 - accuracy: 0.7204 - val_loss: 0.9598 - val_accuracy: 0.6316\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 244us/step - loss: 0.7628 - accuracy: 0.7263 - val_loss: 0.9563 - val_accuracy: 0.6459\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 242us/step - loss: 0.7533 - accuracy: 0.7279 - val_loss: 0.9622 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 244us/step - loss: 0.7622 - accuracy: 0.7188 - val_loss: 0.9427 - val_accuracy: 0.6603\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.7471 - accuracy: 0.7268 - val_loss: 0.9364 - val_accuracy: 0.6699\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.7447 - accuracy: 0.7220 - val_loss: 0.9431 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.7386 - accuracy: 0.7242 - val_loss: 0.9142 - val_accuracy: 0.6507\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 248us/step - loss: 0.7165 - accuracy: 0.7380 - val_loss: 0.9207 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 0.7225 - accuracy: 0.7290 - val_loss: 0.9164 - val_accuracy: 0.6651\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.7210 - accuracy: 0.7322 - val_loss: 0.9235 - val_accuracy: 0.6555\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.7203 - accuracy: 0.7327 - val_loss: 0.9069 - val_accuracy: 0.6699\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 0.7121 - accuracy: 0.7386 - val_loss: 0.9215 - val_accuracy: 0.6794\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.7034 - accuracy: 0.7444 - val_loss: 0.8988 - val_accuracy: 0.6651\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 292us/step - loss: 0.6983 - accuracy: 0.7412 - val_loss: 0.9102 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 391us/step - loss: 0.7034 - accuracy: 0.7396 - val_loss: 0.8931 - val_accuracy: 0.6699\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.6883 - accuracy: 0.7455 - val_loss: 0.8911 - val_accuracy: 0.6555\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.6790 - accuracy: 0.7508 - val_loss: 0.9063 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 0.6791 - accuracy: 0.7412 - val_loss: 0.8916 - val_accuracy: 0.6603\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 0.6862 - accuracy: 0.7359 - val_loss: 0.8962 - val_accuracy: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 7/60 [07:41<57:12, 64.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.2506 - accuracy: 0.4808 - val_loss: 1.2833 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 483us/step - loss: 1.1637 - accuracy: 0.5655 - val_loss: 1.2237 - val_accuracy: 0.4880\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 491us/step - loss: 1.1174 - accuracy: 0.6012 - val_loss: 1.1694 - val_accuracy: 0.5359\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 439us/step - loss: 1.0830 - accuracy: 0.5985 - val_loss: 1.1332 - val_accuracy: 0.5120\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 417us/step - loss: 1.0458 - accuracy: 0.6230 - val_loss: 1.0935 - val_accuracy: 0.5885\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 397us/step - loss: 1.0168 - accuracy: 0.6656 - val_loss: 1.0689 - val_accuracy: 0.5981\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 424us/step - loss: 1.0007 - accuracy: 0.6640 - val_loss: 1.0602 - val_accuracy: 0.6029\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 455us/step - loss: 0.9827 - accuracy: 0.6757 - val_loss: 1.0384 - val_accuracy: 0.6268\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 448us/step - loss: 0.9452 - accuracy: 0.6938 - val_loss: 1.0114 - val_accuracy: 0.6507\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 454us/step - loss: 0.9172 - accuracy: 0.7061 - val_loss: 1.0119 - val_accuracy: 0.6411\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 490us/step - loss: 0.9077 - accuracy: 0.7007 - val_loss: 0.9834 - val_accuracy: 0.6555\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 441us/step - loss: 0.8945 - accuracy: 0.7087 - val_loss: 1.0072 - val_accuracy: 0.6172\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 476us/step - loss: 0.8647 - accuracy: 0.7178 - val_loss: 1.0065 - val_accuracy: 0.6411\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 439us/step - loss: 0.8519 - accuracy: 0.7178 - val_loss: 0.9701 - val_accuracy: 0.6364\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 448us/step - loss: 0.8369 - accuracy: 0.7258 - val_loss: 0.9882 - val_accuracy: 0.6029\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 437us/step - loss: 0.8310 - accuracy: 0.7183 - val_loss: 0.9734 - val_accuracy: 0.6316\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.8159 - accuracy: 0.7279 - val_loss: 0.9567 - val_accuracy: 0.6316\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 444us/step - loss: 0.8060 - accuracy: 0.7290 - val_loss: 0.9103 - val_accuracy: 0.6842\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 427us/step - loss: 0.7766 - accuracy: 0.7401 - val_loss: 0.8945 - val_accuracy: 0.6603\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 428us/step - loss: 0.7677 - accuracy: 0.7412 - val_loss: 0.8998 - val_accuracy: 0.6651\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 449us/step - loss: 0.7485 - accuracy: 0.7476 - val_loss: 0.8890 - val_accuracy: 0.6746\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 0.7346 - accuracy: 0.7535 - val_loss: 0.9253 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 426us/step - loss: 0.7287 - accuracy: 0.7524 - val_loss: 0.9278 - val_accuracy: 0.6459\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 534us/step - loss: 0.7313 - accuracy: 0.7529 - val_loss: 0.9129 - val_accuracy: 0.6459\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 548us/step - loss: 0.7028 - accuracy: 0.7646 - val_loss: 0.9127 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 482us/step - loss: 0.7055 - accuracy: 0.7593 - val_loss: 0.9794 - val_accuracy: 0.6316\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 532us/step - loss: 0.6804 - accuracy: 0.7753 - val_loss: 0.9146 - val_accuracy: 0.6603\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 524us/step - loss: 0.6723 - accuracy: 0.7742 - val_loss: 0.8934 - val_accuracy: 0.6651\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 470us/step - loss: 0.6848 - accuracy: 0.7561 - val_loss: 0.9573 - val_accuracy: 0.6411\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 497us/step - loss: 0.6640 - accuracy: 0.7641 - val_loss: 0.9101 - val_accuracy: 0.6699\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 463us/step - loss: 0.6478 - accuracy: 0.7790 - val_loss: 0.8865 - val_accuracy: 0.6890\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 0.6497 - accuracy: 0.7764 - val_loss: 0.8823 - val_accuracy: 0.6699\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 454us/step - loss: 0.6581 - accuracy: 0.7662 - val_loss: 0.9026 - val_accuracy: 0.6603\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 491us/step - loss: 0.6301 - accuracy: 0.7774 - val_loss: 0.8897 - val_accuracy: 0.6699\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 420us/step - loss: 0.6231 - accuracy: 0.7785 - val_loss: 0.9122 - val_accuracy: 0.6699\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 420us/step - loss: 0.6122 - accuracy: 0.7796 - val_loss: 0.8866 - val_accuracy: 0.6794\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 418us/step - loss: 0.6110 - accuracy: 0.7822 - val_loss: 0.8792 - val_accuracy: 0.6746\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 428us/step - loss: 0.6006 - accuracy: 0.7870 - val_loss: 0.9200 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 432us/step - loss: 0.5955 - accuracy: 0.7817 - val_loss: 0.9212 - val_accuracy: 0.6603\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 461us/step - loss: 0.6085 - accuracy: 0.7806 - val_loss: 0.8690 - val_accuracy: 0.6938\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 428us/step - loss: 0.5901 - accuracy: 0.7822 - val_loss: 0.8782 - val_accuracy: 0.6746\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 468us/step - loss: 0.5704 - accuracy: 0.7907 - val_loss: 0.8551 - val_accuracy: 0.6938\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 472us/step - loss: 0.5701 - accuracy: 0.7913 - val_loss: 0.9055 - val_accuracy: 0.6842\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 467us/step - loss: 0.5655 - accuracy: 0.7907 - val_loss: 0.8678 - val_accuracy: 0.6938\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 449us/step - loss: 0.5630 - accuracy: 0.7854 - val_loss: 0.8900 - val_accuracy: 0.6890\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 0.5492 - accuracy: 0.7950 - val_loss: 0.9077 - val_accuracy: 0.6842\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 450us/step - loss: 0.5465 - accuracy: 0.7945 - val_loss: 0.9160 - val_accuracy: 0.6842\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 498us/step - loss: 0.5394 - accuracy: 0.7987 - val_loss: 0.8932 - val_accuracy: 0.6938\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 518us/step - loss: 0.5498 - accuracy: 0.7977 - val_loss: 0.9010 - val_accuracy: 0.6890\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 488us/step - loss: 0.5462 - accuracy: 0.7961 - val_loss: 0.9628 - val_accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 8/60 [08:28<51:23, 59.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.2666 - accuracy: 0.5096 - val_loss: 1.2651 - val_accuracy: 0.5120\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1965 - accuracy: 0.5389 - val_loss: 1.2239 - val_accuracy: 0.5215\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1522 - accuracy: 0.5655 - val_loss: 1.2183 - val_accuracy: 0.4737\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1245 - accuracy: 0.5809 - val_loss: 1.1542 - val_accuracy: 0.5742\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0958 - accuracy: 0.5990 - val_loss: 1.1504 - val_accuracy: 0.5502\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0671 - accuracy: 0.6305 - val_loss: 1.0919 - val_accuracy: 0.6268\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0382 - accuracy: 0.6528 - val_loss: 1.0944 - val_accuracy: 0.6029\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0224 - accuracy: 0.6454 - val_loss: 1.0533 - val_accuracy: 0.6220\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0015 - accuracy: 0.6544 - val_loss: 1.0930 - val_accuracy: 0.5885\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9820 - accuracy: 0.6581 - val_loss: 1.0903 - val_accuracy: 0.5694\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9820 - accuracy: 0.6496 - val_loss: 1.0272 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9557 - accuracy: 0.6571 - val_loss: 0.9721 - val_accuracy: 0.6699\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9334 - accuracy: 0.6667 - val_loss: 0.9924 - val_accuracy: 0.6411\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9259 - accuracy: 0.6725 - val_loss: 1.0549 - val_accuracy: 0.6029\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9135 - accuracy: 0.6741 - val_loss: 1.0186 - val_accuracy: 0.6172\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8831 - accuracy: 0.6906 - val_loss: 1.0546 - val_accuracy: 0.5981\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8968 - accuracy: 0.6773 - val_loss: 1.0470 - val_accuracy: 0.5837\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8724 - accuracy: 0.6858 - val_loss: 0.9989 - val_accuracy: 0.6172\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8730 - accuracy: 0.6917 - val_loss: 0.9325 - val_accuracy: 0.6651\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8468 - accuracy: 0.6928 - val_loss: 0.9941 - val_accuracy: 0.6172\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8293 - accuracy: 0.7061 - val_loss: 0.9634 - val_accuracy: 0.6268\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7985 - accuracy: 0.7215 - val_loss: 0.9466 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8127 - accuracy: 0.7045 - val_loss: 0.9204 - val_accuracy: 0.6507\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7849 - accuracy: 0.7204 - val_loss: 0.9377 - val_accuracy: 0.6603\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7635 - accuracy: 0.7348 - val_loss: 0.9453 - val_accuracy: 0.6268\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7581 - accuracy: 0.7322 - val_loss: 0.9407 - val_accuracy: 0.6316\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7579 - accuracy: 0.7247 - val_loss: 0.9495 - val_accuracy: 0.6459\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7520 - accuracy: 0.7327 - val_loss: 0.8922 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7347 - accuracy: 0.7386 - val_loss: 0.8790 - val_accuracy: 0.6651\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7170 - accuracy: 0.7428 - val_loss: 0.9103 - val_accuracy: 0.6364\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7429 - accuracy: 0.7306 - val_loss: 0.9281 - val_accuracy: 0.6507\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 5s 2ms/step - loss: 0.6960 - accuracy: 0.7508 - val_loss: 0.9020 - val_accuracy: 0.6459\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.7189 - accuracy: 0.7417 - val_loss: 0.9419 - val_accuracy: 0.6364\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7177 - accuracy: 0.7396 - val_loss: 0.8611 - val_accuracy: 0.6842\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7006 - accuracy: 0.7348 - val_loss: 0.9108 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.6860 - accuracy: 0.7577 - val_loss: 0.9141 - val_accuracy: 0.6459\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.6587 - accuracy: 0.7604 - val_loss: 0.9344 - val_accuracy: 0.6555\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.6557 - accuracy: 0.7588 - val_loss: 0.9094 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6450 - accuracy: 0.7705 - val_loss: 0.9003 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6516 - accuracy: 0.7742 - val_loss: 0.9542 - val_accuracy: 0.6507\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6445 - accuracy: 0.7646 - val_loss: 0.9520 - val_accuracy: 0.6507\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6233 - accuracy: 0.7806 - val_loss: 0.9042 - val_accuracy: 0.6651\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6128 - accuracy: 0.7817 - val_loss: 0.9305 - val_accuracy: 0.6555\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6196 - accuracy: 0.7796 - val_loss: 0.9561 - val_accuracy: 0.6651\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6130 - accuracy: 0.7859 - val_loss: 0.9215 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6143 - accuracy: 0.7812 - val_loss: 0.9555 - val_accuracy: 0.6651\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6167 - accuracy: 0.7796 - val_loss: 0.9493 - val_accuracy: 0.6459\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.5857 - accuracy: 0.7907 - val_loss: 0.9086 - val_accuracy: 0.6699\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.5955 - accuracy: 0.7865 - val_loss: 0.9305 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.5827 - accuracy: 0.7865 - val_loss: 0.9414 - val_accuracy: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 9/60 [11:07<1:15:51, 89.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.3294 - accuracy: 0.3866 - val_loss: 1.3287 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 332us/step - loss: 1.2720 - accuracy: 0.4782 - val_loss: 1.2985 - val_accuracy: 0.4019\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 460us/step - loss: 1.2227 - accuracy: 0.5032 - val_loss: 1.2617 - val_accuracy: 0.4163\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 459us/step - loss: 1.1860 - accuracy: 0.5197 - val_loss: 1.2239 - val_accuracy: 0.4641\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 242us/step - loss: 1.1487 - accuracy: 0.5575 - val_loss: 1.1815 - val_accuracy: 0.5024\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 404us/step - loss: 1.1139 - accuracy: 0.5836 - val_loss: 1.1621 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 578us/step - loss: 1.0916 - accuracy: 0.5889 - val_loss: 1.1265 - val_accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 402us/step - loss: 1.0701 - accuracy: 0.5895 - val_loss: 1.0923 - val_accuracy: 0.5598\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 360us/step - loss: 1.0399 - accuracy: 0.6097 - val_loss: 1.0854 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 324us/step - loss: 1.0252 - accuracy: 0.6177 - val_loss: 1.0721 - val_accuracy: 0.5694\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 1.0191 - accuracy: 0.6060 - val_loss: 1.0717 - val_accuracy: 0.5789\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 1.0128 - accuracy: 0.6118 - val_loss: 1.0661 - val_accuracy: 0.5598\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 321us/step - loss: 0.9922 - accuracy: 0.6262 - val_loss: 1.0610 - val_accuracy: 0.5646\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 503us/step - loss: 0.9835 - accuracy: 0.6235 - val_loss: 1.0652 - val_accuracy: 0.5550\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 321us/step - loss: 0.9662 - accuracy: 0.6214 - val_loss: 1.0607 - val_accuracy: 0.5646\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 336us/step - loss: 0.9793 - accuracy: 0.6134 - val_loss: 1.0526 - val_accuracy: 0.5598\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.9644 - accuracy: 0.6257 - val_loss: 1.0488 - val_accuracy: 0.5550\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 266us/step - loss: 0.9508 - accuracy: 0.6315 - val_loss: 1.0538 - val_accuracy: 0.5502\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 0.9304 - accuracy: 0.6305 - val_loss: 1.0470 - val_accuracy: 0.5502\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 393us/step - loss: 0.9266 - accuracy: 0.6358 - val_loss: 1.0455 - val_accuracy: 0.5550\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 371us/step - loss: 0.9263 - accuracy: 0.6358 - val_loss: 1.0459 - val_accuracy: 0.5455\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 395us/step - loss: 0.9112 - accuracy: 0.6443 - val_loss: 1.0369 - val_accuracy: 0.5455\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 387us/step - loss: 0.8868 - accuracy: 0.6672 - val_loss: 1.0352 - val_accuracy: 0.5789\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.8882 - accuracy: 0.6629 - val_loss: 1.0333 - val_accuracy: 0.5789\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 333us/step - loss: 0.8729 - accuracy: 0.6832 - val_loss: 1.0265 - val_accuracy: 0.5789\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 374us/step - loss: 0.8737 - accuracy: 0.6816 - val_loss: 1.0206 - val_accuracy: 0.5885\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 382us/step - loss: 0.8592 - accuracy: 0.6944 - val_loss: 1.0049 - val_accuracy: 0.6029\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.8509 - accuracy: 0.6970 - val_loss: 1.0072 - val_accuracy: 0.6029\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.8503 - accuracy: 0.6917 - val_loss: 0.9757 - val_accuracy: 0.6268\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8433 - accuracy: 0.6965 - val_loss: 0.9640 - val_accuracy: 0.6220\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 338us/step - loss: 0.8105 - accuracy: 0.7135 - val_loss: 0.9734 - val_accuracy: 0.6124\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.8296 - accuracy: 0.7013 - val_loss: 0.9728 - val_accuracy: 0.6077\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 433us/step - loss: 0.8202 - accuracy: 0.6991 - val_loss: 0.9569 - val_accuracy: 0.6268\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 363us/step - loss: 0.8145 - accuracy: 0.7055 - val_loss: 0.9493 - val_accuracy: 0.6268\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 571us/step - loss: 0.7920 - accuracy: 0.7109 - val_loss: 0.9420 - val_accuracy: 0.6268\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 478us/step - loss: 0.7961 - accuracy: 0.7098 - val_loss: 0.9389 - val_accuracy: 0.6411\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 266us/step - loss: 0.7868 - accuracy: 0.7135 - val_loss: 0.9291 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.7836 - accuracy: 0.7119 - val_loss: 0.9085 - val_accuracy: 0.6794\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.7830 - accuracy: 0.7210 - val_loss: 0.9090 - val_accuracy: 0.6603\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.7852 - accuracy: 0.7050 - val_loss: 0.8912 - val_accuracy: 0.6603\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.7765 - accuracy: 0.7098 - val_loss: 0.8982 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.7717 - accuracy: 0.7157 - val_loss: 0.9020 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.7617 - accuracy: 0.7178 - val_loss: 0.9004 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 0.7652 - accuracy: 0.7188 - val_loss: 0.8966 - val_accuracy: 0.6603\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.7504 - accuracy: 0.7316 - val_loss: 0.9090 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.7476 - accuracy: 0.7220 - val_loss: 0.8968 - val_accuracy: 0.6603\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.7347 - accuracy: 0.7231 - val_loss: 0.8850 - val_accuracy: 0.6651\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.7461 - accuracy: 0.7295 - val_loss: 0.8744 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.7384 - accuracy: 0.7231 - val_loss: 0.8726 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 0.7203 - accuracy: 0.7359 - val_loss: 0.8614 - val_accuracy: 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10/60 [11:43<1:00:56, 73.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 902us/step - loss: 1.2863 - accuracy: 0.4542 - val_loss: 1.3052 - val_accuracy: 0.4067\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 457us/step - loss: 1.1694 - accuracy: 0.5719 - val_loss: 1.2208 - val_accuracy: 0.5598\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 1.1120 - accuracy: 0.5990 - val_loss: 1.1499 - val_accuracy: 0.5550\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 433us/step - loss: 1.0792 - accuracy: 0.6070 - val_loss: 1.1025 - val_accuracy: 0.5981\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 462us/step - loss: 1.0521 - accuracy: 0.6145 - val_loss: 1.1110 - val_accuracy: 0.5455\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 504us/step - loss: 1.0436 - accuracy: 0.6017 - val_loss: 1.0644 - val_accuracy: 0.5981\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 436us/step - loss: 1.0152 - accuracy: 0.6044 - val_loss: 1.0652 - val_accuracy: 0.5789\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 543us/step - loss: 0.9930 - accuracy: 0.6193 - val_loss: 1.0269 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 643us/step - loss: 0.9750 - accuracy: 0.6289 - val_loss: 1.0262 - val_accuracy: 0.6029\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 670us/step - loss: 0.9613 - accuracy: 0.6390 - val_loss: 1.0261 - val_accuracy: 0.6268\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.9388 - accuracy: 0.6773 - val_loss: 1.0129 - val_accuracy: 0.6268\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 435us/step - loss: 0.9271 - accuracy: 0.6715 - val_loss: 0.9798 - val_accuracy: 0.6459\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 435us/step - loss: 0.8986 - accuracy: 0.6832 - val_loss: 0.9520 - val_accuracy: 0.6555\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.8856 - accuracy: 0.6944 - val_loss: 0.9446 - val_accuracy: 0.6555\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 428us/step - loss: 0.8726 - accuracy: 0.7039 - val_loss: 0.9624 - val_accuracy: 0.6507\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 432us/step - loss: 0.8594 - accuracy: 0.7114 - val_loss: 0.9448 - val_accuracy: 0.6459\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 408us/step - loss: 0.8410 - accuracy: 0.7135 - val_loss: 0.9279 - val_accuracy: 0.6603\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 407us/step - loss: 0.8338 - accuracy: 0.7061 - val_loss: 0.9506 - val_accuracy: 0.6699\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.8245 - accuracy: 0.7114 - val_loss: 0.9108 - val_accuracy: 0.6603\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 432us/step - loss: 0.8047 - accuracy: 0.7247 - val_loss: 0.9128 - val_accuracy: 0.6603\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.8061 - accuracy: 0.7194 - val_loss: 0.9334 - val_accuracy: 0.6555\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 432us/step - loss: 0.7850 - accuracy: 0.7311 - val_loss: 0.9425 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.7644 - accuracy: 0.7391 - val_loss: 0.8874 - val_accuracy: 0.6603\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.7568 - accuracy: 0.7375 - val_loss: 0.9130 - val_accuracy: 0.6411\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 445us/step - loss: 0.7557 - accuracy: 0.7401 - val_loss: 0.8876 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 439us/step - loss: 0.7357 - accuracy: 0.7471 - val_loss: 0.8958 - val_accuracy: 0.6459\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 425us/step - loss: 0.7143 - accuracy: 0.7561 - val_loss: 0.8885 - val_accuracy: 0.6603\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.7200 - accuracy: 0.7465 - val_loss: 0.8847 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.6997 - accuracy: 0.7508 - val_loss: 0.8601 - val_accuracy: 0.6507\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 439us/step - loss: 0.6921 - accuracy: 0.7487 - val_loss: 0.8509 - val_accuracy: 0.6746\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 406us/step - loss: 0.6742 - accuracy: 0.7636 - val_loss: 0.8676 - val_accuracy: 0.6651\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 418us/step - loss: 0.6691 - accuracy: 0.7710 - val_loss: 0.8941 - val_accuracy: 0.6603\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 414us/step - loss: 0.6494 - accuracy: 0.7812 - val_loss: 0.9069 - val_accuracy: 0.6459\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 421us/step - loss: 0.6514 - accuracy: 0.7726 - val_loss: 0.8516 - val_accuracy: 0.6411\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.6317 - accuracy: 0.7790 - val_loss: 0.8510 - val_accuracy: 0.6699\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 421us/step - loss: 0.6500 - accuracy: 0.7668 - val_loss: 0.8612 - val_accuracy: 0.6603\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 422us/step - loss: 0.6269 - accuracy: 0.7796 - val_loss: 0.8799 - val_accuracy: 0.6603\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 411us/step - loss: 0.6244 - accuracy: 0.7726 - val_loss: 0.8648 - val_accuracy: 0.6651\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 397us/step - loss: 0.6188 - accuracy: 0.7769 - val_loss: 0.8881 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.6282 - accuracy: 0.7742 - val_loss: 0.8750 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 423us/step - loss: 0.6086 - accuracy: 0.7774 - val_loss: 0.8674 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 419us/step - loss: 0.6002 - accuracy: 0.7806 - val_loss: 0.8972 - val_accuracy: 0.6746\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 376us/step - loss: 0.5859 - accuracy: 0.7891 - val_loss: 0.8622 - val_accuracy: 0.6746\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 378us/step - loss: 0.5777 - accuracy: 0.7827 - val_loss: 0.8596 - val_accuracy: 0.6699\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.5649 - accuracy: 0.7913 - val_loss: 0.8710 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.5650 - accuracy: 0.7923 - val_loss: 0.8751 - val_accuracy: 0.6699\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 427us/step - loss: 0.5619 - accuracy: 0.7961 - val_loss: 0.8747 - val_accuracy: 0.6842\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 402us/step - loss: 0.5601 - accuracy: 0.7929 - val_loss: 0.8516 - val_accuracy: 0.6746\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.5458 - accuracy: 0.8062 - val_loss: 0.8845 - val_accuracy: 0.6603\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 419us/step - loss: 0.5531 - accuracy: 0.8035 - val_loss: 0.9324 - val_accuracy: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 11/60 [12:27<52:39, 64.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2553 - accuracy: 0.5021 - val_loss: 1.2545 - val_accuracy: 0.5407\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1823 - accuracy: 0.5586 - val_loss: 1.1936 - val_accuracy: 0.5120\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1532 - accuracy: 0.5751 - val_loss: 1.1686 - val_accuracy: 0.5359\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1148 - accuracy: 0.5841 - val_loss: 1.1544 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1008 - accuracy: 0.5804 - val_loss: 1.0704 - val_accuracy: 0.5885\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0632 - accuracy: 0.6140 - val_loss: 1.0785 - val_accuracy: 0.5694\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0570 - accuracy: 0.6118 - val_loss: 1.0574 - val_accuracy: 0.5933\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0387 - accuracy: 0.6305 - val_loss: 1.0365 - val_accuracy: 0.5837\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0065 - accuracy: 0.6454 - val_loss: 1.0418 - val_accuracy: 0.5885\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9811 - accuracy: 0.6571 - val_loss: 1.0288 - val_accuracy: 0.5933\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9650 - accuracy: 0.6741 - val_loss: 1.0370 - val_accuracy: 0.6220\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9575 - accuracy: 0.6693 - val_loss: 1.0195 - val_accuracy: 0.5837\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9553 - accuracy: 0.6645 - val_loss: 1.0407 - val_accuracy: 0.5837\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9483 - accuracy: 0.6507 - val_loss: 1.0090 - val_accuracy: 0.5981\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9066 - accuracy: 0.6731 - val_loss: 1.0386 - val_accuracy: 0.5359\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8964 - accuracy: 0.6816 - val_loss: 0.9641 - val_accuracy: 0.6077\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8821 - accuracy: 0.6842 - val_loss: 0.9630 - val_accuracy: 0.5981\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8708 - accuracy: 0.6906 - val_loss: 0.9816 - val_accuracy: 0.6316\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8640 - accuracy: 0.6917 - val_loss: 0.9846 - val_accuracy: 0.5981\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8471 - accuracy: 0.7093 - val_loss: 0.9721 - val_accuracy: 0.6124\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8483 - accuracy: 0.7018 - val_loss: 1.0198 - val_accuracy: 0.5789\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8163 - accuracy: 0.7252 - val_loss: 0.9248 - val_accuracy: 0.6411\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8069 - accuracy: 0.7098 - val_loss: 0.9584 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7999 - accuracy: 0.7167 - val_loss: 0.9418 - val_accuracy: 0.6124\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7845 - accuracy: 0.7327 - val_loss: 0.9289 - val_accuracy: 0.6459\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7805 - accuracy: 0.7220 - val_loss: 0.8809 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7787 - accuracy: 0.7279 - val_loss: 0.8711 - val_accuracy: 0.6507\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7504 - accuracy: 0.7407 - val_loss: 0.8426 - val_accuracy: 0.6746\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7432 - accuracy: 0.7348 - val_loss: 0.8689 - val_accuracy: 0.6555\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7410 - accuracy: 0.7433 - val_loss: 0.8975 - val_accuracy: 0.6411\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7505 - accuracy: 0.7290 - val_loss: 0.9138 - val_accuracy: 0.6459\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7258 - accuracy: 0.7449 - val_loss: 0.8521 - val_accuracy: 0.6507\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7138 - accuracy: 0.7487 - val_loss: 0.8515 - val_accuracy: 0.6651\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7007 - accuracy: 0.7519 - val_loss: 0.8866 - val_accuracy: 0.6507\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7102 - accuracy: 0.7439 - val_loss: 0.8366 - val_accuracy: 0.6746\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6839 - accuracy: 0.7540 - val_loss: 0.9453 - val_accuracy: 0.6364\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6729 - accuracy: 0.7620 - val_loss: 0.9202 - val_accuracy: 0.6364\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6991 - accuracy: 0.7433 - val_loss: 0.8307 - val_accuracy: 0.6603\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6780 - accuracy: 0.7561 - val_loss: 0.8362 - val_accuracy: 0.6603\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6567 - accuracy: 0.7710 - val_loss: 0.8269 - val_accuracy: 0.6938\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6475 - accuracy: 0.7668 - val_loss: 0.8013 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6394 - accuracy: 0.7684 - val_loss: 0.8446 - val_accuracy: 0.6651\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6393 - accuracy: 0.7684 - val_loss: 0.9311 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.7662 - val_loss: 0.9456 - val_accuracy: 0.6411\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6391 - accuracy: 0.7678 - val_loss: 0.8750 - val_accuracy: 0.6746\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6101 - accuracy: 0.7822 - val_loss: 0.8500 - val_accuracy: 0.6746\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6094 - accuracy: 0.7774 - val_loss: 0.8934 - val_accuracy: 0.6651\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6230 - accuracy: 0.7636 - val_loss: 0.9120 - val_accuracy: 0.6268\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6040 - accuracy: 0.7758 - val_loss: 0.8608 - val_accuracy: 0.6746\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.5837 - accuracy: 0.7907 - val_loss: 0.8774 - val_accuracy: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 12/60 [14:20<1:03:09, 78.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 757us/step - loss: 1.3850 - accuracy: 0.2721 - val_loss: 1.3625 - val_accuracy: 0.3876\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 325us/step - loss: 1.2998 - accuracy: 0.4654 - val_loss: 1.3166 - val_accuracy: 0.4115\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 1.2260 - accuracy: 0.5101 - val_loss: 1.2581 - val_accuracy: 0.4641\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 1.1721 - accuracy: 0.5245 - val_loss: 1.2043 - val_accuracy: 0.5120\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 1.1318 - accuracy: 0.5426 - val_loss: 1.1680 - val_accuracy: 0.5167\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 1.1058 - accuracy: 0.5580 - val_loss: 1.1330 - val_accuracy: 0.5407\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 1.0922 - accuracy: 0.5628 - val_loss: 1.1066 - val_accuracy: 0.5789\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 1.0712 - accuracy: 0.5863 - val_loss: 1.0952 - val_accuracy: 0.5550\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 1.0594 - accuracy: 0.5809 - val_loss: 1.0784 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 1.0280 - accuracy: 0.6171 - val_loss: 1.0804 - val_accuracy: 0.5789\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 1.0179 - accuracy: 0.6214 - val_loss: 1.0570 - val_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.9992 - accuracy: 0.6273 - val_loss: 1.0436 - val_accuracy: 0.5885\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.9809 - accuracy: 0.6470 - val_loss: 1.0277 - val_accuracy: 0.6507\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.9716 - accuracy: 0.6470 - val_loss: 1.0257 - val_accuracy: 0.6124\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.9527 - accuracy: 0.6539 - val_loss: 1.0130 - val_accuracy: 0.6459\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.9446 - accuracy: 0.6635 - val_loss: 1.0111 - val_accuracy: 0.6172\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.9266 - accuracy: 0.6747 - val_loss: 0.9887 - val_accuracy: 0.6268\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.9307 - accuracy: 0.6677 - val_loss: 0.9777 - val_accuracy: 0.6459\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.9056 - accuracy: 0.6709 - val_loss: 0.9536 - val_accuracy: 0.6699\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.9046 - accuracy: 0.6677 - val_loss: 0.9872 - val_accuracy: 0.6268\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.9072 - accuracy: 0.6645 - val_loss: 0.9770 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8937 - accuracy: 0.6677 - val_loss: 0.9626 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 0.8750 - accuracy: 0.6816 - val_loss: 0.9533 - val_accuracy: 0.6603\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8725 - accuracy: 0.6864 - val_loss: 0.9382 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.8648 - accuracy: 0.6901 - val_loss: 0.9293 - val_accuracy: 0.6746\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.8630 - accuracy: 0.6757 - val_loss: 0.9320 - val_accuracy: 0.6603\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.8568 - accuracy: 0.6954 - val_loss: 0.9352 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8450 - accuracy: 0.6960 - val_loss: 0.9382 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8236 - accuracy: 0.7055 - val_loss: 0.9232 - val_accuracy: 0.6699\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.8238 - accuracy: 0.7077 - val_loss: 0.9184 - val_accuracy: 0.6459\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.8282 - accuracy: 0.7055 - val_loss: 0.9255 - val_accuracy: 0.6651\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 0.8349 - accuracy: 0.6922 - val_loss: 0.9151 - val_accuracy: 0.6411\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.8047 - accuracy: 0.7018 - val_loss: 0.9158 - val_accuracy: 0.6746\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.8169 - accuracy: 0.6928 - val_loss: 0.9038 - val_accuracy: 0.6842\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.8049 - accuracy: 0.7151 - val_loss: 0.9039 - val_accuracy: 0.6986\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 0.8247 - accuracy: 0.6960 - val_loss: 0.9062 - val_accuracy: 0.6651\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.8216 - accuracy: 0.6991 - val_loss: 0.9003 - val_accuracy: 0.6699\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.7951 - accuracy: 0.7066 - val_loss: 0.9065 - val_accuracy: 0.6507\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 0.8085 - accuracy: 0.7103 - val_loss: 0.9018 - val_accuracy: 0.6603\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.7948 - accuracy: 0.7157 - val_loss: 0.9084 - val_accuracy: 0.6603\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.7782 - accuracy: 0.7210 - val_loss: 0.9115 - val_accuracy: 0.6411\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 0.7864 - accuracy: 0.7098 - val_loss: 0.9182 - val_accuracy: 0.6507\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.7845 - accuracy: 0.7109 - val_loss: 0.9019 - val_accuracy: 0.6794\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.7792 - accuracy: 0.7210 - val_loss: 0.9118 - val_accuracy: 0.6603\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.7802 - accuracy: 0.7188 - val_loss: 0.8985 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.7618 - accuracy: 0.7226 - val_loss: 0.8957 - val_accuracy: 0.6651\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.7605 - accuracy: 0.7215 - val_loss: 0.8949 - val_accuracy: 0.6651\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.7876 - accuracy: 0.7039 - val_loss: 0.8943 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 363us/step - loss: 0.7719 - accuracy: 0.7173 - val_loss: 0.8758 - val_accuracy: 0.6603\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 346us/step - loss: 0.7666 - accuracy: 0.7119 - val_loss: 0.8902 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 13/60 [14:47<49:48, 63.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 8s 4ms/step - loss: 1.2598 - accuracy: 0.4920 - val_loss: 1.2798 - val_accuracy: 0.4833\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 607us/step - loss: 1.1574 - accuracy: 0.5682 - val_loss: 1.2048 - val_accuracy: 0.5311\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 625us/step - loss: 1.1092 - accuracy: 0.5889 - val_loss: 1.1538 - val_accuracy: 0.5646\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 656us/step - loss: 1.0779 - accuracy: 0.5900 - val_loss: 1.1036 - val_accuracy: 0.5837\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 650us/step - loss: 1.0479 - accuracy: 0.6044 - val_loss: 1.0540 - val_accuracy: 0.5885\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 640us/step - loss: 1.0430 - accuracy: 0.5873 - val_loss: 1.0579 - val_accuracy: 0.5694\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 756us/step - loss: 1.0161 - accuracy: 0.5985 - val_loss: 1.0574 - val_accuracy: 0.5502\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 556us/step - loss: 0.9887 - accuracy: 0.6129 - val_loss: 1.0281 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 553us/step - loss: 0.9668 - accuracy: 0.6177 - val_loss: 1.0196 - val_accuracy: 0.6077\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 535us/step - loss: 0.9631 - accuracy: 0.6342 - val_loss: 0.9888 - val_accuracy: 0.6507\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 641us/step - loss: 0.9482 - accuracy: 0.6576 - val_loss: 0.9874 - val_accuracy: 0.6316\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 556us/step - loss: 0.9359 - accuracy: 0.6672 - val_loss: 0.9586 - val_accuracy: 0.6603\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 595us/step - loss: 0.9271 - accuracy: 0.6613 - val_loss: 0.9726 - val_accuracy: 0.6459\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 505us/step - loss: 0.9204 - accuracy: 0.6688 - val_loss: 0.9674 - val_accuracy: 0.6268\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 563us/step - loss: 0.8854 - accuracy: 0.6837 - val_loss: 0.9268 - val_accuracy: 0.6651\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 533us/step - loss: 0.8753 - accuracy: 0.6874 - val_loss: 0.9294 - val_accuracy: 0.6651\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 526us/step - loss: 0.8655 - accuracy: 0.6970 - val_loss: 0.9311 - val_accuracy: 0.6316\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 578us/step - loss: 0.8493 - accuracy: 0.6949 - val_loss: 0.9227 - val_accuracy: 0.6603\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 526us/step - loss: 0.8489 - accuracy: 0.7055 - val_loss: 0.9031 - val_accuracy: 0.6746\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 502us/step - loss: 0.8195 - accuracy: 0.7135 - val_loss: 0.8988 - val_accuracy: 0.6603\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 542us/step - loss: 0.8349 - accuracy: 0.6997 - val_loss: 0.9115 - val_accuracy: 0.6555\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 532us/step - loss: 0.8081 - accuracy: 0.7114 - val_loss: 0.8940 - val_accuracy: 0.6794\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 628us/step - loss: 0.7934 - accuracy: 0.7268 - val_loss: 0.9103 - val_accuracy: 0.6651\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 865us/step - loss: 0.8042 - accuracy: 0.7077 - val_loss: 0.9074 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 502us/step - loss: 0.7715 - accuracy: 0.7300 - val_loss: 0.8808 - val_accuracy: 0.6603\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 564us/step - loss: 0.7633 - accuracy: 0.7338 - val_loss: 0.8870 - val_accuracy: 0.6651\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 708us/step - loss: 0.7474 - accuracy: 0.7375 - val_loss: 0.8756 - val_accuracy: 0.6651\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 583us/step - loss: 0.7751 - accuracy: 0.7263 - val_loss: 0.8889 - val_accuracy: 0.6699\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 574us/step - loss: 0.7411 - accuracy: 0.7364 - val_loss: 0.8496 - val_accuracy: 0.6794\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 587us/step - loss: 0.7451 - accuracy: 0.7231 - val_loss: 0.8390 - val_accuracy: 0.6842\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 544us/step - loss: 0.7186 - accuracy: 0.7455 - val_loss: 0.9020 - val_accuracy: 0.6507\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 527us/step - loss: 0.7332 - accuracy: 0.7439 - val_loss: 0.8762 - val_accuracy: 0.6411\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 606us/step - loss: 0.7075 - accuracy: 0.7588 - val_loss: 0.9035 - val_accuracy: 0.6411\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 576us/step - loss: 0.7048 - accuracy: 0.7412 - val_loss: 0.8502 - val_accuracy: 0.6699\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 484us/step - loss: 0.7024 - accuracy: 0.7524 - val_loss: 0.8662 - val_accuracy: 0.6699\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 464us/step - loss: 0.7026 - accuracy: 0.7487 - val_loss: 0.8390 - val_accuracy: 0.6890\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 691us/step - loss: 0.6900 - accuracy: 0.7551 - val_loss: 0.8791 - val_accuracy: 0.6651\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 664us/step - loss: 0.6745 - accuracy: 0.7604 - val_loss: 0.8473 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 609us/step - loss: 0.6713 - accuracy: 0.7630 - val_loss: 0.8513 - val_accuracy: 0.6746\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 544us/step - loss: 0.6620 - accuracy: 0.7668 - val_loss: 0.8241 - val_accuracy: 0.6842\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 481us/step - loss: 0.6557 - accuracy: 0.7641 - val_loss: 0.8823 - val_accuracy: 0.6555\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 492us/step - loss: 0.6485 - accuracy: 0.7609 - val_loss: 0.8818 - val_accuracy: 0.6603\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 494us/step - loss: 0.6448 - accuracy: 0.7662 - val_loss: 0.8498 - val_accuracy: 0.6746\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 486us/step - loss: 0.6278 - accuracy: 0.7705 - val_loss: 0.8236 - val_accuracy: 0.6938\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 490us/step - loss: 0.6537 - accuracy: 0.7641 - val_loss: 0.8445 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 521us/step - loss: 0.6175 - accuracy: 0.7748 - val_loss: 0.8528 - val_accuracy: 0.6746\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 483us/step - loss: 0.6251 - accuracy: 0.7657 - val_loss: 0.8268 - val_accuracy: 0.6842\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 482us/step - loss: 0.6116 - accuracy: 0.7726 - val_loss: 0.8494 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 529us/step - loss: 0.6091 - accuracy: 0.7838 - val_loss: 0.8821 - val_accuracy: 0.6411\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 496us/step - loss: 0.6154 - accuracy: 0.7652 - val_loss: 0.8523 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 14/60 [16:06<52:07, 67.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2971 - accuracy: 0.3908 - val_loss: 1.2962 - val_accuracy: 0.5694\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.2224 - accuracy: 0.5607 - val_loss: 1.2277 - val_accuracy: 0.5550\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1862 - accuracy: 0.5820 - val_loss: 1.1838 - val_accuracy: 0.5885\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1405 - accuracy: 0.6012 - val_loss: 1.2478 - val_accuracy: 0.4402\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1143 - accuracy: 0.6150 - val_loss: 1.1250 - val_accuracy: 0.6124\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0959 - accuracy: 0.6278 - val_loss: 1.1055 - val_accuracy: 0.6077\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0726 - accuracy: 0.6310 - val_loss: 1.1118 - val_accuracy: 0.5885\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0689 - accuracy: 0.6283 - val_loss: 1.0934 - val_accuracy: 0.6077\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0434 - accuracy: 0.6331 - val_loss: 1.1200 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0216 - accuracy: 0.6486 - val_loss: 1.0217 - val_accuracy: 0.6316\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0161 - accuracy: 0.6384 - val_loss: 1.0464 - val_accuracy: 0.6077\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0114 - accuracy: 0.6438 - val_loss: 1.0149 - val_accuracy: 0.6555\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0057 - accuracy: 0.6358 - val_loss: 1.1174 - val_accuracy: 0.5215\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9832 - accuracy: 0.6544 - val_loss: 1.0097 - val_accuracy: 0.6411\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9573 - accuracy: 0.6683 - val_loss: 1.0725 - val_accuracy: 0.5742\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9642 - accuracy: 0.6480 - val_loss: 0.9971 - val_accuracy: 0.6124\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9402 - accuracy: 0.6672 - val_loss: 0.9555 - val_accuracy: 0.6459\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9252 - accuracy: 0.6715 - val_loss: 1.0014 - val_accuracy: 0.5933\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9290 - accuracy: 0.6667 - val_loss: 0.9869 - val_accuracy: 0.6459\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9071 - accuracy: 0.6709 - val_loss: 0.9277 - val_accuracy: 0.6555\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8943 - accuracy: 0.6752 - val_loss: 0.9887 - val_accuracy: 0.6029\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8848 - accuracy: 0.6869 - val_loss: 0.9747 - val_accuracy: 0.6172\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8676 - accuracy: 0.6949 - val_loss: 0.9997 - val_accuracy: 0.6172\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8689 - accuracy: 0.6821 - val_loss: 0.9808 - val_accuracy: 0.6029\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8561 - accuracy: 0.6880 - val_loss: 0.9867 - val_accuracy: 0.6029\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8191 - accuracy: 0.7125 - val_loss: 0.9609 - val_accuracy: 0.6124\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8120 - accuracy: 0.7130 - val_loss: 0.9301 - val_accuracy: 0.6411\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8256 - accuracy: 0.7018 - val_loss: 0.9306 - val_accuracy: 0.6172\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8152 - accuracy: 0.7055 - val_loss: 0.9815 - val_accuracy: 0.6220\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8225 - accuracy: 0.6991 - val_loss: 0.9599 - val_accuracy: 0.6029\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7967 - accuracy: 0.7178 - val_loss: 0.9694 - val_accuracy: 0.5933\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7751 - accuracy: 0.7199 - val_loss: 0.9033 - val_accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7584 - accuracy: 0.7295 - val_loss: 0.9052 - val_accuracy: 0.6603\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7660 - accuracy: 0.7274 - val_loss: 0.9524 - val_accuracy: 0.6172\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7514 - accuracy: 0.7370 - val_loss: 0.8942 - val_accuracy: 0.6411\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7383 - accuracy: 0.7401 - val_loss: 0.8929 - val_accuracy: 0.6603\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7388 - accuracy: 0.7364 - val_loss: 0.9257 - val_accuracy: 0.6507\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7327 - accuracy: 0.7343 - val_loss: 0.8823 - val_accuracy: 0.6459\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.7364 - val_loss: 0.9120 - val_accuracy: 0.6459\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7021 - accuracy: 0.7439 - val_loss: 0.9149 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6886 - accuracy: 0.7524 - val_loss: 0.8853 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6728 - accuracy: 0.7641 - val_loss: 0.8890 - val_accuracy: 0.6507\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6858 - accuracy: 0.7492 - val_loss: 0.9698 - val_accuracy: 0.6077\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6794 - accuracy: 0.7535 - val_loss: 0.9129 - val_accuracy: 0.6411\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6802 - accuracy: 0.7508 - val_loss: 0.8816 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6609 - accuracy: 0.7662 - val_loss: 0.9367 - val_accuracy: 0.6411\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6600 - accuracy: 0.7609 - val_loss: 0.8982 - val_accuracy: 0.6411\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6248 - accuracy: 0.7710 - val_loss: 0.9072 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6236 - accuracy: 0.7716 - val_loss: 0.8788 - val_accuracy: 0.6507\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6368 - accuracy: 0.7625 - val_loss: 0.8737 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 15/60 [18:07<1:02:58, 83.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 770us/step - loss: 1.3733 - accuracy: 0.3424 - val_loss: 1.3640 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 352us/step - loss: 1.2872 - accuracy: 0.4446 - val_loss: 1.3109 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 356us/step - loss: 1.2354 - accuracy: 0.4505 - val_loss: 1.2581 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 1.1961 - accuracy: 0.4606 - val_loss: 1.2122 - val_accuracy: 0.4019\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 351us/step - loss: 1.1708 - accuracy: 0.4872 - val_loss: 1.1759 - val_accuracy: 0.4689\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 399us/step - loss: 1.1419 - accuracy: 0.5261 - val_loss: 1.1590 - val_accuracy: 0.4928\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 1.1157 - accuracy: 0.5447 - val_loss: 1.1219 - val_accuracy: 0.5694\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 1.1011 - accuracy: 0.5554 - val_loss: 1.0963 - val_accuracy: 0.5885\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 1.0776 - accuracy: 0.5799 - val_loss: 1.0777 - val_accuracy: 0.5981\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 1.0573 - accuracy: 0.5831 - val_loss: 1.0688 - val_accuracy: 0.5550\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 1.0388 - accuracy: 0.5964 - val_loss: 1.0375 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 1.0284 - accuracy: 0.6033 - val_loss: 1.0156 - val_accuracy: 0.6124\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 1.0016 - accuracy: 0.6198 - val_loss: 1.0044 - val_accuracy: 0.6124\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.9927 - accuracy: 0.6134 - val_loss: 0.9929 - val_accuracy: 0.6172\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 304us/step - loss: 0.9705 - accuracy: 0.6278 - val_loss: 0.9862 - val_accuracy: 0.6077\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 0.9565 - accuracy: 0.6475 - val_loss: 0.9767 - val_accuracy: 0.6124\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.9405 - accuracy: 0.6427 - val_loss: 0.9683 - val_accuracy: 0.6172\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.9432 - accuracy: 0.6459 - val_loss: 0.9569 - val_accuracy: 0.6364\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.9201 - accuracy: 0.6603 - val_loss: 0.9502 - val_accuracy: 0.6268\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.9099 - accuracy: 0.6560 - val_loss: 0.9428 - val_accuracy: 0.6316\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 241us/step - loss: 0.8860 - accuracy: 0.6837 - val_loss: 0.9365 - val_accuracy: 0.6220\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 238us/step - loss: 0.8854 - accuracy: 0.6773 - val_loss: 0.9200 - val_accuracy: 0.6220\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.8963 - accuracy: 0.6709 - val_loss: 0.9132 - val_accuracy: 0.6220\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 0.8779 - accuracy: 0.6757 - val_loss: 0.9044 - val_accuracy: 0.6220\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.8658 - accuracy: 0.6864 - val_loss: 0.9060 - val_accuracy: 0.6411\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.8628 - accuracy: 0.6784 - val_loss: 0.9031 - val_accuracy: 0.6268\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.8440 - accuracy: 0.6858 - val_loss: 0.8976 - val_accuracy: 0.6172\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.8636 - accuracy: 0.6709 - val_loss: 0.8944 - val_accuracy: 0.6124\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.8301 - accuracy: 0.6991 - val_loss: 0.8957 - val_accuracy: 0.6268\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.8336 - accuracy: 0.6906 - val_loss: 0.8766 - val_accuracy: 0.6555\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.8360 - accuracy: 0.6789 - val_loss: 0.8744 - val_accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.8361 - accuracy: 0.6842 - val_loss: 0.8776 - val_accuracy: 0.6411\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 0.8261 - accuracy: 0.6832 - val_loss: 0.8706 - val_accuracy: 0.6507\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 248us/step - loss: 0.8307 - accuracy: 0.6890 - val_loss: 0.8674 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.8327 - accuracy: 0.6864 - val_loss: 0.8806 - val_accuracy: 0.6268\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.8156 - accuracy: 0.6922 - val_loss: 0.8710 - val_accuracy: 0.6411\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.8168 - accuracy: 0.6794 - val_loss: 0.8767 - val_accuracy: 0.6364\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.7995 - accuracy: 0.6981 - val_loss: 0.8697 - val_accuracy: 0.6507\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.8115 - accuracy: 0.6922 - val_loss: 0.8665 - val_accuracy: 0.6411\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.8054 - accuracy: 0.6944 - val_loss: 0.8579 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.7921 - accuracy: 0.6997 - val_loss: 0.8437 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.7857 - accuracy: 0.6960 - val_loss: 0.8423 - val_accuracy: 0.6555\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.7886 - accuracy: 0.7002 - val_loss: 0.8413 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 241us/step - loss: 0.7989 - accuracy: 0.6944 - val_loss: 0.8589 - val_accuracy: 0.6124\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.7937 - accuracy: 0.6954 - val_loss: 0.8621 - val_accuracy: 0.6268\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.7845 - accuracy: 0.7023 - val_loss: 0.8451 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 240us/step - loss: 0.7862 - accuracy: 0.7077 - val_loss: 0.8433 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.7802 - accuracy: 0.6981 - val_loss: 0.8440 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.7645 - accuracy: 0.7178 - val_loss: 0.8455 - val_accuracy: 0.6603\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 0.7730 - accuracy: 0.7039 - val_loss: 0.8354 - val_accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 16/60 [18:35<49:15, 67.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 844us/step - loss: 1.2690 - accuracy: 0.4558 - val_loss: 1.2941 - val_accuracy: 0.4019\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 435us/step - loss: 1.1760 - accuracy: 0.5176 - val_loss: 1.2394 - val_accuracy: 0.4880\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 407us/step - loss: 1.1375 - accuracy: 0.5389 - val_loss: 1.1807 - val_accuracy: 0.5072\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 384us/step - loss: 1.1132 - accuracy: 0.5575 - val_loss: 1.1324 - val_accuracy: 0.5455\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 433us/step - loss: 1.0766 - accuracy: 0.5799 - val_loss: 1.1015 - val_accuracy: 0.5981\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 405us/step - loss: 1.0644 - accuracy: 0.5969 - val_loss: 1.0876 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 415us/step - loss: 1.0406 - accuracy: 0.6257 - val_loss: 1.0851 - val_accuracy: 0.6029\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 435us/step - loss: 1.0109 - accuracy: 0.6321 - val_loss: 1.0607 - val_accuracy: 0.6172\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 173s 92ms/step - loss: 0.9986 - accuracy: 0.6353 - val_loss: 1.0445 - val_accuracy: 0.6029\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9899 - accuracy: 0.6321 - val_loss: 1.0473 - val_accuracy: 0.6124\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 697us/step - loss: 0.9687 - accuracy: 0.6512 - val_loss: 1.0306 - val_accuracy: 0.6364\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 662us/step - loss: 0.9542 - accuracy: 0.6555 - val_loss: 1.0403 - val_accuracy: 0.6029\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 508us/step - loss: 0.9352 - accuracy: 0.6651 - val_loss: 1.0012 - val_accuracy: 0.6411\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - -7s -3478us/step - loss: 0.9256 - accuracy: 0.6576 - val_loss: 0.9717 - val_accuracy: 0.6459\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 558us/step - loss: 0.9195 - accuracy: 0.6661 - val_loss: 0.9843 - val_accuracy: 0.6316\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 526us/step - loss: 0.9050 - accuracy: 0.6704 - val_loss: 0.9514 - val_accuracy: 0.6459\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 460us/step - loss: 0.8927 - accuracy: 0.6842 - val_loss: 0.9437 - val_accuracy: 0.6651\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 521us/step - loss: 0.8918 - accuracy: 0.6747 - val_loss: 0.9438 - val_accuracy: 0.6555\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 556us/step - loss: 0.8696 - accuracy: 0.6789 - val_loss: 0.9091 - val_accuracy: 0.6603\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 546us/step - loss: 0.8486 - accuracy: 0.6922 - val_loss: 0.9246 - val_accuracy: 0.6411\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 494us/step - loss: 0.8344 - accuracy: 0.6965 - val_loss: 0.8852 - val_accuracy: 0.6746\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 615us/step - loss: 0.8457 - accuracy: 0.6890 - val_loss: 0.9330 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 519us/step - loss: 0.8176 - accuracy: 0.6970 - val_loss: 0.9072 - val_accuracy: 0.6555\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 460us/step - loss: 0.8226 - accuracy: 0.7013 - val_loss: 0.9268 - val_accuracy: 0.6459\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 490us/step - loss: 0.8087 - accuracy: 0.7077 - val_loss: 0.8624 - val_accuracy: 0.6699\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 540us/step - loss: 0.8027 - accuracy: 0.6981 - val_loss: 0.8758 - val_accuracy: 0.6699\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 421us/step - loss: 0.7752 - accuracy: 0.7226 - val_loss: 0.8816 - val_accuracy: 0.6746\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 418us/step - loss: 0.7710 - accuracy: 0.7146 - val_loss: 0.8895 - val_accuracy: 0.6699\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 418us/step - loss: 0.7572 - accuracy: 0.7231 - val_loss: 0.8606 - val_accuracy: 0.6699\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.7515 - accuracy: 0.7290 - val_loss: 0.8660 - val_accuracy: 0.6699\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 424us/step - loss: 0.7441 - accuracy: 0.7258 - val_loss: 0.8660 - val_accuracy: 0.6411\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 449us/step - loss: 0.7305 - accuracy: 0.7338 - val_loss: 0.8513 - val_accuracy: 0.6794\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 418us/step - loss: 0.7362 - accuracy: 0.7236 - val_loss: 0.8594 - val_accuracy: 0.6699\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 435us/step - loss: 0.7214 - accuracy: 0.7364 - val_loss: 0.8501 - val_accuracy: 0.6699\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 422us/step - loss: 0.7210 - accuracy: 0.7311 - val_loss: 0.8463 - val_accuracy: 0.6746\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 410us/step - loss: 0.7007 - accuracy: 0.7428 - val_loss: 0.8498 - val_accuracy: 0.6699\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 420us/step - loss: 0.7048 - accuracy: 0.7407 - val_loss: 0.8881 - val_accuracy: 0.6746\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 413us/step - loss: 0.7105 - accuracy: 0.7359 - val_loss: 0.8322 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 423us/step - loss: 0.6751 - accuracy: 0.7551 - val_loss: 0.8549 - val_accuracy: 0.6746\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 415us/step - loss: 0.6801 - accuracy: 0.7551 - val_loss: 0.8367 - val_accuracy: 0.6842\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 417us/step - loss: 0.6871 - accuracy: 0.7433 - val_loss: 0.8247 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 417us/step - loss: 0.6607 - accuracy: 0.7577 - val_loss: 0.8281 - val_accuracy: 0.6794\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.6632 - accuracy: 0.7487 - val_loss: 0.8433 - val_accuracy: 0.6794\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 608us/step - loss: 0.6488 - accuracy: 0.7630 - val_loss: 0.8337 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 654us/step - loss: 0.6554 - accuracy: 0.7444 - val_loss: 0.8374 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 560us/step - loss: 0.6395 - accuracy: 0.7455 - val_loss: 0.8438 - val_accuracy: 0.6746\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 487us/step - loss: 0.6389 - accuracy: 0.7583 - val_loss: 0.7991 - val_accuracy: 0.6746\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 500us/step - loss: 0.6271 - accuracy: 0.7588 - val_loss: 0.8981 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 471us/step - loss: 0.6495 - accuracy: 0.7449 - val_loss: 0.8232 - val_accuracy: 0.6746\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 429us/step - loss: 0.6173 - accuracy: 0.7662 - val_loss: 0.8380 - val_accuracy: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 17/60 [22:08<1:19:32, 110.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.3331 - accuracy: 0.3530 - val_loss: 1.3506 - val_accuracy: 0.4067\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.2527 - accuracy: 0.5346 - val_loss: 1.2647 - val_accuracy: 0.5981\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1882 - accuracy: 0.5969 - val_loss: 1.2046 - val_accuracy: 0.5933\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.1617 - accuracy: 0.5927 - val_loss: 1.1852 - val_accuracy: 0.5789\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1141 - accuracy: 0.6241 - val_loss: 1.1183 - val_accuracy: 0.5885\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1009 - accuracy: 0.6081 - val_loss: 1.1123 - val_accuracy: 0.6077\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0879 - accuracy: 0.6124 - val_loss: 1.0855 - val_accuracy: 0.6077\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0589 - accuracy: 0.6310 - val_loss: 1.0836 - val_accuracy: 0.5933\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0397 - accuracy: 0.6406 - val_loss: 1.1069 - val_accuracy: 0.5742\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0153 - accuracy: 0.6331 - val_loss: 1.0670 - val_accuracy: 0.5933\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 5s 2ms/step - loss: 1.0129 - accuracy: 0.6331 - val_loss: 1.0419 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9965 - accuracy: 0.6379 - val_loss: 1.0440 - val_accuracy: 0.5837\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9798 - accuracy: 0.6347 - val_loss: 0.9943 - val_accuracy: 0.6411\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9781 - accuracy: 0.6390 - val_loss: 1.0375 - val_accuracy: 0.6077\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9670 - accuracy: 0.6411 - val_loss: 0.9920 - val_accuracy: 0.6268\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9458 - accuracy: 0.6534 - val_loss: 1.0078 - val_accuracy: 0.5981\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9523 - accuracy: 0.6427 - val_loss: 0.9522 - val_accuracy: 0.6316\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9351 - accuracy: 0.6528 - val_loss: 0.9495 - val_accuracy: 0.6507\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9175 - accuracy: 0.6688 - val_loss: 0.9556 - val_accuracy: 0.6268\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9005 - accuracy: 0.6725 - val_loss: 0.9613 - val_accuracy: 0.6220\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8926 - accuracy: 0.6784 - val_loss: 0.9347 - val_accuracy: 0.6172\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8956 - accuracy: 0.6747 - val_loss: 0.9482 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8816 - accuracy: 0.6816 - val_loss: 0.9297 - val_accuracy: 0.6316\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8730 - accuracy: 0.6763 - val_loss: 0.9671 - val_accuracy: 0.6029\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8450 - accuracy: 0.6848 - val_loss: 0.9095 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8478 - accuracy: 0.6896 - val_loss: 0.9117 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8266 - accuracy: 0.6944 - val_loss: 0.9060 - val_accuracy: 0.6651\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8385 - accuracy: 0.6896 - val_loss: 0.9324 - val_accuracy: 0.6507\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8352 - accuracy: 0.6928 - val_loss: 0.9234 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8173 - accuracy: 0.7023 - val_loss: 0.8903 - val_accuracy: 0.6555\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8168 - accuracy: 0.6965 - val_loss: 0.8977 - val_accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7952 - accuracy: 0.7103 - val_loss: 0.9614 - val_accuracy: 0.6459\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7833 - accuracy: 0.7077 - val_loss: 0.8408 - val_accuracy: 0.6794\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7628 - accuracy: 0.7263 - val_loss: 0.8892 - val_accuracy: 0.6699\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.7591 - accuracy: 0.7125 - val_loss: 0.8607 - val_accuracy: 0.6507\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7676 - accuracy: 0.7162 - val_loss: 0.8985 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7627 - accuracy: 0.7114 - val_loss: 0.8700 - val_accuracy: 0.6555\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7548 - accuracy: 0.7210 - val_loss: 0.8843 - val_accuracy: 0.6842\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7514 - accuracy: 0.7135 - val_loss: 0.8815 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7353 - accuracy: 0.7146 - val_loss: 0.8967 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7186 - accuracy: 0.7247 - val_loss: 0.8738 - val_accuracy: 0.6507\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7040 - accuracy: 0.7370 - val_loss: 0.8642 - val_accuracy: 0.6603\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7012 - accuracy: 0.7433 - val_loss: 0.8743 - val_accuracy: 0.6699\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6969 - accuracy: 0.7391 - val_loss: 0.8393 - val_accuracy: 0.6651\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7004 - accuracy: 0.7460 - val_loss: 0.8448 - val_accuracy: 0.6746\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6670 - accuracy: 0.7604 - val_loss: 0.8586 - val_accuracy: 0.6651\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6927 - accuracy: 0.7401 - val_loss: 0.8791 - val_accuracy: 0.6411\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6746 - accuracy: 0.7588 - val_loss: 0.8378 - val_accuracy: 0.6651\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6590 - accuracy: 0.7487 - val_loss: 0.7818 - val_accuracy: 0.6890\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6640 - accuracy: 0.7439 - val_loss: 0.8027 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 18/60 [24:44<1:27:05, 124.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.3637 - accuracy: 0.2812 - val_loss: 1.3407 - val_accuracy: 0.3349\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 338us/step - loss: 1.3184 - accuracy: 0.3972 - val_loss: 1.3186 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 381us/step - loss: 1.2734 - accuracy: 0.4558 - val_loss: 1.2950 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 383us/step - loss: 1.2416 - accuracy: 0.4686 - val_loss: 1.2648 - val_accuracy: 0.3971\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 360us/step - loss: 1.2064 - accuracy: 0.4968 - val_loss: 1.2246 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 375us/step - loss: 1.1661 - accuracy: 0.5170 - val_loss: 1.1733 - val_accuracy: 0.4976\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 463us/step - loss: 1.1435 - accuracy: 0.5367 - val_loss: 1.1528 - val_accuracy: 0.5311\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - ETA: 0s - loss: 1.1269 - accuracy: 0.54 - 1s 620us/step - loss: 1.1286 - accuracy: 0.5394 - val_loss: 1.1165 - val_accuracy: 0.5407\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 444us/step - loss: 1.0954 - accuracy: 0.5671 - val_loss: 1.1095 - val_accuracy: 0.5407\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 549us/step - loss: 1.0982 - accuracy: 0.5623 - val_loss: 1.1086 - val_accuracy: 0.5407\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 383us/step - loss: 1.0594 - accuracy: 0.5788 - val_loss: 1.0930 - val_accuracy: 0.5502\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 367us/step - loss: 1.0529 - accuracy: 0.5831 - val_loss: 1.0755 - val_accuracy: 0.5598\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 539us/step - loss: 1.0449 - accuracy: 0.5852 - val_loss: 1.0754 - val_accuracy: 0.5502\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 1.0445 - accuracy: 0.5767 - val_loss: 1.0625 - val_accuracy: 0.5455\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 375us/step - loss: 1.0412 - accuracy: 0.5708 - val_loss: 1.0572 - val_accuracy: 0.5455\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 357us/step - loss: 1.0270 - accuracy: 0.5841 - val_loss: 1.0438 - val_accuracy: 0.5598\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 397us/step - loss: 1.0163 - accuracy: 0.5927 - val_loss: 1.0395 - val_accuracy: 0.5694\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 355us/step - loss: 1.0049 - accuracy: 0.5980 - val_loss: 1.0349 - val_accuracy: 0.5646\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 371us/step - loss: 1.0019 - accuracy: 0.5985 - val_loss: 1.0402 - val_accuracy: 0.5598\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 359us/step - loss: 0.9978 - accuracy: 0.5873 - val_loss: 1.0309 - val_accuracy: 0.5694\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 361us/step - loss: 1.0047 - accuracy: 0.5948 - val_loss: 1.0311 - val_accuracy: 0.5646\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 354us/step - loss: 0.9892 - accuracy: 0.5937 - val_loss: 1.0281 - val_accuracy: 0.5694\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 370us/step - loss: 0.9874 - accuracy: 0.5905 - val_loss: 1.0264 - val_accuracy: 0.5742\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 437us/step - loss: 0.9774 - accuracy: 0.5990 - val_loss: 1.0138 - val_accuracy: 0.5742\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 492us/step - loss: 0.9687 - accuracy: 0.6060 - val_loss: 1.0121 - val_accuracy: 0.5789\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 407us/step - loss: 0.9682 - accuracy: 0.6113 - val_loss: 1.0151 - val_accuracy: 0.5789\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 494us/step - loss: 0.9578 - accuracy: 0.6171 - val_loss: 1.0037 - val_accuracy: 0.5981\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 507us/step - loss: 0.9440 - accuracy: 0.6337 - val_loss: 0.9943 - val_accuracy: 0.5933\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 455us/step - loss: 0.9552 - accuracy: 0.6273 - val_loss: 0.9861 - val_accuracy: 0.5885\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 472us/step - loss: 0.9305 - accuracy: 0.6395 - val_loss: 0.9763 - val_accuracy: 0.6077\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 472us/step - loss: 0.9287 - accuracy: 0.6406 - val_loss: 0.9676 - val_accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 470us/step - loss: 0.9283 - accuracy: 0.6432 - val_loss: 0.9566 - val_accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 611us/step - loss: 0.9143 - accuracy: 0.6592 - val_loss: 0.9470 - val_accuracy: 0.6699\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 486us/step - loss: 0.9112 - accuracy: 0.6491 - val_loss: 0.9446 - val_accuracy: 0.6555\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 391us/step - loss: 0.9048 - accuracy: 0.6470 - val_loss: 0.9428 - val_accuracy: 0.6411\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.9025 - accuracy: 0.6555 - val_loss: 0.9371 - val_accuracy: 0.6459\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 548us/step - loss: 0.8947 - accuracy: 0.6603 - val_loss: 0.9318 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 610us/step - loss: 0.8847 - accuracy: 0.6619 - val_loss: 0.9241 - val_accuracy: 0.6507\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 492us/step - loss: 0.8892 - accuracy: 0.6645 - val_loss: 0.9245 - val_accuracy: 0.6507\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 668us/step - loss: 0.8773 - accuracy: 0.6667 - val_loss: 0.9296 - val_accuracy: 0.6507\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 571us/step - loss: 0.8784 - accuracy: 0.6683 - val_loss: 0.9157 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 517us/step - loss: 0.8578 - accuracy: 0.6784 - val_loss: 0.9229 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 510us/step - loss: 0.8753 - accuracy: 0.6619 - val_loss: 0.9256 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 451us/step - loss: 0.8421 - accuracy: 0.6864 - val_loss: 0.9244 - val_accuracy: 0.6411\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 377us/step - loss: 0.8540 - accuracy: 0.6747 - val_loss: 0.9182 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 290us/step - loss: 0.8804 - accuracy: 0.6597 - val_loss: 0.9096 - val_accuracy: 0.6651\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 422us/step - loss: 0.8619 - accuracy: 0.6624 - val_loss: 0.9109 - val_accuracy: 0.6555\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.8514 - accuracy: 0.6752 - val_loss: 0.9092 - val_accuracy: 0.6651\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 372us/step - loss: 0.8635 - accuracy: 0.6715 - val_loss: 0.9065 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 599us/step - loss: 0.8509 - accuracy: 0.6736 - val_loss: 0.9077 - val_accuracy: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 19/60 [25:31<1:09:14, 101.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.3095 - accuracy: 0.4185 - val_loss: 1.3357 - val_accuracy: 0.4593\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 532us/step - loss: 1.2225 - accuracy: 0.5197 - val_loss: 1.2572 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 656us/step - loss: 1.1797 - accuracy: 0.5373 - val_loss: 1.1827 - val_accuracy: 0.5598\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 442us/step - loss: 1.1483 - accuracy: 0.5431 - val_loss: 1.1438 - val_accuracy: 0.5646\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 788us/step - loss: 1.1214 - accuracy: 0.5724 - val_loss: 1.1297 - val_accuracy: 0.5311\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 666us/step - loss: 1.0940 - accuracy: 0.5714 - val_loss: 1.1002 - val_accuracy: 0.5407\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 664us/step - loss: 1.0875 - accuracy: 0.5698 - val_loss: 1.0781 - val_accuracy: 0.5646\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 764us/step - loss: 1.0725 - accuracy: 0.5708 - val_loss: 1.0367 - val_accuracy: 0.5694\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 527us/step - loss: 1.0581 - accuracy: 0.5682 - val_loss: 1.0294 - val_accuracy: 0.5742\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 566us/step - loss: 1.0283 - accuracy: 0.5953 - val_loss: 0.9792 - val_accuracy: 0.5837\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 494us/step - loss: 1.0144 - accuracy: 0.6001 - val_loss: 0.9764 - val_accuracy: 0.6029\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 614us/step - loss: 0.9971 - accuracy: 0.6294 - val_loss: 0.9762 - val_accuracy: 0.6651\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 685us/step - loss: 0.9856 - accuracy: 0.6459 - val_loss: 0.9831 - val_accuracy: 0.6603\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 723us/step - loss: 0.9705 - accuracy: 0.6448 - val_loss: 0.9594 - val_accuracy: 0.6459\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 716us/step - loss: 0.9666 - accuracy: 0.6539 - val_loss: 0.9767 - val_accuracy: 0.6316\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 491us/step - loss: 0.9392 - accuracy: 0.6629 - val_loss: 0.9395 - val_accuracy: 0.6507\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 503us/step - loss: 0.9467 - accuracy: 0.6523 - val_loss: 0.9377 - val_accuracy: 0.6746\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 408us/step - loss: 0.9318 - accuracy: 0.6661 - val_loss: 0.9234 - val_accuracy: 0.6746\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 405us/step - loss: 0.9038 - accuracy: 0.6752 - val_loss: 0.9320 - val_accuracy: 0.6699\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 419us/step - loss: 0.8907 - accuracy: 0.6810 - val_loss: 0.9487 - val_accuracy: 0.6507\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.8929 - accuracy: 0.6763 - val_loss: 0.9088 - val_accuracy: 0.6699\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 541us/step - loss: 0.8856 - accuracy: 0.6736 - val_loss: 0.9062 - val_accuracy: 0.6699\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 492us/step - loss: 0.8755 - accuracy: 0.6816 - val_loss: 0.9160 - val_accuracy: 0.6555\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 493us/step - loss: 0.8764 - accuracy: 0.6757 - val_loss: 0.9005 - val_accuracy: 0.6651\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 380us/step - loss: 0.8601 - accuracy: 0.6832 - val_loss: 0.9009 - val_accuracy: 0.6651\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 504us/step - loss: 0.8413 - accuracy: 0.6874 - val_loss: 0.8808 - val_accuracy: 0.6794\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 625us/step - loss: 0.8283 - accuracy: 0.6960 - val_loss: 0.8966 - val_accuracy: 0.6411\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 614us/step - loss: 0.8300 - accuracy: 0.6970 - val_loss: 0.8739 - val_accuracy: 0.6794\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 658us/step - loss: 0.8183 - accuracy: 0.7093 - val_loss: 0.8926 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 664us/step - loss: 0.8105 - accuracy: 0.7055 - val_loss: 0.8801 - val_accuracy: 0.6459\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 632us/step - loss: 0.8051 - accuracy: 0.7093 - val_loss: 0.8571 - val_accuracy: 0.6699\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 703us/step - loss: 0.8109 - accuracy: 0.6965 - val_loss: 0.8533 - val_accuracy: 0.6651\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 724us/step - loss: 0.7911 - accuracy: 0.7002 - val_loss: 0.8796 - val_accuracy: 0.6364\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 695us/step - loss: 0.7840 - accuracy: 0.7125 - val_loss: 0.8254 - val_accuracy: 0.6938\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 623us/step - loss: 0.7744 - accuracy: 0.7114 - val_loss: 0.8693 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 682us/step - loss: 0.7722 - accuracy: 0.7204 - val_loss: 0.8289 - val_accuracy: 0.6699\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 492us/step - loss: 0.7579 - accuracy: 0.7231 - val_loss: 0.8555 - val_accuracy: 0.6603\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 424us/step - loss: 0.7563 - accuracy: 0.7098 - val_loss: 0.8624 - val_accuracy: 0.6507\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 0.7532 - accuracy: 0.7173 - val_loss: 0.8337 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 0.7367 - accuracy: 0.7322 - val_loss: 0.8674 - val_accuracy: 0.6411\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.7248 - accuracy: 0.7295 - val_loss: 0.8509 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 432us/step - loss: 0.7181 - accuracy: 0.7343 - val_loss: 0.8445 - val_accuracy: 0.6603\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 428us/step - loss: 0.7047 - accuracy: 0.7433 - val_loss: 0.8309 - val_accuracy: 0.6603\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 480us/step - loss: 0.7192 - accuracy: 0.7322 - val_loss: 0.8351 - val_accuracy: 0.6507\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 756us/step - loss: 0.7167 - accuracy: 0.7300 - val_loss: 0.8458 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 539us/step - loss: 0.7089 - accuracy: 0.7375 - val_loss: 0.8455 - val_accuracy: 0.6651\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 699us/step - loss: 0.7080 - accuracy: 0.7401 - val_loss: 0.8570 - val_accuracy: 0.6364\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 623us/step - loss: 0.7006 - accuracy: 0.7359 - val_loss: 0.8603 - val_accuracy: 0.6459\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 485us/step - loss: 0.6835 - accuracy: 0.7455 - val_loss: 0.8475 - val_accuracy: 0.6555\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 456us/step - loss: 0.6662 - accuracy: 0.7551 - val_loss: 0.8502 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 20/60 [26:36<1:00:13, 90.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2427 - accuracy: 0.4973 - val_loss: 1.2579 - val_accuracy: 0.5072\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1795 - accuracy: 0.5447 - val_loss: 1.2138 - val_accuracy: 0.4928\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1481 - accuracy: 0.5506 - val_loss: 1.1794 - val_accuracy: 0.5120\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1295 - accuracy: 0.5548 - val_loss: 1.1292 - val_accuracy: 0.5694\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0960 - accuracy: 0.5900 - val_loss: 1.1103 - val_accuracy: 0.6077\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0945 - accuracy: 0.5868 - val_loss: 1.1040 - val_accuracy: 0.5502\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0838 - accuracy: 0.6028 - val_loss: 1.0804 - val_accuracy: 0.6029\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0664 - accuracy: 0.6118 - val_loss: 1.0795 - val_accuracy: 0.5694\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 5s 2ms/step - loss: 1.0404 - accuracy: 0.5990 - val_loss: 1.0464 - val_accuracy: 0.5981\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0309 - accuracy: 0.6161 - val_loss: 1.0399 - val_accuracy: 0.5885\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0245 - accuracy: 0.6171 - val_loss: 1.0311 - val_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0098 - accuracy: 0.6315 - val_loss: 1.0175 - val_accuracy: 0.5885\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0166 - accuracy: 0.6022 - val_loss: 1.0119 - val_accuracy: 0.6077\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9852 - accuracy: 0.6395 - val_loss: 1.0419 - val_accuracy: 0.5694\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9675 - accuracy: 0.6443 - val_loss: 1.0128 - val_accuracy: 0.6124\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9628 - accuracy: 0.6486 - val_loss: 0.9956 - val_accuracy: 0.6220\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9653 - accuracy: 0.6411 - val_loss: 1.0932 - val_accuracy: 0.5311\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.9568 - accuracy: 0.6368 - val_loss: 1.0132 - val_accuracy: 0.5885\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 5s 2ms/step - loss: 0.9461 - accuracy: 0.6416 - val_loss: 1.0171 - val_accuracy: 0.5789\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.9331 - accuracy: 0.6539 - val_loss: 0.9669 - val_accuracy: 0.6077\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9220 - accuracy: 0.6613 - val_loss: 1.0403 - val_accuracy: 0.5694\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9261 - accuracy: 0.6539 - val_loss: 0.9709 - val_accuracy: 0.6220\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8882 - accuracy: 0.6842 - val_loss: 0.9486 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8834 - accuracy: 0.6672 - val_loss: 0.9632 - val_accuracy: 0.5789\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8851 - accuracy: 0.6715 - val_loss: 0.9595 - val_accuracy: 0.6172\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8860 - accuracy: 0.6731 - val_loss: 0.9151 - val_accuracy: 0.6603\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8883 - accuracy: 0.6752 - val_loss: 0.9418 - val_accuracy: 0.6077\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8572 - accuracy: 0.6821 - val_loss: 0.9433 - val_accuracy: 0.6172\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.8609 - accuracy: 0.6805 - val_loss: 0.9605 - val_accuracy: 0.5981\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8590 - accuracy: 0.6778 - val_loss: 0.9177 - val_accuracy: 0.6651\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8323 - accuracy: 0.6794 - val_loss: 0.9287 - val_accuracy: 0.6220\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8519 - accuracy: 0.6773 - val_loss: 0.9084 - val_accuracy: 0.6507\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8226 - accuracy: 0.6997 - val_loss: 0.9152 - val_accuracy: 0.6316\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8179 - accuracy: 0.6928 - val_loss: 0.9030 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8080 - accuracy: 0.7066 - val_loss: 0.9431 - val_accuracy: 0.6364\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8071 - accuracy: 0.6938 - val_loss: 0.9243 - val_accuracy: 0.6268\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7902 - accuracy: 0.6981 - val_loss: 0.9360 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7839 - accuracy: 0.7066 - val_loss: 0.9162 - val_accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.7822 - accuracy: 0.7109 - val_loss: 0.9225 - val_accuracy: 0.6220\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7657 - accuracy: 0.7125 - val_loss: 0.9696 - val_accuracy: 0.6029\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7528 - accuracy: 0.7167 - val_loss: 0.8970 - val_accuracy: 0.6555\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7761 - accuracy: 0.6944 - val_loss: 0.9220 - val_accuracy: 0.6411\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.7452 - accuracy: 0.7204 - val_loss: 0.8745 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.7586 - accuracy: 0.7093 - val_loss: 0.9035 - val_accuracy: 0.6316\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7460 - accuracy: 0.7188 - val_loss: 0.9252 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7306 - accuracy: 0.7274 - val_loss: 0.9194 - val_accuracy: 0.6268\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7111 - accuracy: 0.7316 - val_loss: 0.8871 - val_accuracy: 0.6555\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7204 - accuracy: 0.7242 - val_loss: 0.8975 - val_accuracy: 0.6364\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7214 - accuracy: 0.7194 - val_loss: 0.9082 - val_accuracy: 0.6411\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7154 - accuracy: 0.7231 - val_loss: 0.8981 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 21/60 [29:45<1:17:59, 119.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.3525 - accuracy: 0.3408 - val_loss: 1.3509 - val_accuracy: 0.3254\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 349us/step - loss: 1.2699 - accuracy: 0.4579 - val_loss: 1.2785 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 348us/step - loss: 1.2297 - accuracy: 0.4846 - val_loss: 1.2207 - val_accuracy: 0.5359\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 454us/step - loss: 1.2064 - accuracy: 0.4995 - val_loss: 1.1842 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 548us/step - loss: 1.1806 - accuracy: 0.5122 - val_loss: 1.1603 - val_accuracy: 0.5359\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 414us/step - loss: 1.1591 - accuracy: 0.5245 - val_loss: 1.1365 - val_accuracy: 0.5455\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 379us/step - loss: 1.1486 - accuracy: 0.5357 - val_loss: 1.1156 - val_accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 1.1344 - accuracy: 0.5373 - val_loss: 1.0984 - val_accuracy: 0.5646\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 1.1165 - accuracy: 0.5559 - val_loss: 1.0819 - val_accuracy: 0.5646\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 1.1014 - accuracy: 0.5724 - val_loss: 1.0596 - val_accuracy: 0.5981\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 1.0916 - accuracy: 0.5751 - val_loss: 1.0464 - val_accuracy: 0.5885\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 1.0870 - accuracy: 0.5735 - val_loss: 1.0248 - val_accuracy: 0.5981\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 249us/step - loss: 1.0752 - accuracy: 0.5777 - val_loss: 1.0286 - val_accuracy: 0.5742\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 248us/step - loss: 1.0617 - accuracy: 0.5793 - val_loss: 1.0175 - val_accuracy: 0.6029\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 1.0426 - accuracy: 0.5937 - val_loss: 1.0076 - val_accuracy: 0.5885\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 303us/step - loss: 1.0421 - accuracy: 0.5900 - val_loss: 1.0041 - val_accuracy: 0.5789\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 315us/step - loss: 1.0391 - accuracy: 0.5756 - val_loss: 1.0027 - val_accuracy: 0.5789\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 1.0348 - accuracy: 0.5873 - val_loss: 1.0034 - val_accuracy: 0.5789\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 279us/step - loss: 1.0197 - accuracy: 0.5873 - val_loss: 1.0050 - val_accuracy: 0.5694\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 1.0114 - accuracy: 0.5847 - val_loss: 0.9993 - val_accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 449us/step - loss: 1.0049 - accuracy: 0.5980 - val_loss: 0.9950 - val_accuracy: 0.5742\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 439us/step - loss: 1.0117 - accuracy: 0.5937 - val_loss: 0.9962 - val_accuracy: 0.5789\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 511us/step - loss: 1.0113 - accuracy: 0.5868 - val_loss: 0.9897 - val_accuracy: 0.5837\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 536us/step - loss: 0.9920 - accuracy: 0.6054 - val_loss: 0.9917 - val_accuracy: 0.5789\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 516us/step - loss: 0.9793 - accuracy: 0.6033 - val_loss: 0.9859 - val_accuracy: 0.5837\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 525us/step - loss: 0.9899 - accuracy: 0.5942 - val_loss: 0.9869 - val_accuracy: 0.5837\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.9763 - accuracy: 0.6038 - val_loss: 0.9781 - val_accuracy: 0.5933\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 572us/step - loss: 0.9721 - accuracy: 0.6092 - val_loss: 0.9737 - val_accuracy: 0.5837\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 358us/step - loss: 0.9774 - accuracy: 0.5985 - val_loss: 0.9794 - val_accuracy: 0.6029\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 326us/step - loss: 0.9738 - accuracy: 0.6086 - val_loss: 0.9721 - val_accuracy: 0.5933\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 318us/step - loss: 0.9675 - accuracy: 0.6097 - val_loss: 0.9641 - val_accuracy: 0.6077\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 377us/step - loss: 0.9537 - accuracy: 0.6108 - val_loss: 0.9636 - val_accuracy: 0.6029\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 481us/step - loss: 0.9793 - accuracy: 0.5958 - val_loss: 0.9533 - val_accuracy: 0.6124\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 389us/step - loss: 0.9644 - accuracy: 0.6155 - val_loss: 0.9553 - val_accuracy: 0.6172\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 503us/step - loss: 0.9471 - accuracy: 0.6267 - val_loss: 0.9570 - val_accuracy: 0.6029\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 349us/step - loss: 0.9406 - accuracy: 0.6246 - val_loss: 0.9568 - val_accuracy: 0.6077\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 325us/step - loss: 0.9423 - accuracy: 0.6171 - val_loss: 0.9472 - val_accuracy: 0.6124\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 456us/step - loss: 0.9340 - accuracy: 0.6262 - val_loss: 0.9425 - val_accuracy: 0.6124\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.9263 - accuracy: 0.6326 - val_loss: 0.9484 - val_accuracy: 0.5885\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 322us/step - loss: 0.9383 - accuracy: 0.6214 - val_loss: 0.9467 - val_accuracy: 0.6124\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 483us/step - loss: 0.9191 - accuracy: 0.6326 - val_loss: 0.9410 - val_accuracy: 0.6077\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 319us/step - loss: 0.9250 - accuracy: 0.6225 - val_loss: 0.9422 - val_accuracy: 0.6029\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 0.9188 - accuracy: 0.6374 - val_loss: 0.9367 - val_accuracy: 0.6220\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.9113 - accuracy: 0.6273 - val_loss: 0.9325 - val_accuracy: 0.6172\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.9072 - accuracy: 0.6321 - val_loss: 0.9229 - val_accuracy: 0.6316\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.9025 - accuracy: 0.6416 - val_loss: 0.9199 - val_accuracy: 0.6220\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.9004 - accuracy: 0.6486 - val_loss: 0.9177 - val_accuracy: 0.6172\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.8987 - accuracy: 0.6523 - val_loss: 0.9179 - val_accuracy: 0.6220\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.8894 - accuracy: 0.6587 - val_loss: 0.9156 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 0.8912 - accuracy: 0.6555 - val_loss: 0.9103 - val_accuracy: 0.6268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 22/60 [30:23<1:00:24, 95.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 842us/step - loss: 1.3069 - accuracy: 0.4292 - val_loss: 1.3174 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 434us/step - loss: 1.2213 - accuracy: 0.5021 - val_loss: 1.2412 - val_accuracy: 0.4067\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 1.1808 - accuracy: 0.5437 - val_loss: 1.2117 - val_accuracy: 0.4498\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 427us/step - loss: 1.1420 - accuracy: 0.5543 - val_loss: 1.1584 - val_accuracy: 0.5215\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 429us/step - loss: 1.1335 - accuracy: 0.5591 - val_loss: 1.1368 - val_accuracy: 0.5598\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 425us/step - loss: 1.1110 - accuracy: 0.5745 - val_loss: 1.1239 - val_accuracy: 0.5407\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 397us/step - loss: 1.0975 - accuracy: 0.5676 - val_loss: 1.1058 - val_accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 415us/step - loss: 1.0824 - accuracy: 0.5788 - val_loss: 1.1340 - val_accuracy: 0.5263\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 422us/step - loss: 1.0598 - accuracy: 0.5905 - val_loss: 1.0790 - val_accuracy: 0.5598\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 434us/step - loss: 1.0404 - accuracy: 0.5815 - val_loss: 1.0645 - val_accuracy: 0.5502\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 410us/step - loss: 1.0271 - accuracy: 0.5820 - val_loss: 1.0595 - val_accuracy: 0.5502\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 445us/step - loss: 1.0306 - accuracy: 0.5868 - val_loss: 1.0315 - val_accuracy: 0.5742\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 420us/step - loss: 1.0106 - accuracy: 0.6006 - val_loss: 1.0218 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 610us/step - loss: 0.9980 - accuracy: 0.6257 - val_loss: 1.0181 - val_accuracy: 0.6124\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 484us/step - loss: 0.9930 - accuracy: 0.6289 - val_loss: 1.0214 - val_accuracy: 0.6124\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 425us/step - loss: 0.9751 - accuracy: 0.6416 - val_loss: 1.0007 - val_accuracy: 0.6459\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 422us/step - loss: 0.9667 - accuracy: 0.6470 - val_loss: 1.0040 - val_accuracy: 0.6411\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 457us/step - loss: 0.9617 - accuracy: 0.6459 - val_loss: 0.9724 - val_accuracy: 0.6555\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 474us/step - loss: 0.9612 - accuracy: 0.6406 - val_loss: 0.9477 - val_accuracy: 0.6555\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 454us/step - loss: 0.9508 - accuracy: 0.6550 - val_loss: 0.9443 - val_accuracy: 0.6459\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 411us/step - loss: 0.9169 - accuracy: 0.6683 - val_loss: 0.9707 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 401us/step - loss: 0.9191 - accuracy: 0.6592 - val_loss: 0.9551 - val_accuracy: 0.6364\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 419us/step - loss: 0.9239 - accuracy: 0.6512 - val_loss: 0.9742 - val_accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 506us/step - loss: 0.9094 - accuracy: 0.6677 - val_loss: 0.9387 - val_accuracy: 0.6603\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 374us/step - loss: 0.9018 - accuracy: 0.6683 - val_loss: 0.9600 - val_accuracy: 0.6172\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 452us/step - loss: 0.8945 - accuracy: 0.6619 - val_loss: 0.9496 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 408us/step - loss: 0.8930 - accuracy: 0.6661 - val_loss: 0.9514 - val_accuracy: 0.6268\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 496us/step - loss: 0.8640 - accuracy: 0.6810 - val_loss: 0.9318 - val_accuracy: 0.6172\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 441us/step - loss: 0.8691 - accuracy: 0.6720 - val_loss: 0.9220 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 425us/step - loss: 0.8739 - accuracy: 0.6715 - val_loss: 0.9260 - val_accuracy: 0.6364\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.8624 - accuracy: 0.6794 - val_loss: 0.9129 - val_accuracy: 0.6459\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.8553 - accuracy: 0.6800 - val_loss: 0.9106 - val_accuracy: 0.6459\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 388us/step - loss: 0.8447 - accuracy: 0.6906 - val_loss: 0.9033 - val_accuracy: 0.6411\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 391us/step - loss: 0.8337 - accuracy: 0.6970 - val_loss: 0.9137 - val_accuracy: 0.6411\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 426us/step - loss: 0.8177 - accuracy: 0.7050 - val_loss: 0.8944 - val_accuracy: 0.6459\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 417us/step - loss: 0.8118 - accuracy: 0.6970 - val_loss: 0.9125 - val_accuracy: 0.6220\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 414us/step - loss: 0.8172 - accuracy: 0.6991 - val_loss: 0.9017 - val_accuracy: 0.6268\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 406us/step - loss: 0.8205 - accuracy: 0.6869 - val_loss: 0.8833 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 450us/step - loss: 0.8062 - accuracy: 0.7013 - val_loss: 0.8796 - val_accuracy: 0.6364\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 469us/step - loss: 0.8100 - accuracy: 0.6981 - val_loss: 0.8850 - val_accuracy: 0.6316\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 591us/step - loss: 0.7942 - accuracy: 0.7013 - val_loss: 0.8752 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.7769 - accuracy: 0.7173 - val_loss: 0.8645 - val_accuracy: 0.6555\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 448us/step - loss: 0.7744 - accuracy: 0.7045 - val_loss: 0.8721 - val_accuracy: 0.6411\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 433us/step - loss: 0.7933 - accuracy: 0.7029 - val_loss: 0.8855 - val_accuracy: 0.6459\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 409us/step - loss: 0.7666 - accuracy: 0.7103 - val_loss: 0.8850 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 422us/step - loss: 0.7487 - accuracy: 0.7247 - val_loss: 0.8683 - val_accuracy: 0.6699\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 429us/step - loss: 0.7572 - accuracy: 0.7135 - val_loss: 0.8671 - val_accuracy: 0.6555\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 432us/step - loss: 0.7542 - accuracy: 0.7226 - val_loss: 0.8745 - val_accuracy: 0.6459\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 417us/step - loss: 0.7467 - accuracy: 0.7236 - val_loss: 0.8521 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 429us/step - loss: 0.7538 - accuracy: 0.7157 - val_loss: 0.8691 - val_accuracy: 0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 23/60 [31:07<49:13, 79.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 1.2403 - accuracy: 0.4835 - val_loss: 1.2287 - val_accuracy: 0.5550\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1700 - accuracy: 0.5431 - val_loss: 1.1914 - val_accuracy: 0.5502\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1403 - accuracy: 0.5517 - val_loss: 1.1518 - val_accuracy: 0.5694\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1267 - accuracy: 0.5543 - val_loss: 1.1205 - val_accuracy: 0.5598\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0960 - accuracy: 0.5804 - val_loss: 1.1286 - val_accuracy: 0.5502\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0847 - accuracy: 0.5916 - val_loss: 1.1101 - val_accuracy: 0.5646\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0645 - accuracy: 0.5996 - val_loss: 1.0543 - val_accuracy: 0.6555\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0463 - accuracy: 0.6022 - val_loss: 1.0765 - val_accuracy: 0.6077\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0397 - accuracy: 0.6187 - val_loss: 1.0268 - val_accuracy: 0.6411\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0527 - accuracy: 0.5969 - val_loss: 1.0685 - val_accuracy: 0.6029\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0359 - accuracy: 0.6060 - val_loss: 1.0019 - val_accuracy: 0.6459\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0158 - accuracy: 0.6283 - val_loss: 0.9962 - val_accuracy: 0.6411\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0083 - accuracy: 0.6246 - val_loss: 1.0277 - val_accuracy: 0.6507\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0159 - accuracy: 0.6182 - val_loss: 1.0388 - val_accuracy: 0.6077\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9770 - accuracy: 0.6470 - val_loss: 0.9565 - val_accuracy: 0.6890\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9871 - accuracy: 0.6315 - val_loss: 0.9997 - val_accuracy: 0.6411\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9624 - accuracy: 0.6326 - val_loss: 0.9756 - val_accuracy: 0.6507\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9901 - accuracy: 0.6289 - val_loss: 1.0883 - val_accuracy: 0.5742\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9720 - accuracy: 0.6267 - val_loss: 1.0383 - val_accuracy: 0.5789\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9649 - accuracy: 0.6368 - val_loss: 1.0125 - val_accuracy: 0.6172\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9451 - accuracy: 0.6480 - val_loss: 0.9626 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.9284 - accuracy: 0.6550 - val_loss: 0.9488 - val_accuracy: 0.6603\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.9369 - accuracy: 0.6470 - val_loss: 0.9339 - val_accuracy: 0.6651\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9239 - accuracy: 0.6571 - val_loss: 0.9431 - val_accuracy: 0.6411\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8969 - accuracy: 0.6672 - val_loss: 0.9579 - val_accuracy: 0.6268\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9139 - accuracy: 0.6629 - val_loss: 0.9329 - val_accuracy: 0.6268\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8907 - accuracy: 0.6683 - val_loss: 0.9359 - val_accuracy: 0.6220\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8989 - accuracy: 0.6603 - val_loss: 0.9160 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9019 - accuracy: 0.6544 - val_loss: 0.9301 - val_accuracy: 0.6316\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8734 - accuracy: 0.6683 - val_loss: 0.8911 - val_accuracy: 0.6651\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8693 - accuracy: 0.6757 - val_loss: 0.9290 - val_accuracy: 0.6172\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 0.8808 - accuracy: 0.6752 - val_loss: 0.9360 - val_accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8535 - accuracy: 0.6917 - val_loss: 0.9292 - val_accuracy: 0.6172\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8572 - accuracy: 0.6821 - val_loss: 0.8901 - val_accuracy: 0.6364\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8493 - accuracy: 0.6906 - val_loss: 0.9259 - val_accuracy: 0.6077\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8491 - accuracy: 0.6869 - val_loss: 0.9681 - val_accuracy: 0.5981\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8396 - accuracy: 0.6981 - val_loss: 0.9199 - val_accuracy: 0.6220\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8075 - accuracy: 0.7018 - val_loss: 0.8924 - val_accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8169 - accuracy: 0.7002 - val_loss: 0.9170 - val_accuracy: 0.6220\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8137 - accuracy: 0.7077 - val_loss: 0.8926 - val_accuracy: 0.6411\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8011 - accuracy: 0.6981 - val_loss: 0.8919 - val_accuracy: 0.6220\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8104 - accuracy: 0.6944 - val_loss: 0.8774 - val_accuracy: 0.6603\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8197 - accuracy: 0.6912 - val_loss: 0.9188 - val_accuracy: 0.6364\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8045 - accuracy: 0.6938 - val_loss: 0.9125 - val_accuracy: 0.6124\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7842 - accuracy: 0.7157 - val_loss: 0.9070 - val_accuracy: 0.6411\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7674 - accuracy: 0.7183 - val_loss: 0.8755 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7940 - accuracy: 0.6917 - val_loss: 0.9046 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7710 - accuracy: 0.7109 - val_loss: 0.8776 - val_accuracy: 0.6316\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7537 - accuracy: 0.7226 - val_loss: 0.8688 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.7411 - accuracy: 0.7268 - val_loss: 0.8730 - val_accuracy: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 24/60 [33:38<1:00:47, 101.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 771us/step - loss: 1.3459 - accuracy: 0.3520 - val_loss: 1.3343 - val_accuracy: 0.3493\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 1.2971 - accuracy: 0.4526 - val_loss: 1.3051 - val_accuracy: 0.4258\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 1.2555 - accuracy: 0.4883 - val_loss: 1.2707 - val_accuracy: 0.4354\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 1.2207 - accuracy: 0.4984 - val_loss: 1.2314 - val_accuracy: 0.4689\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 1.1907 - accuracy: 0.5160 - val_loss: 1.1902 - val_accuracy: 0.5215\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 1.1745 - accuracy: 0.5176 - val_loss: 1.1558 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 1.1640 - accuracy: 0.5144 - val_loss: 1.1411 - val_accuracy: 0.5215\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 1.1467 - accuracy: 0.5160 - val_loss: 1.1332 - val_accuracy: 0.5263\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 1.1344 - accuracy: 0.5245 - val_loss: 1.1229 - val_accuracy: 0.5263\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 1.1185 - accuracy: 0.5357 - val_loss: 1.1151 - val_accuracy: 0.5359\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 1.1154 - accuracy: 0.5543 - val_loss: 1.1054 - val_accuracy: 0.5455\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 1.1070 - accuracy: 0.5357 - val_loss: 1.0935 - val_accuracy: 0.5550\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 1.0887 - accuracy: 0.5687 - val_loss: 1.0871 - val_accuracy: 0.5646\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 1.0934 - accuracy: 0.5618 - val_loss: 1.0792 - val_accuracy: 0.5646\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 1.0688 - accuracy: 0.5687 - val_loss: 1.0686 - val_accuracy: 0.5646\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 1.0654 - accuracy: 0.5719 - val_loss: 1.0614 - val_accuracy: 0.5837\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 1.0552 - accuracy: 0.5783 - val_loss: 1.0490 - val_accuracy: 0.5837\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 1.0423 - accuracy: 0.5841 - val_loss: 1.0429 - val_accuracy: 0.5885\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 1.0507 - accuracy: 0.5841 - val_loss: 1.0315 - val_accuracy: 0.6124\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 1.0269 - accuracy: 0.5932 - val_loss: 1.0218 - val_accuracy: 0.5837\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 1.0129 - accuracy: 0.6145 - val_loss: 1.0077 - val_accuracy: 0.6268\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 1.0060 - accuracy: 0.6177 - val_loss: 1.0008 - val_accuracy: 0.6077\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.9997 - accuracy: 0.6235 - val_loss: 0.9921 - val_accuracy: 0.6220\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.9965 - accuracy: 0.6140 - val_loss: 0.9900 - val_accuracy: 0.6364\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.9855 - accuracy: 0.6305 - val_loss: 0.9847 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 0.9712 - accuracy: 0.6368 - val_loss: 0.9738 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.9672 - accuracy: 0.6315 - val_loss: 0.9734 - val_accuracy: 0.6459\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.9708 - accuracy: 0.6326 - val_loss: 0.9744 - val_accuracy: 0.6364\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.9689 - accuracy: 0.6235 - val_loss: 0.9695 - val_accuracy: 0.6507\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 414us/step - loss: 0.9606 - accuracy: 0.6337 - val_loss: 0.9666 - val_accuracy: 0.6411\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 318us/step - loss: 0.9622 - accuracy: 0.6342 - val_loss: 0.9616 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.9621 - accuracy: 0.6230 - val_loss: 0.9592 - val_accuracy: 0.6411\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 344us/step - loss: 0.9465 - accuracy: 0.6411 - val_loss: 0.9553 - val_accuracy: 0.6364\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 0.9317 - accuracy: 0.6523 - val_loss: 0.9543 - val_accuracy: 0.6268\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.9430 - accuracy: 0.6416 - val_loss: 0.9514 - val_accuracy: 0.6316\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 421us/step - loss: 0.9173 - accuracy: 0.6571 - val_loss: 0.9490 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 369us/step - loss: 0.9451 - accuracy: 0.6406 - val_loss: 0.9463 - val_accuracy: 0.6220\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 411us/step - loss: 0.9363 - accuracy: 0.6416 - val_loss: 0.9409 - val_accuracy: 0.6268\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 395us/step - loss: 0.9113 - accuracy: 0.6480 - val_loss: 0.9476 - val_accuracy: 0.6220\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 290us/step - loss: 0.9183 - accuracy: 0.6480 - val_loss: 0.9378 - val_accuracy: 0.6124\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.8971 - accuracy: 0.6597 - val_loss: 0.9366 - val_accuracy: 0.6077\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.9119 - accuracy: 0.6512 - val_loss: 0.9355 - val_accuracy: 0.6124\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 0.9244 - accuracy: 0.6432 - val_loss: 0.9372 - val_accuracy: 0.6124\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 262us/step - loss: 0.9022 - accuracy: 0.6651 - val_loss: 0.9332 - val_accuracy: 0.6172\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 338us/step - loss: 0.9008 - accuracy: 0.6581 - val_loss: 0.9319 - val_accuracy: 0.6172\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 325us/step - loss: 0.9112 - accuracy: 0.6544 - val_loss: 0.9277 - val_accuracy: 0.6268\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 324us/step - loss: 0.8959 - accuracy: 0.6587 - val_loss: 0.9289 - val_accuracy: 0.6029\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 515us/step - loss: 0.8961 - accuracy: 0.6507 - val_loss: 0.9133 - val_accuracy: 0.6268\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 398us/step - loss: 0.8942 - accuracy: 0.6555 - val_loss: 0.9186 - val_accuracy: 0.6172\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 372us/step - loss: 0.8915 - accuracy: 0.6534 - val_loss: 0.9131 - val_accuracy: 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 25/60 [34:09<46:46, 80.18s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.3025 - accuracy: 0.4302 - val_loss: 1.3163 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 626us/step - loss: 1.2088 - accuracy: 0.5080 - val_loss: 1.2448 - val_accuracy: 0.4163\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 532us/step - loss: 1.1624 - accuracy: 0.5234 - val_loss: 1.1973 - val_accuracy: 0.4354\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 463us/step - loss: 1.1338 - accuracy: 0.5410 - val_loss: 1.1520 - val_accuracy: 0.4880\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 424us/step - loss: 1.1097 - accuracy: 0.5479 - val_loss: 1.0896 - val_accuracy: 0.5598\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 533us/step - loss: 1.0948 - accuracy: 0.5554 - val_loss: 1.1002 - val_accuracy: 0.5646\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 449us/step - loss: 1.0767 - accuracy: 0.5660 - val_loss: 1.0821 - val_accuracy: 0.5550\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 474us/step - loss: 1.0772 - accuracy: 0.5676 - val_loss: 1.0391 - val_accuracy: 0.6077\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 465us/step - loss: 1.0559 - accuracy: 0.5703 - val_loss: 1.0510 - val_accuracy: 0.5502\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 489us/step - loss: 1.0510 - accuracy: 0.5692 - val_loss: 1.0245 - val_accuracy: 0.5550\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 493us/step - loss: 1.0336 - accuracy: 0.5831 - val_loss: 1.0178 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 469us/step - loss: 1.0348 - accuracy: 0.5927 - val_loss: 1.0050 - val_accuracy: 0.6699\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 443us/step - loss: 1.0086 - accuracy: 0.5937 - val_loss: 1.0136 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 463us/step - loss: 1.0038 - accuracy: 0.6102 - val_loss: 0.9841 - val_accuracy: 0.6555\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 467us/step - loss: 0.9843 - accuracy: 0.6283 - val_loss: 0.9722 - val_accuracy: 0.6699\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 457us/step - loss: 0.9883 - accuracy: 0.6225 - val_loss: 0.9776 - val_accuracy: 0.6651\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 474us/step - loss: 0.9723 - accuracy: 0.6283 - val_loss: 0.9520 - val_accuracy: 0.6268\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 445us/step - loss: 0.9755 - accuracy: 0.6294 - val_loss: 0.9475 - val_accuracy: 0.6603\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 455us/step - loss: 0.9652 - accuracy: 0.6289 - val_loss: 0.9354 - val_accuracy: 0.6651\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 452us/step - loss: 0.9544 - accuracy: 0.6368 - val_loss: 0.9306 - val_accuracy: 0.6603\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 425us/step - loss: 0.9442 - accuracy: 0.6390 - val_loss: 0.9369 - val_accuracy: 0.6651\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 438us/step - loss: 0.9284 - accuracy: 0.6512 - val_loss: 0.9440 - val_accuracy: 0.6555\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 456us/step - loss: 0.9394 - accuracy: 0.6491 - val_loss: 0.9188 - val_accuracy: 0.6651\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 474us/step - loss: 0.9274 - accuracy: 0.6597 - val_loss: 0.9057 - val_accuracy: 0.6699\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 471us/step - loss: 0.9166 - accuracy: 0.6603 - val_loss: 0.9228 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 484us/step - loss: 0.9128 - accuracy: 0.6576 - val_loss: 0.9193 - val_accuracy: 0.6555\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 425us/step - loss: 0.8926 - accuracy: 0.6645 - val_loss: 0.8954 - val_accuracy: 0.6794\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 440us/step - loss: 0.9112 - accuracy: 0.6587 - val_loss: 0.8786 - val_accuracy: 0.6890\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 480us/step - loss: 0.8984 - accuracy: 0.6565 - val_loss: 0.8805 - val_accuracy: 0.6746\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 480us/step - loss: 0.8888 - accuracy: 0.6656 - val_loss: 0.8744 - val_accuracy: 0.6842\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 504us/step - loss: 0.8903 - accuracy: 0.6560 - val_loss: 0.8733 - val_accuracy: 0.6842\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 511us/step - loss: 0.8570 - accuracy: 0.6837 - val_loss: 0.8726 - val_accuracy: 0.7033\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 506us/step - loss: 0.8814 - accuracy: 0.6720 - val_loss: 0.8711 - val_accuracy: 0.6890\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 491us/step - loss: 0.8692 - accuracy: 0.6677 - val_loss: 0.8873 - val_accuracy: 0.6699\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 511us/step - loss: 0.8553 - accuracy: 0.6837 - val_loss: 0.8813 - val_accuracy: 0.6746\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 499us/step - loss: 0.8513 - accuracy: 0.6763 - val_loss: 0.8627 - val_accuracy: 0.6842\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 470us/step - loss: 0.8507 - accuracy: 0.6805 - val_loss: 0.8805 - val_accuracy: 0.6651\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 455us/step - loss: 0.8519 - accuracy: 0.6763 - val_loss: 0.8998 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 436us/step - loss: 0.8553 - accuracy: 0.6784 - val_loss: 0.8739 - val_accuracy: 0.6603\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 431us/step - loss: 0.8589 - accuracy: 0.6736 - val_loss: 0.8741 - val_accuracy: 0.6603\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 395us/step - loss: 0.8404 - accuracy: 0.6757 - val_loss: 0.8510 - val_accuracy: 0.6746\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 513us/step - loss: 0.8356 - accuracy: 0.6869 - val_loss: 0.8646 - val_accuracy: 0.6555\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 446us/step - loss: 0.8297 - accuracy: 0.6789 - val_loss: 0.8674 - val_accuracy: 0.6651\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 420us/step - loss: 0.7954 - accuracy: 0.7082 - val_loss: 0.8812 - val_accuracy: 0.6268\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 424us/step - loss: 0.8150 - accuracy: 0.6965 - val_loss: 0.8562 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 426us/step - loss: 0.8077 - accuracy: 0.7023 - val_loss: 0.8476 - val_accuracy: 0.6603\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 478us/step - loss: 0.7992 - accuracy: 0.6970 - val_loss: 0.8408 - val_accuracy: 0.6603\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 438us/step - loss: 0.7989 - accuracy: 0.6917 - val_loss: 0.8591 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 439us/step - loss: 0.8038 - accuracy: 0.6890 - val_loss: 0.8355 - val_accuracy: 0.6651\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 393us/step - loss: 0.7771 - accuracy: 0.7071 - val_loss: 0.8611 - val_accuracy: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 26/60 [34:56<39:52, 70.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2363 - accuracy: 0.4835 - val_loss: 1.2492 - val_accuracy: 0.4928\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1620 - accuracy: 0.5357 - val_loss: 1.1932 - val_accuracy: 0.4928\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1496 - accuracy: 0.5490 - val_loss: 1.1466 - val_accuracy: 0.5311\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1155 - accuracy: 0.5783 - val_loss: 1.1549 - val_accuracy: 0.5598\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1203 - accuracy: 0.5543 - val_loss: 1.1128 - val_accuracy: 0.5550\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0995 - accuracy: 0.5724 - val_loss: 1.1126 - val_accuracy: 0.5694\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0942 - accuracy: 0.5815 - val_loss: 1.0653 - val_accuracy: 0.5837\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0792 - accuracy: 0.5942 - val_loss: 1.1292 - val_accuracy: 0.5742\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0725 - accuracy: 0.5857 - val_loss: 1.0528 - val_accuracy: 0.6268\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0565 - accuracy: 0.6070 - val_loss: 1.0580 - val_accuracy: 0.5933\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0493 - accuracy: 0.6102 - val_loss: 1.0427 - val_accuracy: 0.6364\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0331 - accuracy: 0.6294 - val_loss: 1.0313 - val_accuracy: 0.6459\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0320 - accuracy: 0.6081 - val_loss: 1.0165 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0348 - accuracy: 0.6060 - val_loss: 1.0489 - val_accuracy: 0.6029\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0175 - accuracy: 0.6177 - val_loss: 1.0122 - val_accuracy: 0.6411\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9986 - accuracy: 0.6278 - val_loss: 1.0149 - val_accuracy: 0.6124\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 1.0074 - accuracy: 0.6145 - val_loss: 1.0174 - val_accuracy: 0.6220\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9967 - accuracy: 0.6177 - val_loss: 1.0051 - val_accuracy: 0.6364\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9909 - accuracy: 0.6198 - val_loss: 0.9688 - val_accuracy: 0.6603\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9819 - accuracy: 0.6315 - val_loss: 0.9906 - val_accuracy: 0.6364\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9760 - accuracy: 0.6241 - val_loss: 1.0007 - val_accuracy: 0.6077\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9661 - accuracy: 0.6289 - val_loss: 0.9981 - val_accuracy: 0.6411\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9624 - accuracy: 0.6358 - val_loss: 0.9684 - val_accuracy: 0.6220\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9263 - accuracy: 0.6597 - val_loss: 0.9682 - val_accuracy: 0.6220\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9345 - accuracy: 0.6443 - val_loss: 0.9375 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9278 - accuracy: 0.6470 - val_loss: 0.9408 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9251 - accuracy: 0.6448 - val_loss: 0.9574 - val_accuracy: 0.6411\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9102 - accuracy: 0.6565 - val_loss: 0.9487 - val_accuracy: 0.6411\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9078 - accuracy: 0.6544 - val_loss: 0.9300 - val_accuracy: 0.6651\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9025 - accuracy: 0.6587 - val_loss: 0.9317 - val_accuracy: 0.6555\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8908 - accuracy: 0.6688 - val_loss: 0.9364 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8812 - accuracy: 0.6651 - val_loss: 0.9503 - val_accuracy: 0.6459\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8880 - accuracy: 0.6619 - val_loss: 0.9450 - val_accuracy: 0.6459\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8821 - accuracy: 0.6635 - val_loss: 0.9416 - val_accuracy: 0.6316\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8557 - accuracy: 0.6778 - val_loss: 0.9356 - val_accuracy: 0.6507\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8576 - accuracy: 0.6747 - val_loss: 0.9248 - val_accuracy: 0.6364\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8380 - accuracy: 0.6816 - val_loss: 0.9392 - val_accuracy: 0.6220\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8463 - accuracy: 0.6768 - val_loss: 0.9310 - val_accuracy: 0.6268\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8394 - accuracy: 0.6821 - val_loss: 0.8870 - val_accuracy: 0.6938\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8462 - accuracy: 0.6826 - val_loss: 0.9314 - val_accuracy: 0.6172\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8240 - accuracy: 0.6832 - val_loss: 0.8788 - val_accuracy: 0.6794\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7924 - accuracy: 0.7167 - val_loss: 0.9225 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8150 - accuracy: 0.6816 - val_loss: 0.8624 - val_accuracy: 0.6651\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8176 - accuracy: 0.6832 - val_loss: 0.8542 - val_accuracy: 0.6603\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7941 - accuracy: 0.6991 - val_loss: 0.8819 - val_accuracy: 0.6603\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8070 - accuracy: 0.6917 - val_loss: 0.8542 - val_accuracy: 0.6699\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7936 - accuracy: 0.6960 - val_loss: 0.8535 - val_accuracy: 0.6699\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7871 - accuracy: 0.6997 - val_loss: 0.8750 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7904 - accuracy: 0.6906 - val_loss: 0.8341 - val_accuracy: 0.6555\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7760 - accuracy: 0.7023 - val_loss: 0.8160 - val_accuracy: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 27/60 [37:16<50:10, 91.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 791us/step - loss: 1.3431 - accuracy: 0.4004 - val_loss: 1.3369 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 342us/step - loss: 1.2931 - accuracy: 0.4420 - val_loss: 1.3093 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 320us/step - loss: 1.2490 - accuracy: 0.4622 - val_loss: 1.2707 - val_accuracy: 0.4067\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 317us/step - loss: 1.2183 - accuracy: 0.4755 - val_loss: 1.2346 - val_accuracy: 0.4306\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 315us/step - loss: 1.1953 - accuracy: 0.4862 - val_loss: 1.2049 - val_accuracy: 0.4545\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 1.1822 - accuracy: 0.4931 - val_loss: 1.1810 - val_accuracy: 0.4880\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 304us/step - loss: 1.1577 - accuracy: 0.5160 - val_loss: 1.1569 - val_accuracy: 0.5215\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 329us/step - loss: 1.1511 - accuracy: 0.5245 - val_loss: 1.1394 - val_accuracy: 0.5167\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 1.1331 - accuracy: 0.5463 - val_loss: 1.1304 - val_accuracy: 0.5455\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 1.1178 - accuracy: 0.5559 - val_loss: 1.1179 - val_accuracy: 0.5837\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 302us/step - loss: 1.1073 - accuracy: 0.5618 - val_loss: 1.0958 - val_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 300us/step - loss: 1.0895 - accuracy: 0.5612 - val_loss: 1.0975 - val_accuracy: 0.5694\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 320us/step - loss: 1.0987 - accuracy: 0.5687 - val_loss: 1.0968 - val_accuracy: 0.5742\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 336us/step - loss: 1.0950 - accuracy: 0.5548 - val_loss: 1.0831 - val_accuracy: 0.5742\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 413us/step - loss: 1.0832 - accuracy: 0.5756 - val_loss: 1.0885 - val_accuracy: 0.5598\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 1.0762 - accuracy: 0.5708 - val_loss: 1.0799 - val_accuracy: 0.5789\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 394us/step - loss: 1.0578 - accuracy: 0.5772 - val_loss: 1.0686 - val_accuracy: 0.5694\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 381us/step - loss: 1.0681 - accuracy: 0.5676 - val_loss: 1.0730 - val_accuracy: 0.5742\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 364us/step - loss: 1.0642 - accuracy: 0.5708 - val_loss: 1.0726 - val_accuracy: 0.5550\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 391us/step - loss: 1.0511 - accuracy: 0.5868 - val_loss: 1.0690 - val_accuracy: 0.5550\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 388us/step - loss: 1.0549 - accuracy: 0.5761 - val_loss: 1.0646 - val_accuracy: 0.5598\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 357us/step - loss: 1.0516 - accuracy: 0.5793 - val_loss: 1.0646 - val_accuracy: 0.5646\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 411us/step - loss: 1.0364 - accuracy: 0.5847 - val_loss: 1.0580 - val_accuracy: 0.5550\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 388us/step - loss: 1.0262 - accuracy: 0.5964 - val_loss: 1.0473 - val_accuracy: 0.5742\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 337us/step - loss: 1.0155 - accuracy: 0.6006 - val_loss: 1.0406 - val_accuracy: 0.5789\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 409us/step - loss: 1.0201 - accuracy: 0.5974 - val_loss: 1.0379 - val_accuracy: 0.5789\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 368us/step - loss: 1.0310 - accuracy: 0.5996 - val_loss: 1.0338 - val_accuracy: 0.5933\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 1.0233 - accuracy: 0.6033 - val_loss: 1.0268 - val_accuracy: 0.5789\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 281us/step - loss: 1.0111 - accuracy: 0.6006 - val_loss: 1.0187 - val_accuracy: 0.5885\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 1.0038 - accuracy: 0.6065 - val_loss: 1.0066 - val_accuracy: 0.5933\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 286us/step - loss: 1.0024 - accuracy: 0.6022 - val_loss: 0.9988 - val_accuracy: 0.6029\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 286us/step - loss: 0.9912 - accuracy: 0.6129 - val_loss: 1.0005 - val_accuracy: 0.6029\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.9960 - accuracy: 0.6187 - val_loss: 0.9914 - val_accuracy: 0.6124\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 302us/step - loss: 0.9610 - accuracy: 0.6379 - val_loss: 0.9935 - val_accuracy: 0.6172\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.9656 - accuracy: 0.6353 - val_loss: 0.9970 - val_accuracy: 0.6172\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 355us/step - loss: 0.9752 - accuracy: 0.6177 - val_loss: 0.9978 - val_accuracy: 0.6077\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.9581 - accuracy: 0.6283 - val_loss: 0.9827 - val_accuracy: 0.6220\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.9739 - accuracy: 0.6219 - val_loss: 0.9733 - val_accuracy: 0.6172\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.9543 - accuracy: 0.6305 - val_loss: 0.9694 - val_accuracy: 0.6220\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.9540 - accuracy: 0.6257 - val_loss: 0.9660 - val_accuracy: 0.6268\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 293us/step - loss: 0.9594 - accuracy: 0.6241 - val_loss: 0.9615 - val_accuracy: 0.6268\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.9500 - accuracy: 0.6342 - val_loss: 0.9632 - val_accuracy: 0.6316\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 414us/step - loss: 0.9510 - accuracy: 0.6310 - val_loss: 0.9605 - val_accuracy: 0.6364\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 372us/step - loss: 0.9335 - accuracy: 0.6310 - val_loss: 0.9555 - val_accuracy: 0.6268\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 324us/step - loss: 0.9152 - accuracy: 0.6480 - val_loss: 0.9521 - val_accuracy: 0.6364\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 380us/step - loss: 0.9292 - accuracy: 0.6454 - val_loss: 0.9496 - val_accuracy: 0.6459\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 372us/step - loss: 0.9346 - accuracy: 0.6422 - val_loss: 0.9523 - val_accuracy: 0.6411\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 359us/step - loss: 0.9174 - accuracy: 0.6544 - val_loss: 0.9490 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 327us/step - loss: 0.9240 - accuracy: 0.6422 - val_loss: 0.9493 - val_accuracy: 0.6459\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 333us/step - loss: 0.9371 - accuracy: 0.6400 - val_loss: 0.9487 - val_accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 28/60 [37:51<39:34, 74.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.2972 - accuracy: 0.4233 - val_loss: 1.2970 - val_accuracy: 0.4019\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 543us/step - loss: 1.2184 - accuracy: 0.5101 - val_loss: 1.2485 - val_accuracy: 0.4067\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 455us/step - loss: 1.1794 - accuracy: 0.5277 - val_loss: 1.1991 - val_accuracy: 0.5502\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 793us/step - loss: 1.1483 - accuracy: 0.5410 - val_loss: 1.1752 - val_accuracy: 0.5837\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 741us/step - loss: 1.1268 - accuracy: 0.5777 - val_loss: 1.1620 - val_accuracy: 0.5981\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 627us/step - loss: 1.1172 - accuracy: 0.5729 - val_loss: 1.1341 - val_accuracy: 0.5885\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 763us/step - loss: 1.1108 - accuracy: 0.5735 - val_loss: 1.1130 - val_accuracy: 0.5885\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 598us/step - loss: 1.0841 - accuracy: 0.5889 - val_loss: 1.0857 - val_accuracy: 0.6268\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 864us/step - loss: 1.0735 - accuracy: 0.5964 - val_loss: 1.0774 - val_accuracy: 0.6459\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 512us/step - loss: 1.0624 - accuracy: 0.5964 - val_loss: 1.0402 - val_accuracy: 0.6699\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 565us/step - loss: 1.0504 - accuracy: 0.6006 - val_loss: 1.0498 - val_accuracy: 0.6411\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 528us/step - loss: 1.0380 - accuracy: 0.6012 - val_loss: 1.0307 - val_accuracy: 0.6172\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 448us/step - loss: 1.0351 - accuracy: 0.5937 - val_loss: 1.0019 - val_accuracy: 0.6746\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 799us/step - loss: 1.0230 - accuracy: 0.6124 - val_loss: 1.0008 - val_accuracy: 0.6555\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 483us/step - loss: 1.0180 - accuracy: 0.6102 - val_loss: 0.9951 - val_accuracy: 0.6603\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 691us/step - loss: 0.9947 - accuracy: 0.6161 - val_loss: 0.9947 - val_accuracy: 0.6364\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 430us/step - loss: 0.9950 - accuracy: 0.6203 - val_loss: 0.9809 - val_accuracy: 0.6794\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 439us/step - loss: 0.9816 - accuracy: 0.6219 - val_loss: 0.9768 - val_accuracy: 0.6651\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 427us/step - loss: 0.9875 - accuracy: 0.6187 - val_loss: 0.9737 - val_accuracy: 0.6555\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 428us/step - loss: 0.9649 - accuracy: 0.6214 - val_loss: 0.9875 - val_accuracy: 0.6555\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 479us/step - loss: 0.9481 - accuracy: 0.6486 - val_loss: 0.9795 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 547us/step - loss: 0.9438 - accuracy: 0.6512 - val_loss: 0.9698 - val_accuracy: 0.6411\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 509us/step - loss: 0.9493 - accuracy: 0.6395 - val_loss: 0.9608 - val_accuracy: 0.6459\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 636us/step - loss: 0.9240 - accuracy: 0.6539 - val_loss: 0.9520 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 732us/step - loss: 0.9270 - accuracy: 0.6459 - val_loss: 0.9388 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 656us/step - loss: 0.9035 - accuracy: 0.6635 - val_loss: 0.9273 - val_accuracy: 0.6555\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 660us/step - loss: 0.9115 - accuracy: 0.6518 - val_loss: 0.9321 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 607us/step - loss: 0.9159 - accuracy: 0.6592 - val_loss: 0.9267 - val_accuracy: 0.6555\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 575us/step - loss: 0.9102 - accuracy: 0.6496 - val_loss: 0.9363 - val_accuracy: 0.6555\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 471us/step - loss: 0.8842 - accuracy: 0.6741 - val_loss: 0.9142 - val_accuracy: 0.6507\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 467us/step - loss: 0.8882 - accuracy: 0.6640 - val_loss: 0.9208 - val_accuracy: 0.6459\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 504us/step - loss: 0.9081 - accuracy: 0.6475 - val_loss: 0.9085 - val_accuracy: 0.6555\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 469us/step - loss: 0.8919 - accuracy: 0.6603 - val_loss: 0.9001 - val_accuracy: 0.6507\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 467us/step - loss: 0.8959 - accuracy: 0.6486 - val_loss: 0.9025 - val_accuracy: 0.6507\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 442us/step - loss: 0.8872 - accuracy: 0.6571 - val_loss: 0.9080 - val_accuracy: 0.6507\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 508us/step - loss: 0.8593 - accuracy: 0.6699 - val_loss: 0.8924 - val_accuracy: 0.6651\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 487us/step - loss: 0.8625 - accuracy: 0.6640 - val_loss: 0.9087 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 468us/step - loss: 0.8530 - accuracy: 0.6752 - val_loss: 0.9035 - val_accuracy: 0.6411\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 512us/step - loss: 0.8607 - accuracy: 0.6651 - val_loss: 0.9094 - val_accuracy: 0.6268\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 496us/step - loss: 0.8560 - accuracy: 0.6619 - val_loss: 0.9056 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 472us/step - loss: 0.8446 - accuracy: 0.6848 - val_loss: 0.8949 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 483us/step - loss: 0.8550 - accuracy: 0.6763 - val_loss: 0.9013 - val_accuracy: 0.6268\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 518us/step - loss: 0.8355 - accuracy: 0.6789 - val_loss: 0.9019 - val_accuracy: 0.6411\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 526us/step - loss: 0.8183 - accuracy: 0.6858 - val_loss: 0.8874 - val_accuracy: 0.6459\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 512us/step - loss: 0.8410 - accuracy: 0.6752 - val_loss: 0.8780 - val_accuracy: 0.6603\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 416us/step - loss: 0.8208 - accuracy: 0.6821 - val_loss: 0.8869 - val_accuracy: 0.6364\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 478us/step - loss: 0.8177 - accuracy: 0.6848 - val_loss: 0.8678 - val_accuracy: 0.6651\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 526us/step - loss: 0.8264 - accuracy: 0.6832 - val_loss: 0.8782 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 406us/step - loss: 0.8214 - accuracy: 0.6826 - val_loss: 0.8848 - val_accuracy: 0.6411\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 603us/step - loss: 0.8011 - accuracy: 0.6858 - val_loss: 0.8652 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 29/60 [38:46<35:24, 68.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 5s 2ms/step - loss: 1.2493 - accuracy: 0.4840 - val_loss: 1.2502 - val_accuracy: 0.4306\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1919 - accuracy: 0.5138 - val_loss: 1.2015 - val_accuracy: 0.4880\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1842 - accuracy: 0.5165 - val_loss: 1.1799 - val_accuracy: 0.4737\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1559 - accuracy: 0.5101 - val_loss: 1.1288 - val_accuracy: 0.5215\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1544 - accuracy: 0.5064 - val_loss: 1.1265 - val_accuracy: 0.5120\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1406 - accuracy: 0.5176 - val_loss: 1.1231 - val_accuracy: 0.5120\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1187 - accuracy: 0.5293 - val_loss: 1.0927 - val_accuracy: 0.5120\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1126 - accuracy: 0.5192 - val_loss: 1.0695 - val_accuracy: 0.5359\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1106 - accuracy: 0.5277 - val_loss: 1.0969 - val_accuracy: 0.5359\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.1061 - accuracy: 0.5394 - val_loss: 1.0576 - val_accuracy: 0.6029\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0756 - accuracy: 0.5948 - val_loss: 1.0834 - val_accuracy: 0.5789\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0741 - accuracy: 0.5793 - val_loss: 1.0555 - val_accuracy: 0.5981\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0802 - accuracy: 0.5783 - val_loss: 1.0570 - val_accuracy: 0.5981\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0593 - accuracy: 0.6038 - val_loss: 1.0815 - val_accuracy: 0.5646\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0520 - accuracy: 0.6065 - val_loss: 1.0478 - val_accuracy: 0.5837\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 5s 3ms/step - loss: 1.0369 - accuracy: 0.6070 - val_loss: 1.0727 - val_accuracy: 0.5789\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 1.0359 - accuracy: 0.6033 - val_loss: 1.0083 - val_accuracy: 0.6172\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0334 - accuracy: 0.6017 - val_loss: 1.0308 - val_accuracy: 0.6077\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0201 - accuracy: 0.6012 - val_loss: 1.0385 - val_accuracy: 0.5885\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0066 - accuracy: 0.6113 - val_loss: 0.9772 - val_accuracy: 0.6459\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0154 - accuracy: 0.6140 - val_loss: 1.0191 - val_accuracy: 0.5933\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9965 - accuracy: 0.6155 - val_loss: 1.0407 - val_accuracy: 0.5789\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0128 - accuracy: 0.6140 - val_loss: 1.0489 - val_accuracy: 0.5694\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9940 - accuracy: 0.6235 - val_loss: 0.9868 - val_accuracy: 0.6220\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9867 - accuracy: 0.6235 - val_loss: 1.0217 - val_accuracy: 0.5933\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9744 - accuracy: 0.6294 - val_loss: 0.9700 - val_accuracy: 0.6316\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9529 - accuracy: 0.6464 - val_loss: 0.9697 - val_accuracy: 0.6077\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9743 - accuracy: 0.6251 - val_loss: 0.9890 - val_accuracy: 0.6172\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9562 - accuracy: 0.6384 - val_loss: 0.9690 - val_accuracy: 0.6268\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9551 - accuracy: 0.6358 - val_loss: 0.9472 - val_accuracy: 0.6364\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9449 - accuracy: 0.6384 - val_loss: 0.9614 - val_accuracy: 0.6268\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9431 - accuracy: 0.6363 - val_loss: 0.9698 - val_accuracy: 0.6220\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9376 - accuracy: 0.6390 - val_loss: 0.9458 - val_accuracy: 0.6124\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9358 - accuracy: 0.6363 - val_loss: 0.9226 - val_accuracy: 0.6220\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9328 - accuracy: 0.6353 - val_loss: 0.9301 - val_accuracy: 0.6411\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9297 - accuracy: 0.6310 - val_loss: 0.9092 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9342 - accuracy: 0.6406 - val_loss: 0.9143 - val_accuracy: 0.6507\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9063 - accuracy: 0.6512 - val_loss: 0.9501 - val_accuracy: 0.6124\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9091 - accuracy: 0.6528 - val_loss: 0.9220 - val_accuracy: 0.6172\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9076 - accuracy: 0.6448 - val_loss: 0.9015 - val_accuracy: 0.6555\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9012 - accuracy: 0.6550 - val_loss: 0.9085 - val_accuracy: 0.6268\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8861 - accuracy: 0.6619 - val_loss: 0.9142 - val_accuracy: 0.6220\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8801 - accuracy: 0.6656 - val_loss: 0.9001 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8650 - accuracy: 0.6699 - val_loss: 0.8852 - val_accuracy: 0.6316\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8764 - accuracy: 0.6640 - val_loss: 0.8872 - val_accuracy: 0.6364\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8707 - accuracy: 0.6667 - val_loss: 0.8885 - val_accuracy: 0.6411\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8657 - accuracy: 0.6656 - val_loss: 0.8983 - val_accuracy: 0.6411\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8770 - accuracy: 0.6683 - val_loss: 0.9063 - val_accuracy: 0.6459\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8479 - accuracy: 0.6768 - val_loss: 0.9088 - val_accuracy: 0.6459\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.8211 - accuracy: 0.6965 - val_loss: 0.9096 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 30/60 [41:24<47:36, 95.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 818us/step - loss: 1.3349 - accuracy: 0.4132 - val_loss: 1.3679 - val_accuracy: 0.3493\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 1.2754 - accuracy: 0.4909 - val_loss: 1.3391 - val_accuracy: 0.4019\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 218us/step - loss: 1.2298 - accuracy: 0.5341 - val_loss: 1.3042 - val_accuracy: 0.4067\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 1.1904 - accuracy: 0.5639 - val_loss: 1.2682 - val_accuracy: 0.4545\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 195us/step - loss: 1.1584 - accuracy: 0.5761 - val_loss: 1.2346 - val_accuracy: 0.5120\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 167us/step - loss: 1.1313 - accuracy: 0.5974 - val_loss: 1.1983 - val_accuracy: 0.5167\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 166us/step - loss: 1.1068 - accuracy: 0.6060 - val_loss: 1.1660 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 185us/step - loss: 1.0856 - accuracy: 0.6134 - val_loss: 1.1334 - val_accuracy: 0.5837\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 164us/step - loss: 1.0649 - accuracy: 0.6225 - val_loss: 1.1022 - val_accuracy: 0.5694\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 181us/step - loss: 1.0515 - accuracy: 0.6187 - val_loss: 1.0855 - val_accuracy: 0.5885\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.0334 - accuracy: 0.6331 - val_loss: 1.0774 - val_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.0144 - accuracy: 0.6390 - val_loss: 1.0569 - val_accuracy: 0.5742\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 206us/step - loss: 1.0032 - accuracy: 0.6454 - val_loss: 1.0391 - val_accuracy: 0.5885\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 133us/step - loss: 0.9865 - accuracy: 0.6518 - val_loss: 1.0293 - val_accuracy: 0.5837\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 155us/step - loss: 0.9677 - accuracy: 0.6523 - val_loss: 1.0143 - val_accuracy: 0.6077\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 0.9601 - accuracy: 0.6576 - val_loss: 1.0110 - val_accuracy: 0.6029\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 0.9498 - accuracy: 0.6560 - val_loss: 1.0169 - val_accuracy: 0.6029\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 202us/step - loss: 0.9340 - accuracy: 0.6656 - val_loss: 0.9888 - val_accuracy: 0.5933\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 120us/step - loss: 0.9216 - accuracy: 0.6651 - val_loss: 0.9941 - val_accuracy: 0.5789\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 205us/step - loss: 0.9065 - accuracy: 0.6709 - val_loss: 0.9809 - val_accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 182us/step - loss: 0.8930 - accuracy: 0.6752 - val_loss: 0.9721 - val_accuracy: 0.5933\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 0.8800 - accuracy: 0.6960 - val_loss: 0.9642 - val_accuracy: 0.6029\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.70 - 0s 212us/step - loss: 0.8656 - accuracy: 0.7082 - val_loss: 0.9548 - val_accuracy: 0.6316\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 0.8485 - accuracy: 0.7311 - val_loss: 0.9626 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8384 - accuracy: 0.7343 - val_loss: 0.9381 - val_accuracy: 0.6459\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 0.8231 - accuracy: 0.7439 - val_loss: 0.9437 - val_accuracy: 0.6507\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 193us/step - loss: 0.8137 - accuracy: 0.7471 - val_loss: 0.9233 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 233us/step - loss: 0.8039 - accuracy: 0.7524 - val_loss: 0.9158 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 176us/step - loss: 0.7871 - accuracy: 0.7583 - val_loss: 0.9228 - val_accuracy: 0.6411\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 121us/step - loss: 0.7748 - accuracy: 0.7604 - val_loss: 0.8978 - val_accuracy: 0.6603\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 117us/step - loss: 0.7660 - accuracy: 0.7636 - val_loss: 0.8974 - val_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 122us/step - loss: 0.7639 - accuracy: 0.7593 - val_loss: 0.8950 - val_accuracy: 0.6555\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 228us/step - loss: 0.7519 - accuracy: 0.7657 - val_loss: 0.8977 - val_accuracy: 0.6459\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 131us/step - loss: 0.7417 - accuracy: 0.7630 - val_loss: 0.8850 - val_accuracy: 0.6651\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 130us/step - loss: 0.7365 - accuracy: 0.7641 - val_loss: 0.9052 - val_accuracy: 0.6411\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 124us/step - loss: 0.7198 - accuracy: 0.7732 - val_loss: 0.8902 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 123us/step - loss: 0.7060 - accuracy: 0.7796 - val_loss: 0.8871 - val_accuracy: 0.6651\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 118us/step - loss: 0.7037 - accuracy: 0.7790 - val_loss: 0.9090 - val_accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 129us/step - loss: 0.6979 - accuracy: 0.7780 - val_loss: 0.9101 - val_accuracy: 0.6316\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 131us/step - loss: 0.6859 - accuracy: 0.7780 - val_loss: 0.8875 - val_accuracy: 0.6555\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 123us/step - loss: 0.6774 - accuracy: 0.7865 - val_loss: 0.9005 - val_accuracy: 0.6459\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 122us/step - loss: 0.6777 - accuracy: 0.7822 - val_loss: 0.8831 - val_accuracy: 0.6603\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 128us/step - loss: 0.6747 - accuracy: 0.7806 - val_loss: 0.9119 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 120us/step - loss: 0.6676 - accuracy: 0.7886 - val_loss: 0.8628 - val_accuracy: 0.6699\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 128us/step - loss: 0.6569 - accuracy: 0.7923 - val_loss: 0.9081 - val_accuracy: 0.6411\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 126us/step - loss: 0.6519 - accuracy: 0.7886 - val_loss: 0.8843 - val_accuracy: 0.6555\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 125us/step - loss: 0.6505 - accuracy: 0.7870 - val_loss: 0.8777 - val_accuracy: 0.6603\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 176us/step - loss: 0.6445 - accuracy: 0.7961 - val_loss: 0.8796 - val_accuracy: 0.6459\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 126us/step - loss: 0.6402 - accuracy: 0.7966 - val_loss: 0.8692 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 123us/step - loss: 0.6364 - accuracy: 0.7902 - val_loss: 0.8955 - val_accuracy: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 31/60 [41:43<35:02, 72.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 811us/step - loss: 1.2877 - accuracy: 0.4324 - val_loss: 1.3148 - val_accuracy: 0.5502\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 326us/step - loss: 1.1859 - accuracy: 0.5889 - val_loss: 1.2650 - val_accuracy: 0.5167\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 398us/step - loss: 1.1306 - accuracy: 0.6358 - val_loss: 1.2193 - val_accuracy: 0.5359\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 377us/step - loss: 1.0924 - accuracy: 0.6347 - val_loss: 1.2024 - val_accuracy: 0.5598\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 358us/step - loss: 1.0653 - accuracy: 0.6406 - val_loss: 1.1477 - val_accuracy: 0.5646\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 299us/step - loss: 1.0375 - accuracy: 0.6544 - val_loss: 1.1381 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 302us/step - loss: 1.0141 - accuracy: 0.6475 - val_loss: 1.0706 - val_accuracy: 0.5981\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 354us/step - loss: 0.9848 - accuracy: 0.6581 - val_loss: 1.0737 - val_accuracy: 0.5837\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 262us/step - loss: 0.9647 - accuracy: 0.6725 - val_loss: 1.0497 - val_accuracy: 0.5742\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.9333 - accuracy: 0.7194 - val_loss: 1.0203 - val_accuracy: 0.5885\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 248us/step - loss: 0.9092 - accuracy: 0.7327 - val_loss: 1.0192 - val_accuracy: 0.6124\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.8945 - accuracy: 0.7386 - val_loss: 0.9803 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 248us/step - loss: 0.8824 - accuracy: 0.7386 - val_loss: 0.9675 - val_accuracy: 0.6651\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 243us/step - loss: 0.8544 - accuracy: 0.7545 - val_loss: 0.9605 - val_accuracy: 0.6555\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.8432 - accuracy: 0.7545 - val_loss: 0.9830 - val_accuracy: 0.6507\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 241us/step - loss: 0.8322 - accuracy: 0.7524 - val_loss: 0.9387 - val_accuracy: 0.6555\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.8124 - accuracy: 0.7614 - val_loss: 0.9422 - val_accuracy: 0.6603\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.7940 - accuracy: 0.7668 - val_loss: 0.9107 - val_accuracy: 0.6699\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.7887 - accuracy: 0.7630 - val_loss: 0.9268 - val_accuracy: 0.6603\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 246us/step - loss: 0.7648 - accuracy: 0.7689 - val_loss: 0.9119 - val_accuracy: 0.6603\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 0.7501 - accuracy: 0.7721 - val_loss: 0.9442 - val_accuracy: 0.6651\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.7421 - accuracy: 0.7801 - val_loss: 0.9055 - val_accuracy: 0.6794\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.7297 - accuracy: 0.7790 - val_loss: 0.9257 - val_accuracy: 0.6603\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 321us/step - loss: 0.7227 - accuracy: 0.7769 - val_loss: 0.9286 - val_accuracy: 0.6746\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 337us/step - loss: 0.7057 - accuracy: 0.7833 - val_loss: 0.8834 - val_accuracy: 0.6746\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 0.6970 - accuracy: 0.7881 - val_loss: 0.9098 - val_accuracy: 0.6699\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 0.6910 - accuracy: 0.7849 - val_loss: 0.8825 - val_accuracy: 0.6746\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 343us/step - loss: 0.6948 - accuracy: 0.7785 - val_loss: 0.9010 - val_accuracy: 0.6842\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 312us/step - loss: 0.6848 - accuracy: 0.7827 - val_loss: 0.8909 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 354us/step - loss: 0.6698 - accuracy: 0.7891 - val_loss: 0.8947 - val_accuracy: 0.6842\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 251us/step - loss: 0.6634 - accuracy: 0.7822 - val_loss: 0.8667 - val_accuracy: 0.6938\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.6483 - accuracy: 0.7881 - val_loss: 0.9246 - val_accuracy: 0.6603\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.6463 - accuracy: 0.7886 - val_loss: 0.9102 - val_accuracy: 0.6555\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 240us/step - loss: 0.6340 - accuracy: 0.7961 - val_loss: 0.9210 - val_accuracy: 0.6651\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 506us/step - loss: 0.6267 - accuracy: 0.7939 - val_loss: 0.9422 - val_accuracy: 0.6507\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.6197 - accuracy: 0.7945 - val_loss: 0.9001 - val_accuracy: 0.6651\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.6132 - accuracy: 0.8009 - val_loss: 0.8608 - val_accuracy: 0.6986\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 264us/step - loss: 0.6102 - accuracy: 0.7950 - val_loss: 0.8737 - val_accuracy: 0.6938\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.6002 - accuracy: 0.7993 - val_loss: 0.9146 - val_accuracy: 0.6746\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 325us/step - loss: 0.5955 - accuracy: 0.8035 - val_loss: 0.9178 - val_accuracy: 0.6746\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 330us/step - loss: 0.5910 - accuracy: 0.8003 - val_loss: 0.9334 - val_accuracy: 0.6555\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 483us/step - loss: 0.5859 - accuracy: 0.8003 - val_loss: 0.9134 - val_accuracy: 0.6746\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 328us/step - loss: 0.5799 - accuracy: 0.8030 - val_loss: 0.9685 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 360us/step - loss: 0.5754 - accuracy: 0.7998 - val_loss: 0.9392 - val_accuracy: 0.6651\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 340us/step - loss: 0.5686 - accuracy: 0.8072 - val_loss: 0.9565 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 0.5687 - accuracy: 0.8019 - val_loss: 0.9629 - val_accuracy: 0.6555\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 348us/step - loss: 0.5652 - accuracy: 0.8062 - val_loss: 0.9285 - val_accuracy: 0.6603\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.5663 - accuracy: 0.8003 - val_loss: 0.9233 - val_accuracy: 0.6651\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 0.5670 - accuracy: 0.7987 - val_loss: 0.9252 - val_accuracy: 0.6794\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 247us/step - loss: 0.5564 - accuracy: 0.8067 - val_loss: 0.9212 - val_accuracy: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 32/60 [42:14<27:58, 59.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.2069 - accuracy: 0.5133 - val_loss: 1.2284 - val_accuracy: 0.6077\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 820us/step - loss: 1.0924 - accuracy: 0.6363 - val_loss: 1.2161 - val_accuracy: 0.5933\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0522 - accuracy: 0.6693 - val_loss: 1.1479 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0268 - accuracy: 0.6704 - val_loss: 1.1492 - val_accuracy: 0.5694\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 849us/step - loss: 1.0049 - accuracy: 0.6853 - val_loss: 1.0820 - val_accuracy: 0.6555\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 842us/step - loss: 0.9795 - accuracy: 0.6991 - val_loss: 1.0586 - val_accuracy: 0.6746\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 904us/step - loss: 0.9595 - accuracy: 0.6954 - val_loss: 1.0547 - val_accuracy: 0.6459\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9357 - accuracy: 0.7167 - val_loss: 1.0668 - val_accuracy: 0.6124\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9216 - accuracy: 0.7103 - val_loss: 1.0632 - val_accuracy: 0.5837\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9003 - accuracy: 0.7252 - val_loss: 1.0205 - val_accuracy: 0.6364\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8898 - accuracy: 0.7258 - val_loss: 1.0207 - val_accuracy: 0.6316\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8711 - accuracy: 0.7332 - val_loss: 0.9876 - val_accuracy: 0.6603\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8672 - accuracy: 0.7242 - val_loss: 1.0129 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 867us/step - loss: 0.8568 - accuracy: 0.7332 - val_loss: 1.0313 - val_accuracy: 0.6172\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 912us/step - loss: 0.8572 - accuracy: 0.7359 - val_loss: 0.9671 - val_accuracy: 0.6555\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 826us/step - loss: 0.8382 - accuracy: 0.7359 - val_loss: 1.0057 - val_accuracy: 0.6364\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 834us/step - loss: 0.8356 - accuracy: 0.7391 - val_loss: 1.0005 - val_accuracy: 0.6124\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 901us/step - loss: 0.8128 - accuracy: 0.7375 - val_loss: 0.9842 - val_accuracy: 0.6411\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 903us/step - loss: 0.7947 - accuracy: 0.7583 - val_loss: 0.9458 - val_accuracy: 0.6746\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 904us/step - loss: 0.7897 - accuracy: 0.7535 - val_loss: 0.9522 - val_accuracy: 0.6603\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 957us/step - loss: 0.7801 - accuracy: 0.7561 - val_loss: 0.9619 - val_accuracy: 0.6507\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.7588 - val_loss: 1.0006 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7728 - accuracy: 0.7556 - val_loss: 0.9566 - val_accuracy: 0.6555\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7461 - accuracy: 0.7668 - val_loss: 0.9742 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7302 - accuracy: 0.7737 - val_loss: 0.9912 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 881us/step - loss: 0.7411 - accuracy: 0.7646 - val_loss: 0.9324 - val_accuracy: 0.6651\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 924us/step - loss: 0.7392 - accuracy: 0.7710 - val_loss: 0.9086 - val_accuracy: 0.6938\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 901us/step - loss: 0.7410 - accuracy: 0.7678 - val_loss: 0.9231 - val_accuracy: 0.6746\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 838us/step - loss: 0.7154 - accuracy: 0.7790 - val_loss: 0.9337 - val_accuracy: 0.6746\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 833us/step - loss: 0.7017 - accuracy: 0.7806 - val_loss: 0.9966 - val_accuracy: 0.6268\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 827us/step - loss: 0.6994 - accuracy: 0.7758 - val_loss: 0.9618 - val_accuracy: 0.6507\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 798us/step - loss: 0.6964 - accuracy: 0.7843 - val_loss: 0.9508 - val_accuracy: 0.6411\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 793us/step - loss: 0.6895 - accuracy: 0.7827 - val_loss: 0.9167 - val_accuracy: 0.6651\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 868us/step - loss: 0.6875 - accuracy: 0.7843 - val_loss: 0.9221 - val_accuracy: 0.6555\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6865 - accuracy: 0.7785 - val_loss: 0.9460 - val_accuracy: 0.6603\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6834 - accuracy: 0.7838 - val_loss: 0.9236 - val_accuracy: 0.6699\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6686 - accuracy: 0.7923 - val_loss: 0.9354 - val_accuracy: 0.6603\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 889us/step - loss: 0.6707 - accuracy: 0.7870 - val_loss: 1.0029 - val_accuracy: 0.6172\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 862us/step - loss: 0.6598 - accuracy: 0.7870 - val_loss: 0.9244 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 883us/step - loss: 0.6640 - accuracy: 0.7875 - val_loss: 0.9397 - val_accuracy: 0.6651\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6543 - accuracy: 0.7913 - val_loss: 0.9831 - val_accuracy: 0.6364\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 964us/step - loss: 0.6526 - accuracy: 0.7881 - val_loss: 0.9017 - val_accuracy: 0.6746\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6457 - accuracy: 0.7934 - val_loss: 0.9638 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6398 - accuracy: 0.7923 - val_loss: 0.9656 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6344 - accuracy: 0.7993 - val_loss: 0.9020 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6309 - accuracy: 0.7966 - val_loss: 0.9033 - val_accuracy: 0.6794\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6254 - accuracy: 0.7961 - val_loss: 0.9337 - val_accuracy: 0.6603\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6125 - accuracy: 0.8056 - val_loss: 0.9136 - val_accuracy: 0.6651\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6140 - accuracy: 0.7993 - val_loss: 0.9614 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6163 - accuracy: 0.7993 - val_loss: 0.9477 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 33/60 [43:56<32:41, 72.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 644us/step - loss: 1.3533 - accuracy: 0.3179 - val_loss: 1.3654 - val_accuracy: 0.3062\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 185us/step - loss: 1.2864 - accuracy: 0.4457 - val_loss: 1.3369 - val_accuracy: 0.4689\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 186us/step - loss: 1.2390 - accuracy: 0.4867 - val_loss: 1.3054 - val_accuracy: 0.5311\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 184us/step - loss: 1.1962 - accuracy: 0.5245 - val_loss: 1.2575 - val_accuracy: 0.5072\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 1.1598 - accuracy: 0.5351 - val_loss: 1.2166 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 1.1328 - accuracy: 0.5389 - val_loss: 1.1818 - val_accuracy: 0.5598\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 1.1053 - accuracy: 0.5474 - val_loss: 1.1528 - val_accuracy: 0.5646\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 228us/step - loss: 1.0792 - accuracy: 0.5650 - val_loss: 1.1263 - val_accuracy: 0.5694\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 204us/step - loss: 1.0594 - accuracy: 0.5879 - val_loss: 1.0931 - val_accuracy: 0.5694\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 230us/step - loss: 1.0382 - accuracy: 0.6235 - val_loss: 1.0627 - val_accuracy: 0.6029\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 224us/step - loss: 1.0170 - accuracy: 0.6321 - val_loss: 1.0500 - val_accuracy: 0.6029\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 176us/step - loss: 1.0003 - accuracy: 0.6528 - val_loss: 1.0389 - val_accuracy: 0.5981\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.9768 - accuracy: 0.6688 - val_loss: 1.0089 - val_accuracy: 0.6411\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 213us/step - loss: 0.9652 - accuracy: 0.6672 - val_loss: 0.9976 - val_accuracy: 0.6268\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 0.9388 - accuracy: 0.6944 - val_loss: 0.9815 - val_accuracy: 0.6316\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 210us/step - loss: 0.9266 - accuracy: 0.6954 - val_loss: 0.9739 - val_accuracy: 0.6411\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 0.9158 - accuracy: 0.6938 - val_loss: 0.9636 - val_accuracy: 0.6459\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 154us/step - loss: 0.8946 - accuracy: 0.7034 - val_loss: 0.9777 - val_accuracy: 0.6172\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 160us/step - loss: 0.8872 - accuracy: 0.7077 - val_loss: 0.9502 - val_accuracy: 0.6507\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 185us/step - loss: 0.8630 - accuracy: 0.7167 - val_loss: 0.9509 - val_accuracy: 0.6364\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 159us/step - loss: 0.8633 - accuracy: 0.7151 - val_loss: 0.9442 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 162us/step - loss: 0.8456 - accuracy: 0.7220 - val_loss: 0.9368 - val_accuracy: 0.6364\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 189us/step - loss: 0.8238 - accuracy: 0.7370 - val_loss: 0.9317 - val_accuracy: 0.6507\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 226us/step - loss: 0.8305 - accuracy: 0.7268 - val_loss: 0.9322 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 0.8156 - accuracy: 0.7316 - val_loss: 0.9256 - val_accuracy: 0.6459\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 158us/step - loss: 0.8009 - accuracy: 0.7364 - val_loss: 0.9101 - val_accuracy: 0.6699\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 148us/step - loss: 0.8071 - accuracy: 0.7338 - val_loss: 0.9221 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 159us/step - loss: 0.7843 - accuracy: 0.7471 - val_loss: 0.9104 - val_accuracy: 0.6555\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 139us/step - loss: 0.7824 - accuracy: 0.7386 - val_loss: 0.9290 - val_accuracy: 0.6411\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 140us/step - loss: 0.7671 - accuracy: 0.7519 - val_loss: 0.9137 - val_accuracy: 0.6411\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 141us/step - loss: 0.7701 - accuracy: 0.7428 - val_loss: 0.9074 - val_accuracy: 0.6459\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 154us/step - loss: 0.7596 - accuracy: 0.7492 - val_loss: 0.9249 - val_accuracy: 0.6459\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 0.7616 - accuracy: 0.7465 - val_loss: 0.8881 - val_accuracy: 0.6842\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 155us/step - loss: 0.7458 - accuracy: 0.7577 - val_loss: 0.8937 - val_accuracy: 0.6746\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 160us/step - loss: 0.7575 - accuracy: 0.7433 - val_loss: 0.8979 - val_accuracy: 0.6651\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 213us/step - loss: 0.7416 - accuracy: 0.7572 - val_loss: 0.8958 - val_accuracy: 0.6699\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 195us/step - loss: 0.7441 - accuracy: 0.7497 - val_loss: 0.8758 - val_accuracy: 0.6842\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 186us/step - loss: 0.7375 - accuracy: 0.7561 - val_loss: 0.8773 - val_accuracy: 0.6603\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 241us/step - loss: 0.7309 - accuracy: 0.7604 - val_loss: 0.8901 - val_accuracy: 0.6603\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 213us/step - loss: 0.7274 - accuracy: 0.7567 - val_loss: 0.8911 - val_accuracy: 0.6651\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 164us/step - loss: 0.7138 - accuracy: 0.7572 - val_loss: 0.9142 - val_accuracy: 0.6459\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 0.7164 - accuracy: 0.7614 - val_loss: 0.9047 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 159us/step - loss: 0.7176 - accuracy: 0.7540 - val_loss: 0.9237 - val_accuracy: 0.6411\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 0.7035 - accuracy: 0.7662 - val_loss: 0.9144 - val_accuracy: 0.6316\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.7029 - accuracy: 0.7657 - val_loss: 0.9180 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 199us/step - loss: 0.6921 - accuracy: 0.7684 - val_loss: 0.9065 - val_accuracy: 0.6459\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.6908 - accuracy: 0.7673 - val_loss: 0.9265 - val_accuracy: 0.6268\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.6790 - accuracy: 0.7684 - val_loss: 0.9092 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 155us/step - loss: 0.6885 - accuracy: 0.7609 - val_loss: 0.9193 - val_accuracy: 0.6459\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 161us/step - loss: 0.6904 - accuracy: 0.7614 - val_loss: 0.9318 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 34/60 [44:16<24:38, 56.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 951us/step - loss: 1.2940 - accuracy: 0.4329 - val_loss: 1.3346 - val_accuracy: 0.4689\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 376us/step - loss: 1.1866 - accuracy: 0.5777 - val_loss: 1.2714 - val_accuracy: 0.5359\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 476us/step - loss: 1.1454 - accuracy: 0.6006 - val_loss: 1.2267 - val_accuracy: 0.5455\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 414us/step - loss: 1.1176 - accuracy: 0.6209 - val_loss: 1.2040 - val_accuracy: 0.5215\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 436us/step - loss: 1.0859 - accuracy: 0.6565 - val_loss: 1.1480 - val_accuracy: 0.5837\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 376us/step - loss: 1.0573 - accuracy: 0.6688 - val_loss: 1.1375 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 376us/step - loss: 1.0369 - accuracy: 0.6778 - val_loss: 1.1015 - val_accuracy: 0.6172\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 438us/step - loss: 1.0082 - accuracy: 0.6965 - val_loss: 1.0563 - val_accuracy: 0.6364\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 406us/step - loss: 0.9869 - accuracy: 0.7061 - val_loss: 1.0824 - val_accuracy: 0.5885\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 396us/step - loss: 0.9702 - accuracy: 0.7114 - val_loss: 1.0240 - val_accuracy: 0.6364\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 341us/step - loss: 0.9485 - accuracy: 0.7119 - val_loss: 0.9988 - val_accuracy: 0.6890\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 463us/step - loss: 0.9337 - accuracy: 0.7103 - val_loss: 1.0024 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 333us/step - loss: 0.9186 - accuracy: 0.7242 - val_loss: 1.0042 - val_accuracy: 0.6507\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 389us/step - loss: 0.8971 - accuracy: 0.7258 - val_loss: 0.9787 - val_accuracy: 0.6603\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 365us/step - loss: 0.8754 - accuracy: 0.7412 - val_loss: 0.9533 - val_accuracy: 0.6651\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 348us/step - loss: 0.8681 - accuracy: 0.7401 - val_loss: 0.9778 - val_accuracy: 0.6411\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 349us/step - loss: 0.8548 - accuracy: 0.7375 - val_loss: 0.9607 - val_accuracy: 0.6364\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 386us/step - loss: 0.8381 - accuracy: 0.7460 - val_loss: 0.9455 - val_accuracy: 0.6746\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 385us/step - loss: 0.8246 - accuracy: 0.7492 - val_loss: 0.9359 - val_accuracy: 0.6794\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 384us/step - loss: 0.8089 - accuracy: 0.7524 - val_loss: 0.9090 - val_accuracy: 0.6842\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 456us/step - loss: 0.8101 - accuracy: 0.7439 - val_loss: 0.9524 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 406us/step - loss: 0.7856 - accuracy: 0.7620 - val_loss: 0.9232 - val_accuracy: 0.6746\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 379us/step - loss: 0.7730 - accuracy: 0.7609 - val_loss: 0.9190 - val_accuracy: 0.6794\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 345us/step - loss: 0.7677 - accuracy: 0.7625 - val_loss: 0.9099 - val_accuracy: 0.6746\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 343us/step - loss: 0.7543 - accuracy: 0.7689 - val_loss: 0.8658 - val_accuracy: 0.6986\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 345us/step - loss: 0.7373 - accuracy: 0.7716 - val_loss: 0.9172 - val_accuracy: 0.6555\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 347us/step - loss: 0.7328 - accuracy: 0.7753 - val_loss: 0.8859 - val_accuracy: 0.6842\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 343us/step - loss: 0.7199 - accuracy: 0.7785 - val_loss: 0.9098 - val_accuracy: 0.6746\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 366us/step - loss: 0.7183 - accuracy: 0.7822 - val_loss: 0.9258 - val_accuracy: 0.6603\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 324us/step - loss: 0.6997 - accuracy: 0.7891 - val_loss: 0.9102 - val_accuracy: 0.6746\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 346us/step - loss: 0.7107 - accuracy: 0.7737 - val_loss: 0.9027 - val_accuracy: 0.6699\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 344us/step - loss: 0.6865 - accuracy: 0.7891 - val_loss: 0.8796 - val_accuracy: 0.6699\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 473us/step - loss: 0.6847 - accuracy: 0.7865 - val_loss: 0.9199 - val_accuracy: 0.6555\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 443us/step - loss: 0.6710 - accuracy: 0.7955 - val_loss: 0.8736 - val_accuracy: 0.6794\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 445us/step - loss: 0.6717 - accuracy: 0.7907 - val_loss: 0.8953 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 374us/step - loss: 0.6720 - accuracy: 0.7849 - val_loss: 0.8702 - val_accuracy: 0.6842\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 320us/step - loss: 0.6555 - accuracy: 0.7977 - val_loss: 0.9159 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.6539 - accuracy: 0.7902 - val_loss: 0.8813 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.6473 - accuracy: 0.7961 - val_loss: 0.8891 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 331us/step - loss: 0.6273 - accuracy: 0.8062 - val_loss: 0.9201 - val_accuracy: 0.6603\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 375us/step - loss: 0.6343 - accuracy: 0.7929 - val_loss: 0.9100 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 374us/step - loss: 0.6367 - accuracy: 0.7950 - val_loss: 0.9030 - val_accuracy: 0.6699\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 308us/step - loss: 0.6202 - accuracy: 0.8051 - val_loss: 0.9192 - val_accuracy: 0.6651\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.6134 - accuracy: 0.8067 - val_loss: 0.8875 - val_accuracy: 0.6651\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 354us/step - loss: 0.6127 - accuracy: 0.8062 - val_loss: 0.9249 - val_accuracy: 0.6603\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 310us/step - loss: 0.6036 - accuracy: 0.8062 - val_loss: 0.9428 - val_accuracy: 0.6555\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 317us/step - loss: 0.6037 - accuracy: 0.8072 - val_loss: 0.9116 - val_accuracy: 0.6651\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 293us/step - loss: 0.6015 - accuracy: 0.8040 - val_loss: 0.8495 - val_accuracy: 0.6794\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 314us/step - loss: 0.6001 - accuracy: 0.8024 - val_loss: 0.8675 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 346us/step - loss: 0.5867 - accuracy: 0.8115 - val_loss: 0.9222 - val_accuracy: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 35/60 [44:54<21:19, 51.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.1952 - accuracy: 0.5527 - val_loss: 1.2323 - val_accuracy: 0.5407\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0973 - accuracy: 0.6390 - val_loss: 1.1931 - val_accuracy: 0.5072\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0756 - accuracy: 0.6427 - val_loss: 1.1789 - val_accuracy: 0.5550\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0606 - accuracy: 0.6486 - val_loss: 1.1713 - val_accuracy: 0.5311\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 930us/step - loss: 1.0280 - accuracy: 0.6693 - val_loss: 1.1366 - val_accuracy: 0.5455\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 951us/step - loss: 1.0117 - accuracy: 0.6661 - val_loss: 1.1228 - val_accuracy: 0.5455\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 824us/step - loss: 0.9930 - accuracy: 0.6736 - val_loss: 1.0677 - val_accuracy: 0.5981\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 981us/step - loss: 0.9833 - accuracy: 0.6720 - val_loss: 1.1064 - val_accuracy: 0.5407\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9627 - accuracy: 0.6810 - val_loss: 1.0425 - val_accuracy: 0.6220\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9437 - accuracy: 0.7002 - val_loss: 1.0618 - val_accuracy: 0.6220\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9429 - accuracy: 0.6928 - val_loss: 1.0525 - val_accuracy: 0.5837\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9243 - accuracy: 0.6991 - val_loss: 1.0120 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9191 - accuracy: 0.6965 - val_loss: 1.0325 - val_accuracy: 0.6029\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9064 - accuracy: 0.6997 - val_loss: 1.0084 - val_accuracy: 0.6172\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8828 - accuracy: 0.7114 - val_loss: 0.9615 - val_accuracy: 0.6651\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8721 - accuracy: 0.7194 - val_loss: 0.9806 - val_accuracy: 0.6411\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 934us/step - loss: 0.8712 - accuracy: 0.7141 - val_loss: 0.9881 - val_accuracy: 0.6459\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 882us/step - loss: 0.8724 - accuracy: 0.7077 - val_loss: 1.0351 - val_accuracy: 0.6172\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8663 - accuracy: 0.7114 - val_loss: 0.9399 - val_accuracy: 0.6938\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8432 - accuracy: 0.7284 - val_loss: 0.9514 - val_accuracy: 0.6555\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 934us/step - loss: 0.8170 - accuracy: 0.7487 - val_loss: 0.9470 - val_accuracy: 0.6555\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 874us/step - loss: 0.8077 - accuracy: 0.7401 - val_loss: 1.0293 - val_accuracy: 0.6029\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 850us/step - loss: 0.8001 - accuracy: 0.7407 - val_loss: 0.9731 - val_accuracy: 0.6507\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 836us/step - loss: 0.7729 - accuracy: 0.7572 - val_loss: 1.0050 - val_accuracy: 0.6077\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 886us/step - loss: 0.7818 - accuracy: 0.7460 - val_loss: 0.9613 - val_accuracy: 0.6459\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 910us/step - loss: 0.7754 - accuracy: 0.7476 - val_loss: 0.9971 - val_accuracy: 0.6555\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7681 - accuracy: 0.7465 - val_loss: 1.0091 - val_accuracy: 0.6077\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7660 - accuracy: 0.7476 - val_loss: 0.9570 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7484 - accuracy: 0.7519 - val_loss: 0.9591 - val_accuracy: 0.6316\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7199 - accuracy: 0.7705 - val_loss: 0.9470 - val_accuracy: 0.6316\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7162 - accuracy: 0.7684 - val_loss: 0.9553 - val_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7149 - accuracy: 0.7700 - val_loss: 0.9368 - val_accuracy: 0.6555\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7116 - accuracy: 0.7700 - val_loss: 0.9168 - val_accuracy: 0.6507\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 865us/step - loss: 0.7128 - accuracy: 0.7657 - val_loss: 0.9372 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7096 - accuracy: 0.7657 - val_loss: 1.0171 - val_accuracy: 0.6364\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6956 - accuracy: 0.7678 - val_loss: 0.9348 - val_accuracy: 0.6411\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6835 - accuracy: 0.7689 - val_loss: 0.9947 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6673 - accuracy: 0.7812 - val_loss: 0.9521 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6506 - accuracy: 0.7897 - val_loss: 0.9310 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 852us/step - loss: 0.6609 - accuracy: 0.7790 - val_loss: 0.9498 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 853us/step - loss: 0.6429 - accuracy: 0.7806 - val_loss: 0.9832 - val_accuracy: 0.6172\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 793us/step - loss: 0.6243 - accuracy: 0.7891 - val_loss: 0.9406 - val_accuracy: 0.6507\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 799us/step - loss: 0.6233 - accuracy: 0.7891 - val_loss: 0.9372 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 815us/step - loss: 0.6129 - accuracy: 0.7929 - val_loss: 0.9457 - val_accuracy: 0.6459\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 827us/step - loss: 0.6086 - accuracy: 0.7923 - val_loss: 0.9935 - val_accuracy: 0.6220\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 806us/step - loss: 0.6083 - accuracy: 0.7897 - val_loss: 0.9611 - val_accuracy: 0.6124\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 828us/step - loss: 0.5906 - accuracy: 0.7929 - val_loss: 1.0014 - val_accuracy: 0.6411\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 804us/step - loss: 0.6040 - accuracy: 0.7891 - val_loss: 0.9890 - val_accuracy: 0.6411\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 835us/step - loss: 0.5844 - accuracy: 0.7945 - val_loss: 0.9710 - val_accuracy: 0.6124\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 811us/step - loss: 0.5891 - accuracy: 0.7993 - val_loss: 0.9961 - val_accuracy: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 36/60 [46:35<26:28, 66.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 600us/step - loss: 1.4546 - accuracy: 0.1736 - val_loss: 1.4216 - val_accuracy: 0.1962\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 185us/step - loss: 1.3920 - accuracy: 0.2524 - val_loss: 1.3936 - val_accuracy: 0.2010\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 174us/step - loss: 1.3377 - accuracy: 0.4127 - val_loss: 1.3627 - val_accuracy: 0.3254\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 1.2959 - accuracy: 0.4909 - val_loss: 1.3276 - val_accuracy: 0.4833\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 1.2556 - accuracy: 0.5266 - val_loss: 1.2903 - val_accuracy: 0.4880\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 1.2245 - accuracy: 0.5362 - val_loss: 1.2523 - val_accuracy: 0.5215\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 1.1965 - accuracy: 0.5490 - val_loss: 1.2267 - val_accuracy: 0.5072\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 1.1771 - accuracy: 0.5511 - val_loss: 1.2031 - val_accuracy: 0.5215\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 175us/step - loss: 1.1523 - accuracy: 0.5548 - val_loss: 1.1829 - val_accuracy: 0.5311\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 1.1441 - accuracy: 0.5517 - val_loss: 1.1731 - val_accuracy: 0.5407\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.1304 - accuracy: 0.5527 - val_loss: 1.1633 - val_accuracy: 0.5263\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 166us/step - loss: 1.1179 - accuracy: 0.5602 - val_loss: 1.1575 - val_accuracy: 0.5359\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 1.1033 - accuracy: 0.5639 - val_loss: 1.1482 - val_accuracy: 0.5263\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 163us/step - loss: 1.0935 - accuracy: 0.5687 - val_loss: 1.1406 - val_accuracy: 0.5167\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 1.0823 - accuracy: 0.5745 - val_loss: 1.1333 - val_accuracy: 0.5120\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 1.0687 - accuracy: 0.5761 - val_loss: 1.1230 - val_accuracy: 0.5311\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 1.0586 - accuracy: 0.5767 - val_loss: 1.1156 - val_accuracy: 0.5311\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 1.0426 - accuracy: 0.5761 - val_loss: 1.1084 - val_accuracy: 0.5263\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 1.0316 - accuracy: 0.5804 - val_loss: 1.1001 - val_accuracy: 0.5311\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 176us/step - loss: 1.0181 - accuracy: 0.5905 - val_loss: 1.0849 - val_accuracy: 0.5550\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 1.0040 - accuracy: 0.6187 - val_loss: 1.0806 - val_accuracy: 0.5646\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 0.9847 - accuracy: 0.6273 - val_loss: 1.0718 - val_accuracy: 0.5694\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 0.9806 - accuracy: 0.6321 - val_loss: 1.0595 - val_accuracy: 0.5789\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 0.9716 - accuracy: 0.6406 - val_loss: 1.0464 - val_accuracy: 0.5837\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 0.9593 - accuracy: 0.6454 - val_loss: 1.0382 - val_accuracy: 0.5837\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 163us/step - loss: 0.9482 - accuracy: 0.6502 - val_loss: 1.0304 - val_accuracy: 0.6124\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9341 - accuracy: 0.6597 - val_loss: 1.0163 - val_accuracy: 0.6220\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 0.9151 - accuracy: 0.6821 - val_loss: 1.0075 - val_accuracy: 0.6220\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 0.9066 - accuracy: 0.6853 - val_loss: 1.0014 - val_accuracy: 0.6172\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 0.9007 - accuracy: 0.6880 - val_loss: 0.9951 - val_accuracy: 0.6268\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 0.8873 - accuracy: 0.6938 - val_loss: 0.9871 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 0.8730 - accuracy: 0.7002 - val_loss: 0.9804 - val_accuracy: 0.6220\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 136us/step - loss: 0.8658 - accuracy: 0.7034 - val_loss: 0.9687 - val_accuracy: 0.6220\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 0.8603 - accuracy: 0.7055 - val_loss: 0.9691 - val_accuracy: 0.6316\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 149us/step - loss: 0.8471 - accuracy: 0.7071 - val_loss: 0.9627 - val_accuracy: 0.6268\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 0.8302 - accuracy: 0.7178 - val_loss: 0.9613 - val_accuracy: 0.6268\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 0.8362 - accuracy: 0.7114 - val_loss: 0.9557 - val_accuracy: 0.6220\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 197us/step - loss: 0.8216 - accuracy: 0.7167 - val_loss: 0.9484 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 206us/step - loss: 0.8170 - accuracy: 0.7247 - val_loss: 0.9447 - val_accuracy: 0.6364\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 229us/step - loss: 0.8148 - accuracy: 0.7199 - val_loss: 0.9383 - val_accuracy: 0.6411\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 229us/step - loss: 0.8070 - accuracy: 0.7188 - val_loss: 0.9354 - val_accuracy: 0.6459\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 226us/step - loss: 0.7967 - accuracy: 0.7306 - val_loss: 0.9288 - val_accuracy: 0.6411\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 216us/step - loss: 0.7960 - accuracy: 0.7290 - val_loss: 0.9231 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 197us/step - loss: 0.7911 - accuracy: 0.7215 - val_loss: 0.9234 - val_accuracy: 0.6459\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 213us/step - loss: 0.7802 - accuracy: 0.7236 - val_loss: 0.9207 - val_accuracy: 0.6364\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 143us/step - loss: 0.7845 - accuracy: 0.7295 - val_loss: 0.9179 - val_accuracy: 0.6316\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 0.7693 - accuracy: 0.7322 - val_loss: 0.9113 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 148us/step - loss: 0.7526 - accuracy: 0.7423 - val_loss: 0.9009 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.7545 - accuracy: 0.7386 - val_loss: 0.9048 - val_accuracy: 0.6316\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 0.7559 - accuracy: 0.7322 - val_loss: 0.8977 - val_accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 37/60 [46:55<20:03, 52.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 902us/step - loss: 1.3079 - accuracy: 0.4899 - val_loss: 1.3348 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 374us/step - loss: 1.2194 - accuracy: 0.6102 - val_loss: 1.2972 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 328us/step - loss: 1.1721 - accuracy: 0.6289 - val_loss: 1.2532 - val_accuracy: 0.4019\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 553us/step - loss: 1.1379 - accuracy: 0.6502 - val_loss: 1.2160 - val_accuracy: 0.4593\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 406us/step - loss: 1.1105 - accuracy: 0.6677 - val_loss: 1.1786 - val_accuracy: 0.5550\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 427us/step - loss: 1.0893 - accuracy: 0.6693 - val_loss: 1.1631 - val_accuracy: 0.5837\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 398us/step - loss: 1.0592 - accuracy: 0.6890 - val_loss: 1.1259 - val_accuracy: 0.6220\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 545us/step - loss: 1.0421 - accuracy: 0.6842 - val_loss: 1.1197 - val_accuracy: 0.6124\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 368us/step - loss: 1.0165 - accuracy: 0.6997 - val_loss: 1.0970 - val_accuracy: 0.6172\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 372us/step - loss: 0.9975 - accuracy: 0.7130 - val_loss: 1.0849 - val_accuracy: 0.6124\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 299us/step - loss: 0.9801 - accuracy: 0.7103 - val_loss: 1.0646 - val_accuracy: 0.6124\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 436us/step - loss: 0.9562 - accuracy: 0.7151 - val_loss: 1.0330 - val_accuracy: 0.6507\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 376us/step - loss: 0.9443 - accuracy: 0.7178 - val_loss: 1.0567 - val_accuracy: 0.6124\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 0.9305 - accuracy: 0.7258 - val_loss: 1.0087 - val_accuracy: 0.6364\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 0.9066 - accuracy: 0.7380 - val_loss: 1.0026 - val_accuracy: 0.6603\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.8964 - accuracy: 0.7306 - val_loss: 0.9901 - val_accuracy: 0.6507\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 281us/step - loss: 0.8788 - accuracy: 0.7412 - val_loss: 0.9872 - val_accuracy: 0.6507\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.8695 - accuracy: 0.7327 - val_loss: 0.9953 - val_accuracy: 0.6364\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 0.8561 - accuracy: 0.7412 - val_loss: 0.9879 - val_accuracy: 0.6364\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.8398 - accuracy: 0.7428 - val_loss: 0.9511 - val_accuracy: 0.6507\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.8332 - accuracy: 0.7375 - val_loss: 0.9754 - val_accuracy: 0.6411\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 264us/step - loss: 0.8101 - accuracy: 0.7503 - val_loss: 0.9318 - val_accuracy: 0.6651\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 0.7996 - accuracy: 0.7535 - val_loss: 0.9198 - val_accuracy: 0.6746\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 0.8054 - accuracy: 0.7380 - val_loss: 0.9561 - val_accuracy: 0.6411\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 252us/step - loss: 0.7821 - accuracy: 0.7604 - val_loss: 0.9346 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.7616 - accuracy: 0.7684 - val_loss: 0.9016 - val_accuracy: 0.6699\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 266us/step - loss: 0.7651 - accuracy: 0.7646 - val_loss: 0.9065 - val_accuracy: 0.6746\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.7469 - accuracy: 0.7588 - val_loss: 0.9132 - val_accuracy: 0.6699\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.7520 - accuracy: 0.7593 - val_loss: 0.9153 - val_accuracy: 0.6507\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.7289 - accuracy: 0.7678 - val_loss: 0.8768 - val_accuracy: 0.6986\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.7239 - accuracy: 0.7668 - val_loss: 0.9254 - val_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.7049 - accuracy: 0.7769 - val_loss: 0.9031 - val_accuracy: 0.6507\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 0.7012 - accuracy: 0.7769 - val_loss: 0.9077 - val_accuracy: 0.6651\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.7034 - accuracy: 0.7684 - val_loss: 0.8747 - val_accuracy: 0.6986\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.6835 - accuracy: 0.7859 - val_loss: 0.9092 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.6814 - accuracy: 0.7689 - val_loss: 0.9060 - val_accuracy: 0.6603\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.6614 - accuracy: 0.7886 - val_loss: 0.9028 - val_accuracy: 0.6651\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 264us/step - loss: 0.6535 - accuracy: 0.7870 - val_loss: 0.9005 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 264us/step - loss: 0.6593 - accuracy: 0.7859 - val_loss: 0.9027 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 314us/step - loss: 0.6619 - accuracy: 0.7812 - val_loss: 0.8841 - val_accuracy: 0.6746\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 0.6479 - accuracy: 0.7801 - val_loss: 0.8895 - val_accuracy: 0.6842\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.6422 - accuracy: 0.7812 - val_loss: 0.8999 - val_accuracy: 0.6746\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 0.6253 - accuracy: 0.7977 - val_loss: 0.9039 - val_accuracy: 0.6651\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.6277 - accuracy: 0.7875 - val_loss: 0.9144 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.6162 - accuracy: 0.7822 - val_loss: 0.8619 - val_accuracy: 0.6794\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 0.6134 - accuracy: 0.7907 - val_loss: 0.8708 - val_accuracy: 0.6938\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.6001 - accuracy: 0.8009 - val_loss: 0.9060 - val_accuracy: 0.6555\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 0.5972 - accuracy: 0.7897 - val_loss: 0.9050 - val_accuracy: 0.6651\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.6034 - accuracy: 0.7843 - val_loss: 0.8955 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 0.5802 - accuracy: 0.7998 - val_loss: 0.9445 - val_accuracy: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 38/60 [47:28<17:01, 46.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2019 - accuracy: 0.5346 - val_loss: 1.2383 - val_accuracy: 0.5359\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1350 - accuracy: 0.5996 - val_loss: 1.2186 - val_accuracy: 0.4785\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 927us/step - loss: 1.1107 - accuracy: 0.6310 - val_loss: 1.1805 - val_accuracy: 0.4880\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 806us/step - loss: 1.0874 - accuracy: 0.6214 - val_loss: 1.1516 - val_accuracy: 0.5502\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 825us/step - loss: 1.0727 - accuracy: 0.6432 - val_loss: 1.1140 - val_accuracy: 0.5646\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 800us/step - loss: 1.0513 - accuracy: 0.6491 - val_loss: 1.1243 - val_accuracy: 0.5885\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 800us/step - loss: 1.0381 - accuracy: 0.6486 - val_loss: 1.1505 - val_accuracy: 0.4976\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 790us/step - loss: 1.0226 - accuracy: 0.6571 - val_loss: 1.0816 - val_accuracy: 0.6077\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 781us/step - loss: 0.9975 - accuracy: 0.6640 - val_loss: 1.0509 - val_accuracy: 0.6507\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 771us/step - loss: 0.9929 - accuracy: 0.6539 - val_loss: 1.0318 - val_accuracy: 0.6316\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 819us/step - loss: 0.9762 - accuracy: 0.6752 - val_loss: 1.0605 - val_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 783us/step - loss: 0.9612 - accuracy: 0.6880 - val_loss: 1.0227 - val_accuracy: 0.6124\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 794us/step - loss: 0.9522 - accuracy: 0.6747 - val_loss: 0.9967 - val_accuracy: 0.6172\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 810us/step - loss: 0.9288 - accuracy: 0.6901 - val_loss: 1.0130 - val_accuracy: 0.6364\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 791us/step - loss: 0.9199 - accuracy: 0.6816 - val_loss: 1.0160 - val_accuracy: 0.5933\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9115 - accuracy: 0.6928 - val_loss: 0.9690 - val_accuracy: 0.6459\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9074 - accuracy: 0.7013 - val_loss: 0.9841 - val_accuracy: 0.6459\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8888 - accuracy: 0.7114 - val_loss: 1.0369 - val_accuracy: 0.6124\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8685 - accuracy: 0.7242 - val_loss: 1.0255 - val_accuracy: 0.6077\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8742 - accuracy: 0.7109 - val_loss: 0.9434 - val_accuracy: 0.6603\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8577 - accuracy: 0.7199 - val_loss: 1.0003 - val_accuracy: 0.6124\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8625 - accuracy: 0.7071 - val_loss: 0.9291 - val_accuracy: 0.6507\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8324 - accuracy: 0.7226 - val_loss: 0.9291 - val_accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8267 - accuracy: 0.7258 - val_loss: 0.9389 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8227 - accuracy: 0.7300 - val_loss: 0.9443 - val_accuracy: 0.6507\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7997 - accuracy: 0.7348 - val_loss: 0.9293 - val_accuracy: 0.6459\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7827 - accuracy: 0.7439 - val_loss: 0.9418 - val_accuracy: 0.6364\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7918 - accuracy: 0.7364 - val_loss: 0.9273 - val_accuracy: 0.6555\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7780 - accuracy: 0.7311 - val_loss: 0.9424 - val_accuracy: 0.6507\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7767 - accuracy: 0.7364 - val_loss: 0.9016 - val_accuracy: 0.6699\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7644 - accuracy: 0.7386 - val_loss: 0.9062 - val_accuracy: 0.6507\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7460 - accuracy: 0.7513 - val_loss: 0.8774 - val_accuracy: 0.6794\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7484 - accuracy: 0.7471 - val_loss: 0.8820 - val_accuracy: 0.6746\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7366 - accuracy: 0.7465 - val_loss: 0.9019 - val_accuracy: 0.6746\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7335 - accuracy: 0.7609 - val_loss: 0.9276 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7241 - accuracy: 0.7561 - val_loss: 0.9058 - val_accuracy: 0.6651\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7282 - accuracy: 0.7471 - val_loss: 0.8964 - val_accuracy: 0.6699\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7078 - accuracy: 0.7614 - val_loss: 0.8815 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6897 - accuracy: 0.7689 - val_loss: 0.8880 - val_accuracy: 0.6842\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6894 - accuracy: 0.7689 - val_loss: 0.8960 - val_accuracy: 0.6890\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6882 - accuracy: 0.7588 - val_loss: 0.9432 - val_accuracy: 0.6364\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 914us/step - loss: 0.6997 - accuracy: 0.7614 - val_loss: 0.9056 - val_accuracy: 0.6746\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6624 - accuracy: 0.7737 - val_loss: 0.9139 - val_accuracy: 0.6603\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6642 - accuracy: 0.7694 - val_loss: 0.9041 - val_accuracy: 0.6603\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6431 - accuracy: 0.7902 - val_loss: 0.8923 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.6462 - accuracy: 0.7806 - val_loss: 0.9390 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6361 - accuracy: 0.7822 - val_loss: 0.8972 - val_accuracy: 0.6938\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 952us/step - loss: 0.6229 - accuracy: 0.7870 - val_loss: 0.9096 - val_accuracy: 0.6699\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 933us/step - loss: 0.6460 - accuracy: 0.7785 - val_loss: 0.9281 - val_accuracy: 0.6555\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 902us/step - loss: 0.6363 - accuracy: 0.7742 - val_loss: 0.9431 - val_accuracy: 0.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 39/60 [49:16<22:45, 65.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 657us/step - loss: 1.4152 - accuracy: 0.2141 - val_loss: 1.3973 - val_accuracy: 0.2775\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 201us/step - loss: 1.3473 - accuracy: 0.3024 - val_loss: 1.3687 - val_accuracy: 0.2775\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 202us/step - loss: 1.2938 - accuracy: 0.4297 - val_loss: 1.3397 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 189us/step - loss: 1.2448 - accuracy: 0.5005 - val_loss: 1.3074 - val_accuracy: 0.4402\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 1.2029 - accuracy: 0.5447 - val_loss: 1.2720 - val_accuracy: 0.4545\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 1.1721 - accuracy: 0.5511 - val_loss: 1.2480 - val_accuracy: 0.4498\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 188us/step - loss: 1.1430 - accuracy: 0.5751 - val_loss: 1.2213 - val_accuracy: 0.4785\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 1.1230 - accuracy: 0.5756 - val_loss: 1.1939 - val_accuracy: 0.5072\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 182us/step - loss: 1.0995 - accuracy: 0.6054 - val_loss: 1.1666 - val_accuracy: 0.5550\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 190us/step - loss: 1.0705 - accuracy: 0.6203 - val_loss: 1.1465 - val_accuracy: 0.5981\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.0547 - accuracy: 0.6214 - val_loss: 1.1169 - val_accuracy: 0.6316\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 1.0341 - accuracy: 0.6491 - val_loss: 1.1037 - val_accuracy: 0.6077\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 1.0244 - accuracy: 0.6422 - val_loss: 1.0858 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 166us/step - loss: 1.0065 - accuracy: 0.6512 - val_loss: 1.0643 - val_accuracy: 0.6411\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9889 - accuracy: 0.6677 - val_loss: 1.0571 - val_accuracy: 0.6364\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.9773 - accuracy: 0.6677 - val_loss: 1.0620 - val_accuracy: 0.6220\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.9687 - accuracy: 0.6699 - val_loss: 1.0400 - val_accuracy: 0.6364\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 166us/step - loss: 0.9481 - accuracy: 0.6810 - val_loss: 1.0281 - val_accuracy: 0.6411\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.9498 - accuracy: 0.6661 - val_loss: 1.0227 - val_accuracy: 0.6411\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9400 - accuracy: 0.6789 - val_loss: 1.0009 - val_accuracy: 0.6555\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.9198 - accuracy: 0.6912 - val_loss: 1.0004 - val_accuracy: 0.6603\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 0.9164 - accuracy: 0.6901 - val_loss: 0.9958 - val_accuracy: 0.6555\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9136 - accuracy: 0.6880 - val_loss: 0.9899 - val_accuracy: 0.6603\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.9028 - accuracy: 0.6922 - val_loss: 0.9872 - val_accuracy: 0.6603\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 0.8881 - accuracy: 0.7034 - val_loss: 0.9873 - val_accuracy: 0.6459\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 0.8928 - accuracy: 0.6981 - val_loss: 0.9702 - val_accuracy: 0.6507\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 162us/step - loss: 0.8852 - accuracy: 0.6970 - val_loss: 0.9635 - val_accuracy: 0.6603\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.8763 - accuracy: 0.6991 - val_loss: 0.9727 - val_accuracy: 0.6699\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.8708 - accuracy: 0.6954 - val_loss: 0.9490 - val_accuracy: 0.6746\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 0.8735 - accuracy: 0.6944 - val_loss: 0.9374 - val_accuracy: 0.6699\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 163us/step - loss: 0.8485 - accuracy: 0.7087 - val_loss: 0.9394 - val_accuracy: 0.6699\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 164us/step - loss: 0.8429 - accuracy: 0.7114 - val_loss: 0.9232 - val_accuracy: 0.6794\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 0.8526 - accuracy: 0.7018 - val_loss: 0.9123 - val_accuracy: 0.6746\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 158us/step - loss: 0.8314 - accuracy: 0.7157 - val_loss: 0.9075 - val_accuracy: 0.6794\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 190us/step - loss: 0.8298 - accuracy: 0.7098 - val_loss: 0.9046 - val_accuracy: 0.6794\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 161us/step - loss: 0.8265 - accuracy: 0.7114 - val_loss: 0.9018 - val_accuracy: 0.6699\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 162us/step - loss: 0.8168 - accuracy: 0.7119 - val_loss: 0.9033 - val_accuracy: 0.6555\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 196us/step - loss: 0.8155 - accuracy: 0.7146 - val_loss: 0.8885 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 198us/step - loss: 0.8132 - accuracy: 0.7135 - val_loss: 0.8948 - val_accuracy: 0.6746\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 197us/step - loss: 0.7977 - accuracy: 0.7210 - val_loss: 0.8969 - val_accuracy: 0.6699\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 242us/step - loss: 0.7920 - accuracy: 0.7290 - val_loss: 0.8851 - val_accuracy: 0.6842\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 213us/step - loss: 0.8051 - accuracy: 0.7103 - val_loss: 0.8881 - val_accuracy: 0.6842\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 193us/step - loss: 0.7915 - accuracy: 0.7263 - val_loss: 0.8865 - val_accuracy: 0.6794\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 0.8033 - accuracy: 0.7103 - val_loss: 0.8727 - val_accuracy: 0.6842\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 232us/step - loss: 0.7785 - accuracy: 0.7274 - val_loss: 0.8757 - val_accuracy: 0.6842\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 227us/step - loss: 0.7714 - accuracy: 0.7290 - val_loss: 0.8723 - val_accuracy: 0.6794\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 212us/step - loss: 0.7744 - accuracy: 0.7295 - val_loss: 0.8725 - val_accuracy: 0.6890\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 204us/step - loss: 0.7728 - accuracy: 0.7279 - val_loss: 0.8650 - val_accuracy: 0.6890\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 206us/step - loss: 0.7572 - accuracy: 0.7295 - val_loss: 0.8557 - val_accuracy: 0.7033\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 200us/step - loss: 0.7625 - accuracy: 0.7332 - val_loss: 0.8595 - val_accuracy: 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 40/60 [49:36<17:10, 51.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 857us/step - loss: 1.3322 - accuracy: 0.2902 - val_loss: 1.3489 - val_accuracy: 0.3014\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 387us/step - loss: 1.2390 - accuracy: 0.5415 - val_loss: 1.2946 - val_accuracy: 0.5072\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 653us/step - loss: 1.1911 - accuracy: 0.5841 - val_loss: 1.2499 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 404us/step - loss: 1.1639 - accuracy: 0.6028 - val_loss: 1.2052 - val_accuracy: 0.5694\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 371us/step - loss: 1.1307 - accuracy: 0.6155 - val_loss: 1.1780 - val_accuracy: 0.5742\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 346us/step - loss: 1.1157 - accuracy: 0.6022 - val_loss: 1.1497 - val_accuracy: 0.5694\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 363us/step - loss: 1.0944 - accuracy: 0.6209 - val_loss: 1.1327 - val_accuracy: 0.5742\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 320us/step - loss: 1.0727 - accuracy: 0.6225 - val_loss: 1.1072 - val_accuracy: 0.5885\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 406us/step - loss: 1.0498 - accuracy: 0.6390 - val_loss: 1.0908 - val_accuracy: 0.5742\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 501us/step - loss: 1.0365 - accuracy: 0.6289 - val_loss: 1.0861 - val_accuracy: 0.5502\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 492us/step - loss: 1.0233 - accuracy: 0.6384 - val_loss: 1.0663 - val_accuracy: 0.5598\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 357us/step - loss: 1.0025 - accuracy: 0.6358 - val_loss: 1.0534 - val_accuracy: 0.5694\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 449us/step - loss: 0.9934 - accuracy: 0.6294 - val_loss: 1.0453 - val_accuracy: 0.5550\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 365us/step - loss: 0.9728 - accuracy: 0.6491 - val_loss: 1.0224 - val_accuracy: 0.5789\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 320us/step - loss: 0.9632 - accuracy: 0.6363 - val_loss: 1.0204 - val_accuracy: 0.5502\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 347us/step - loss: 0.9406 - accuracy: 0.6571 - val_loss: 1.0387 - val_accuracy: 0.5789\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 405us/step - loss: 0.9268 - accuracy: 0.6613 - val_loss: 0.9961 - val_accuracy: 0.5598\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 329us/step - loss: 0.9107 - accuracy: 0.6534 - val_loss: 1.0011 - val_accuracy: 0.5885\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 336us/step - loss: 0.9105 - accuracy: 0.6581 - val_loss: 0.9851 - val_accuracy: 0.5646\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 360us/step - loss: 0.8784 - accuracy: 0.6651 - val_loss: 0.9616 - val_accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 337us/step - loss: 0.8710 - accuracy: 0.6688 - val_loss: 0.9610 - val_accuracy: 0.5837\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 324us/step - loss: 0.8548 - accuracy: 0.7162 - val_loss: 0.9536 - val_accuracy: 0.6411\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 310us/step - loss: 0.8458 - accuracy: 0.7215 - val_loss: 0.9580 - val_accuracy: 0.6316\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 308us/step - loss: 0.8234 - accuracy: 0.7311 - val_loss: 0.9473 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 309us/step - loss: 0.8145 - accuracy: 0.7348 - val_loss: 0.9714 - val_accuracy: 0.6172\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 309us/step - loss: 0.8070 - accuracy: 0.7359 - val_loss: 0.9498 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 350us/step - loss: 0.8021 - accuracy: 0.7375 - val_loss: 0.9322 - val_accuracy: 0.6507\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 389us/step - loss: 0.7941 - accuracy: 0.7263 - val_loss: 0.9495 - val_accuracy: 0.6268\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 454us/step - loss: 0.7872 - accuracy: 0.7401 - val_loss: 0.9344 - val_accuracy: 0.6220\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 370us/step - loss: 0.7620 - accuracy: 0.7519 - val_loss: 0.9597 - val_accuracy: 0.6124\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 345us/step - loss: 0.7513 - accuracy: 0.7439 - val_loss: 0.9225 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 433us/step - loss: 0.7380 - accuracy: 0.7524 - val_loss: 0.8902 - val_accuracy: 0.6555\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 469us/step - loss: 0.7310 - accuracy: 0.7620 - val_loss: 0.9149 - val_accuracy: 0.6459\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 0.7303 - accuracy: 0.7513 - val_loss: 0.9124 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 327us/step - loss: 0.7166 - accuracy: 0.7599 - val_loss: 0.8971 - val_accuracy: 0.6507\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 325us/step - loss: 0.7140 - accuracy: 0.7540 - val_loss: 0.8613 - val_accuracy: 0.6507\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.7004 - accuracy: 0.7540 - val_loss: 0.8645 - val_accuracy: 0.6507\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 0.6813 - accuracy: 0.7684 - val_loss: 0.8643 - val_accuracy: 0.6651\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 0.6784 - accuracy: 0.7636 - val_loss: 0.8586 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.6800 - accuracy: 0.7694 - val_loss: 0.9177 - val_accuracy: 0.6555\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 0.6808 - accuracy: 0.7657 - val_loss: 0.8799 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 407us/step - loss: 0.6655 - accuracy: 0.7625 - val_loss: 0.8910 - val_accuracy: 0.6220\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 336us/step - loss: 0.6565 - accuracy: 0.7652 - val_loss: 0.8903 - val_accuracy: 0.6364\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 0.6532 - accuracy: 0.7710 - val_loss: 0.8624 - val_accuracy: 0.6699\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.6367 - accuracy: 0.7769 - val_loss: 0.8822 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 357us/step - loss: 0.6290 - accuracy: 0.7758 - val_loss: 0.8941 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 319us/step - loss: 0.6260 - accuracy: 0.7790 - val_loss: 0.8628 - val_accuracy: 0.6507\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 423us/step - loss: 0.6192 - accuracy: 0.7774 - val_loss: 0.8764 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 388us/step - loss: 0.6149 - accuracy: 0.7822 - val_loss: 0.8666 - val_accuracy: 0.6651\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 341us/step - loss: 0.6097 - accuracy: 0.7774 - val_loss: 0.8762 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 41/60 [50:14<15:01, 47.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2736 - accuracy: 0.4888 - val_loss: 1.2913 - val_accuracy: 0.5598\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1907 - accuracy: 0.6065 - val_loss: 1.2363 - val_accuracy: 0.6029\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1557 - accuracy: 0.6225 - val_loss: 1.2148 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1279 - accuracy: 0.6347 - val_loss: 1.1654 - val_accuracy: 0.6220\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 845us/step - loss: 1.1052 - accuracy: 0.6395 - val_loss: 1.1735 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0839 - accuracy: 0.6592 - val_loss: 1.1340 - val_accuracy: 0.6172\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0702 - accuracy: 0.6523 - val_loss: 1.0963 - val_accuracy: 0.6124\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0452 - accuracy: 0.6656 - val_loss: 1.0764 - val_accuracy: 0.6220\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0341 - accuracy: 0.6699 - val_loss: 1.0620 - val_accuracy: 0.6364\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0222 - accuracy: 0.6550 - val_loss: 1.0503 - val_accuracy: 0.6364\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0017 - accuracy: 0.6778 - val_loss: 1.0407 - val_accuracy: 0.6316\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9907 - accuracy: 0.6699 - val_loss: 1.0866 - val_accuracy: 0.6077\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9917 - accuracy: 0.6741 - val_loss: 1.0251 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9674 - accuracy: 0.6821 - val_loss: 0.9953 - val_accuracy: 0.6651\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9540 - accuracy: 0.6912 - val_loss: 0.9895 - val_accuracy: 0.6459\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 925us/step - loss: 0.9479 - accuracy: 0.6885 - val_loss: 1.0429 - val_accuracy: 0.6077\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9349 - accuracy: 0.6933 - val_loss: 0.9907 - val_accuracy: 0.6555\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9235 - accuracy: 0.6986 - val_loss: 0.9948 - val_accuracy: 0.6077\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9105 - accuracy: 0.6991 - val_loss: 0.9790 - val_accuracy: 0.6507\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 945us/step - loss: 0.9052 - accuracy: 0.7002 - val_loss: 0.9978 - val_accuracy: 0.6411\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 958us/step - loss: 0.8953 - accuracy: 0.6954 - val_loss: 0.9825 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8783 - accuracy: 0.7109 - val_loss: 0.9649 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8702 - accuracy: 0.7162 - val_loss: 1.0012 - val_accuracy: 0.6172\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 961us/step - loss: 0.8699 - accuracy: 0.7071 - val_loss: 0.9829 - val_accuracy: 0.6364\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 799us/step - loss: 0.8666 - accuracy: 0.7141 - val_loss: 0.9489 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 802us/step - loss: 0.8526 - accuracy: 0.7210 - val_loss: 0.9688 - val_accuracy: 0.6507\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 827us/step - loss: 0.8514 - accuracy: 0.7114 - val_loss: 0.9331 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 796us/step - loss: 0.8333 - accuracy: 0.7215 - val_loss: 0.8952 - val_accuracy: 0.6842\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 802us/step - loss: 0.8172 - accuracy: 0.7311 - val_loss: 0.9388 - val_accuracy: 0.6411\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 814us/step - loss: 0.8042 - accuracy: 0.7338 - val_loss: 0.9047 - val_accuracy: 0.6699\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 830us/step - loss: 0.7949 - accuracy: 0.7455 - val_loss: 0.9129 - val_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 818us/step - loss: 0.8046 - accuracy: 0.7354 - val_loss: 0.9616 - val_accuracy: 0.6459\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 783us/step - loss: 0.7913 - accuracy: 0.7322 - val_loss: 0.8875 - val_accuracy: 0.6842\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 785us/step - loss: 0.7731 - accuracy: 0.7417 - val_loss: 0.9142 - val_accuracy: 0.6555\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 787us/step - loss: 0.7801 - accuracy: 0.7322 - val_loss: 0.8849 - val_accuracy: 0.6699\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 805us/step - loss: 0.7667 - accuracy: 0.7487 - val_loss: 0.8907 - val_accuracy: 0.6651\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 801us/step - loss: 0.7445 - accuracy: 0.7487 - val_loss: 0.8876 - val_accuracy: 0.6794\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 819us/step - loss: 0.7520 - accuracy: 0.7508 - val_loss: 0.8998 - val_accuracy: 0.6603\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 818us/step - loss: 0.7223 - accuracy: 0.7599 - val_loss: 0.8667 - val_accuracy: 0.6699\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 794us/step - loss: 0.7353 - accuracy: 0.7508 - val_loss: 0.9283 - val_accuracy: 0.6507\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 800us/step - loss: 0.7053 - accuracy: 0.7716 - val_loss: 0.9253 - val_accuracy: 0.6555\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 868us/step - loss: 0.7220 - accuracy: 0.7535 - val_loss: 0.8696 - val_accuracy: 0.6699\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 837us/step - loss: 0.7081 - accuracy: 0.7561 - val_loss: 0.8772 - val_accuracy: 0.6794\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 805us/step - loss: 0.7047 - accuracy: 0.7604 - val_loss: 0.8766 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 943us/step - loss: 0.7029 - accuracy: 0.7620 - val_loss: 0.9135 - val_accuracy: 0.6507\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7106 - accuracy: 0.7503 - val_loss: 0.8901 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6872 - accuracy: 0.7668 - val_loss: 0.8606 - val_accuracy: 0.6651\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6781 - accuracy: 0.7636 - val_loss: 0.8599 - val_accuracy: 0.6746\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.6742 - accuracy: 0.7614 - val_loss: 0.8899 - val_accuracy: 0.6651\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6533 - accuracy: 0.7774 - val_loss: 0.8470 - val_accuracy: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 42/60 [51:51<18:40, 62.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 728us/step - loss: 1.3650 - accuracy: 0.3360 - val_loss: 1.3443 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 239us/step - loss: 1.3187 - accuracy: 0.4366 - val_loss: 1.3288 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 1.2759 - accuracy: 0.4670 - val_loss: 1.3120 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 189us/step - loss: 1.2434 - accuracy: 0.4824 - val_loss: 1.2913 - val_accuracy: 0.3971\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 194us/step - loss: 1.2062 - accuracy: 0.5064 - val_loss: 1.2624 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 196us/step - loss: 1.1748 - accuracy: 0.5351 - val_loss: 1.2259 - val_accuracy: 0.4545\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 234us/step - loss: 1.1506 - accuracy: 0.5224 - val_loss: 1.1912 - val_accuracy: 0.4880\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 244us/step - loss: 1.1232 - accuracy: 0.5458 - val_loss: 1.1615 - val_accuracy: 0.5024\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.0970 - accuracy: 0.5554 - val_loss: 1.1334 - val_accuracy: 0.5215\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.0948 - accuracy: 0.5586 - val_loss: 1.1143 - val_accuracy: 0.5263\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.0782 - accuracy: 0.5671 - val_loss: 1.0956 - val_accuracy: 0.5359\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.0605 - accuracy: 0.5783 - val_loss: 1.0871 - val_accuracy: 0.5455\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.0618 - accuracy: 0.5820 - val_loss: 1.0771 - val_accuracy: 0.5694\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.0421 - accuracy: 0.5942 - val_loss: 1.0677 - val_accuracy: 0.5885\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.0378 - accuracy: 0.5996 - val_loss: 1.0640 - val_accuracy: 0.5885\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.0248 - accuracy: 0.6049 - val_loss: 1.0601 - val_accuracy: 0.5837\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 1.0177 - accuracy: 0.6065 - val_loss: 1.0514 - val_accuracy: 0.5981\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.0129 - accuracy: 0.6113 - val_loss: 1.0549 - val_accuracy: 0.5742\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.9976 - accuracy: 0.6060 - val_loss: 1.0494 - val_accuracy: 0.5837\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 167us/step - loss: 1.0060 - accuracy: 0.6124 - val_loss: 1.0444 - val_accuracy: 0.5933\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.9814 - accuracy: 0.6198 - val_loss: 1.0338 - val_accuracy: 0.5837\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9807 - accuracy: 0.6262 - val_loss: 1.0294 - val_accuracy: 0.5885\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 156us/step - loss: 0.9804 - accuracy: 0.6294 - val_loss: 1.0259 - val_accuracy: 0.6029\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 163us/step - loss: 0.9687 - accuracy: 0.6299 - val_loss: 1.0235 - val_accuracy: 0.5981\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.9652 - accuracy: 0.6400 - val_loss: 1.0095 - val_accuracy: 0.6220\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 157us/step - loss: 0.9445 - accuracy: 0.6464 - val_loss: 1.0005 - val_accuracy: 0.6268\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.9491 - accuracy: 0.6512 - val_loss: 0.9888 - val_accuracy: 0.6220\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.9393 - accuracy: 0.6576 - val_loss: 0.9866 - val_accuracy: 0.6268\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9248 - accuracy: 0.6629 - val_loss: 0.9761 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9166 - accuracy: 0.6667 - val_loss: 0.9801 - val_accuracy: 0.6172\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9120 - accuracy: 0.6677 - val_loss: 0.9739 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.8951 - accuracy: 0.6800 - val_loss: 0.9725 - val_accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.8977 - accuracy: 0.6731 - val_loss: 0.9641 - val_accuracy: 0.6507\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 0.8874 - accuracy: 0.6816 - val_loss: 0.9685 - val_accuracy: 0.6364\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.8809 - accuracy: 0.6858 - val_loss: 0.9674 - val_accuracy: 0.6459\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.8770 - accuracy: 0.6832 - val_loss: 0.9454 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 144us/step - loss: 0.8679 - accuracy: 0.6874 - val_loss: 0.9340 - val_accuracy: 0.6699\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 160us/step - loss: 0.8645 - accuracy: 0.6853 - val_loss: 0.9270 - val_accuracy: 0.6603\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.8514 - accuracy: 0.6997 - val_loss: 0.9288 - val_accuracy: 0.6459\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 0.8506 - accuracy: 0.6970 - val_loss: 0.9299 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 0.8509 - accuracy: 0.6826 - val_loss: 0.9036 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 0.8527 - accuracy: 0.6864 - val_loss: 0.9057 - val_accuracy: 0.6746\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 161us/step - loss: 0.8369 - accuracy: 0.7023 - val_loss: 0.8984 - val_accuracy: 0.6603\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.8143 - accuracy: 0.7082 - val_loss: 0.9090 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 163us/step - loss: 0.8164 - accuracy: 0.7039 - val_loss: 0.8843 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 162us/step - loss: 0.8199 - accuracy: 0.7002 - val_loss: 0.8845 - val_accuracy: 0.6651\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 0.8055 - accuracy: 0.7066 - val_loss: 0.8981 - val_accuracy: 0.6651\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 0.8019 - accuracy: 0.7135 - val_loss: 0.9113 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 0.8130 - accuracy: 0.7039 - val_loss: 0.9026 - val_accuracy: 0.6651\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.7846 - accuracy: 0.7178 - val_loss: 0.8909 - val_accuracy: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 43/60 [52:11<14:00, 49.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 677us/step - loss: 1.3725 - accuracy: 0.2934 - val_loss: 1.3634 - val_accuracy: 0.3445\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 1.2723 - accuracy: 0.5144 - val_loss: 1.3132 - val_accuracy: 0.5167\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 1.2111 - accuracy: 0.5852 - val_loss: 1.2519 - val_accuracy: 0.5550\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 264us/step - loss: 1.1693 - accuracy: 0.6145 - val_loss: 1.2148 - val_accuracy: 0.5598\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 262us/step - loss: 1.1335 - accuracy: 0.6310 - val_loss: 1.1848 - val_accuracy: 0.5837\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 1.1186 - accuracy: 0.6145 - val_loss: 1.1708 - val_accuracy: 0.5550\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 1.0847 - accuracy: 0.6347 - val_loss: 1.1106 - val_accuracy: 0.5933\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 1.0839 - accuracy: 0.6230 - val_loss: 1.1106 - val_accuracy: 0.5933\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 1.0534 - accuracy: 0.6480 - val_loss: 1.1012 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 262us/step - loss: 1.0324 - accuracy: 0.6454 - val_loss: 1.0842 - val_accuracy: 0.5598\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 1.0193 - accuracy: 0.6571 - val_loss: 1.0428 - val_accuracy: 0.6268\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 1.0000 - accuracy: 0.6699 - val_loss: 1.0244 - val_accuracy: 0.6364\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.9838 - accuracy: 0.6661 - val_loss: 1.0297 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 266us/step - loss: 0.9775 - accuracy: 0.6709 - val_loss: 1.0121 - val_accuracy: 0.6316\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 244us/step - loss: 0.9663 - accuracy: 0.6816 - val_loss: 1.0005 - val_accuracy: 0.6364\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 256us/step - loss: 0.9403 - accuracy: 0.6949 - val_loss: 1.0036 - val_accuracy: 0.6124\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 0.9284 - accuracy: 0.6944 - val_loss: 0.9974 - val_accuracy: 0.6220\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 262us/step - loss: 0.9237 - accuracy: 0.6842 - val_loss: 0.9843 - val_accuracy: 0.6220\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.9186 - accuracy: 0.6949 - val_loss: 0.9639 - val_accuracy: 0.6555\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8946 - accuracy: 0.7039 - val_loss: 0.9498 - val_accuracy: 0.6603\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 0.8847 - accuracy: 0.7098 - val_loss: 0.9437 - val_accuracy: 0.6459\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.8815 - accuracy: 0.6970 - val_loss: 0.9406 - val_accuracy: 0.6411\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.8646 - accuracy: 0.7130 - val_loss: 0.9699 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.8649 - accuracy: 0.7050 - val_loss: 0.9442 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8500 - accuracy: 0.7071 - val_loss: 0.9310 - val_accuracy: 0.6507\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 245us/step - loss: 0.8319 - accuracy: 0.7157 - val_loss: 0.9165 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 249us/step - loss: 0.8354 - accuracy: 0.7157 - val_loss: 0.9402 - val_accuracy: 0.6220\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 0.8220 - accuracy: 0.7119 - val_loss: 0.9084 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 259us/step - loss: 0.8019 - accuracy: 0.7295 - val_loss: 0.8873 - val_accuracy: 0.6603\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.8021 - accuracy: 0.7242 - val_loss: 0.9084 - val_accuracy: 0.6507\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.7979 - accuracy: 0.7274 - val_loss: 0.9162 - val_accuracy: 0.6411\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 293us/step - loss: 0.7967 - accuracy: 0.7236 - val_loss: 0.9107 - val_accuracy: 0.6316\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 266us/step - loss: 0.7774 - accuracy: 0.7311 - val_loss: 0.9313 - val_accuracy: 0.6268\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 281us/step - loss: 0.7653 - accuracy: 0.7375 - val_loss: 0.9272 - val_accuracy: 0.6411\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 532us/step - loss: 0.7636 - accuracy: 0.7417 - val_loss: 0.9191 - val_accuracy: 0.6364\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 351us/step - loss: 0.7679 - accuracy: 0.7401 - val_loss: 0.8919 - val_accuracy: 0.6459\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.7533 - accuracy: 0.7428 - val_loss: 0.9197 - val_accuracy: 0.6220\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 331us/step - loss: 0.7353 - accuracy: 0.7497 - val_loss: 0.8769 - val_accuracy: 0.6746\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 359us/step - loss: 0.7354 - accuracy: 0.7471 - val_loss: 0.8983 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.7346 - accuracy: 0.7417 - val_loss: 0.8971 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 301us/step - loss: 0.7224 - accuracy: 0.7455 - val_loss: 0.8818 - val_accuracy: 0.6603\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.7101 - accuracy: 0.7524 - val_loss: 0.8866 - val_accuracy: 0.6651\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 266us/step - loss: 0.6980 - accuracy: 0.7551 - val_loss: 0.8693 - val_accuracy: 0.6603\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 262us/step - loss: 0.6982 - accuracy: 0.7492 - val_loss: 0.8691 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.6920 - accuracy: 0.7556 - val_loss: 0.8466 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.6881 - accuracy: 0.7583 - val_loss: 0.8498 - val_accuracy: 0.6651\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.6783 - accuracy: 0.7519 - val_loss: 0.8580 - val_accuracy: 0.6699\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.6868 - accuracy: 0.7476 - val_loss: 0.8648 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 310us/step - loss: 0.6848 - accuracy: 0.7497 - val_loss: 0.8817 - val_accuracy: 0.6507\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 472us/step - loss: 0.6688 - accuracy: 0.7540 - val_loss: 0.8721 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 44/60 [52:40<11:35, 43.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2475 - accuracy: 0.4973 - val_loss: 1.3248 - val_accuracy: 0.4689\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1731 - accuracy: 0.5799 - val_loss: 1.2771 - val_accuracy: 0.5502\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1523 - accuracy: 0.5692 - val_loss: 1.2011 - val_accuracy: 0.5407\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1393 - accuracy: 0.5745 - val_loss: 1.1826 - val_accuracy: 0.5550\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1219 - accuracy: 0.5804 - val_loss: 1.1876 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 959us/step - loss: 1.0965 - accuracy: 0.5996 - val_loss: 1.1126 - val_accuracy: 0.5550\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 955us/step - loss: 1.0892 - accuracy: 0.5852 - val_loss: 1.1167 - val_accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 912us/step - loss: 1.0772 - accuracy: 0.5985 - val_loss: 1.0849 - val_accuracy: 0.5598\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0626 - accuracy: 0.6145 - val_loss: 1.0852 - val_accuracy: 0.5598\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 950us/step - loss: 1.0580 - accuracy: 0.5942 - val_loss: 1.0854 - val_accuracy: 0.5646\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0359 - accuracy: 0.6134 - val_loss: 1.0974 - val_accuracy: 0.5215\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0336 - accuracy: 0.6065 - val_loss: 1.0824 - val_accuracy: 0.5455\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0112 - accuracy: 0.6198 - val_loss: 1.0970 - val_accuracy: 0.5502\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0098 - accuracy: 0.6187 - val_loss: 1.0603 - val_accuracy: 0.5455\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 989us/step - loss: 0.9962 - accuracy: 0.6166 - val_loss: 1.0589 - val_accuracy: 0.5742\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 812us/step - loss: 0.9798 - accuracy: 0.6299 - val_loss: 1.1027 - val_accuracy: 0.5263\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 834us/step - loss: 0.9767 - accuracy: 0.6299 - val_loss: 1.0665 - val_accuracy: 0.5407\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 825us/step - loss: 0.9691 - accuracy: 0.6241 - val_loss: 1.0670 - val_accuracy: 0.5742\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 817us/step - loss: 0.9584 - accuracy: 0.6597 - val_loss: 1.0684 - val_accuracy: 0.5885\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 811us/step - loss: 0.9640 - accuracy: 0.6581 - val_loss: 1.0363 - val_accuracy: 0.6220\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 797us/step - loss: 0.9376 - accuracy: 0.6613 - val_loss: 1.0170 - val_accuracy: 0.6268\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 812us/step - loss: 0.9297 - accuracy: 0.6800 - val_loss: 0.9959 - val_accuracy: 0.6124\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 824us/step - loss: 0.9180 - accuracy: 0.6805 - val_loss: 1.0026 - val_accuracy: 0.6411\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 810us/step - loss: 0.9063 - accuracy: 0.6800 - val_loss: 1.0040 - val_accuracy: 0.6077\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 817us/step - loss: 0.8998 - accuracy: 0.6747 - val_loss: 0.9865 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 861us/step - loss: 0.8857 - accuracy: 0.6960 - val_loss: 0.9664 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 821us/step - loss: 0.8858 - accuracy: 0.6901 - val_loss: 0.9879 - val_accuracy: 0.6268\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 804us/step - loss: 0.8642 - accuracy: 0.7103 - val_loss: 0.9733 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 798us/step - loss: 0.8471 - accuracy: 0.7119 - val_loss: 0.9517 - val_accuracy: 0.6651\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 826us/step - loss: 0.8454 - accuracy: 0.7199 - val_loss: 0.9612 - val_accuracy: 0.6316\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 924us/step - loss: 0.8545 - accuracy: 0.6965 - val_loss: 0.9675 - val_accuracy: 0.6411\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8372 - accuracy: 0.7188 - val_loss: 0.9550 - val_accuracy: 0.6268\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8366 - accuracy: 0.7061 - val_loss: 0.9151 - val_accuracy: 0.6699\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8120 - accuracy: 0.7151 - val_loss: 0.9213 - val_accuracy: 0.6268\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7961 - accuracy: 0.7274 - val_loss: 0.9251 - val_accuracy: 0.6459\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8135 - accuracy: 0.7125 - val_loss: 0.9220 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7896 - accuracy: 0.7290 - val_loss: 0.9299 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7753 - accuracy: 0.7332 - val_loss: 0.9461 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 947us/step - loss: 0.7566 - accuracy: 0.7423 - val_loss: 0.9155 - val_accuracy: 0.6603\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7549 - accuracy: 0.7380 - val_loss: 0.9433 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7584 - accuracy: 0.7386 - val_loss: 0.9220 - val_accuracy: 0.6411\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7522 - accuracy: 0.7423 - val_loss: 0.9037 - val_accuracy: 0.6507\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7490 - accuracy: 0.7380 - val_loss: 0.9323 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7224 - accuracy: 0.7556 - val_loss: 0.8840 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.7166 - accuracy: 0.7567 - val_loss: 0.8805 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7038 - accuracy: 0.7625 - val_loss: 0.8910 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 970us/step - loss: 0.7225 - accuracy: 0.7487 - val_loss: 0.8582 - val_accuracy: 0.6794\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 895us/step - loss: 0.6986 - accuracy: 0.7508 - val_loss: 0.8647 - val_accuracy: 0.6699\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 978us/step - loss: 0.7030 - accuracy: 0.7561 - val_loss: 0.8703 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 956us/step - loss: 0.6950 - accuracy: 0.7561 - val_loss: 0.8645 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 45/60 [54:22<15:16, 61.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 666us/step - loss: 1.3502 - accuracy: 0.4228 - val_loss: 1.3486 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 191us/step - loss: 1.3140 - accuracy: 0.4366 - val_loss: 1.3304 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.2749 - accuracy: 0.4718 - val_loss: 1.3118 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 189us/step - loss: 1.2424 - accuracy: 0.4952 - val_loss: 1.2941 - val_accuracy: 0.3971\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 1.2124 - accuracy: 0.5170 - val_loss: 1.2728 - val_accuracy: 0.4258\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 157us/step - loss: 1.1869 - accuracy: 0.5325 - val_loss: 1.2511 - val_accuracy: 0.4354\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 199us/step - loss: 1.1741 - accuracy: 0.5256 - val_loss: 1.2278 - val_accuracy: 0.4880\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 183us/step - loss: 1.1588 - accuracy: 0.5319 - val_loss: 1.2039 - val_accuracy: 0.4880\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 1.1387 - accuracy: 0.5431 - val_loss: 1.2003 - val_accuracy: 0.4928\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 1.1232 - accuracy: 0.5442 - val_loss: 1.1649 - val_accuracy: 0.5215\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 140us/step - loss: 1.1050 - accuracy: 0.5682 - val_loss: 1.1572 - val_accuracy: 0.5215\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 144us/step - loss: 1.0948 - accuracy: 0.5660 - val_loss: 1.1367 - val_accuracy: 0.5311\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 143us/step - loss: 1.0831 - accuracy: 0.5831 - val_loss: 1.1227 - val_accuracy: 0.5502\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 133us/step - loss: 1.0641 - accuracy: 0.5889 - val_loss: 1.1067 - val_accuracy: 0.5502\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.0685 - accuracy: 0.5911 - val_loss: 1.1030 - val_accuracy: 0.5646\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 157us/step - loss: 1.0549 - accuracy: 0.5937 - val_loss: 1.1131 - val_accuracy: 0.5598\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.0514 - accuracy: 0.5964 - val_loss: 1.1061 - val_accuracy: 0.5646\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 1.0395 - accuracy: 0.6038 - val_loss: 1.0943 - val_accuracy: 0.5694\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 148us/step - loss: 1.0347 - accuracy: 0.6006 - val_loss: 1.0906 - val_accuracy: 0.5694\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 1.0195 - accuracy: 0.6102 - val_loss: 1.0932 - val_accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 145us/step - loss: 1.0115 - accuracy: 0.6203 - val_loss: 1.0827 - val_accuracy: 0.5742\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 166us/step - loss: 1.0219 - accuracy: 0.5990 - val_loss: 1.0798 - val_accuracy: 0.5789\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 231us/step - loss: 1.0056 - accuracy: 0.6203 - val_loss: 1.0760 - val_accuracy: 0.5789\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 164us/step - loss: 1.0068 - accuracy: 0.6134 - val_loss: 1.0755 - val_accuracy: 0.5789\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 1.0018 - accuracy: 0.6145 - val_loss: 1.0836 - val_accuracy: 0.5742\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9920 - accuracy: 0.6235 - val_loss: 1.0704 - val_accuracy: 0.5933\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 152us/step - loss: 0.9866 - accuracy: 0.6166 - val_loss: 1.0684 - val_accuracy: 0.5885\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9960 - accuracy: 0.6150 - val_loss: 1.0726 - val_accuracy: 0.5789\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 0.9699 - accuracy: 0.6289 - val_loss: 1.0726 - val_accuracy: 0.5789\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 159us/step - loss: 0.9741 - accuracy: 0.6203 - val_loss: 1.0695 - val_accuracy: 0.5742\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 0.9759 - accuracy: 0.6278 - val_loss: 1.0645 - val_accuracy: 0.5598\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 0.9792 - accuracy: 0.6187 - val_loss: 1.0671 - val_accuracy: 0.5694\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 226us/step - loss: 0.9721 - accuracy: 0.6225 - val_loss: 1.0711 - val_accuracy: 0.5789\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.9670 - accuracy: 0.6235 - val_loss: 1.0723 - val_accuracy: 0.5837\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 164us/step - loss: 0.9725 - accuracy: 0.6251 - val_loss: 1.0720 - val_accuracy: 0.5694\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9581 - accuracy: 0.6230 - val_loss: 1.0665 - val_accuracy: 0.5742\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 229us/step - loss: 0.9556 - accuracy: 0.6278 - val_loss: 1.0646 - val_accuracy: 0.5789\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 211us/step - loss: 0.9499 - accuracy: 0.6278 - val_loss: 1.0601 - val_accuracy: 0.5646\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.9555 - accuracy: 0.6278 - val_loss: 1.0588 - val_accuracy: 0.5598\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 217us/step - loss: 0.9357 - accuracy: 0.6337 - val_loss: 1.0618 - val_accuracy: 0.5694\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 0.9446 - accuracy: 0.6347 - val_loss: 1.0617 - val_accuracy: 0.5550\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 240us/step - loss: 0.9322 - accuracy: 0.6416 - val_loss: 1.0595 - val_accuracy: 0.5502\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 238us/step - loss: 0.9370 - accuracy: 0.6464 - val_loss: 1.0611 - val_accuracy: 0.5550\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 194us/step - loss: 0.9488 - accuracy: 0.6241 - val_loss: 1.0564 - val_accuracy: 0.5598\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 351us/step - loss: 0.9204 - accuracy: 0.6486 - val_loss: 1.0541 - val_accuracy: 0.5550\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 209us/step - loss: 0.9337 - accuracy: 0.6353 - val_loss: 1.0525 - val_accuracy: 0.5550\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 186us/step - loss: 0.9304 - accuracy: 0.6315 - val_loss: 1.0595 - val_accuracy: 0.5550\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 203us/step - loss: 0.9345 - accuracy: 0.6278 - val_loss: 1.0606 - val_accuracy: 0.5502\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 0.9249 - accuracy: 0.6411 - val_loss: 1.0586 - val_accuracy: 0.5550\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 148us/step - loss: 0.9215 - accuracy: 0.6310 - val_loss: 1.0659 - val_accuracy: 0.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 46/60 [54:42<11:23, 48.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 734us/step - loss: 1.3209 - accuracy: 0.3972 - val_loss: 1.3399 - val_accuracy: 0.2823\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 1.2369 - accuracy: 0.5453 - val_loss: 1.2904 - val_accuracy: 0.5072\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 1.1886 - accuracy: 0.5900 - val_loss: 1.2367 - val_accuracy: 0.5502\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 391us/step - loss: 1.1572 - accuracy: 0.6076 - val_loss: 1.1947 - val_accuracy: 0.5455\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 1.1338 - accuracy: 0.6209 - val_loss: 1.1617 - val_accuracy: 0.5646\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 302us/step - loss: 1.1102 - accuracy: 0.6379 - val_loss: 1.1427 - val_accuracy: 0.5933\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 421us/step - loss: 1.0913 - accuracy: 0.6368 - val_loss: 1.1209 - val_accuracy: 0.6268\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 374us/step - loss: 1.0779 - accuracy: 0.6347 - val_loss: 1.1033 - val_accuracy: 0.6029\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 398us/step - loss: 1.0491 - accuracy: 0.6491 - val_loss: 1.0743 - val_accuracy: 0.6411\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 446us/step - loss: 1.0526 - accuracy: 0.6480 - val_loss: 1.0608 - val_accuracy: 0.6220\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 587us/step - loss: 1.0288 - accuracy: 0.6486 - val_loss: 1.0437 - val_accuracy: 0.6172\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 376us/step - loss: 1.0216 - accuracy: 0.6555 - val_loss: 1.0322 - val_accuracy: 0.6699\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 368us/step - loss: 1.0001 - accuracy: 0.6709 - val_loss: 1.0118 - val_accuracy: 0.6699\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 368us/step - loss: 0.9840 - accuracy: 0.6699 - val_loss: 0.9998 - val_accuracy: 0.6555\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 346us/step - loss: 0.9745 - accuracy: 0.6789 - val_loss: 1.0041 - val_accuracy: 0.6268\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 403us/step - loss: 0.9682 - accuracy: 0.6720 - val_loss: 0.9947 - val_accuracy: 0.6411\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.9576 - accuracy: 0.6773 - val_loss: 0.9969 - val_accuracy: 0.6459\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 540us/step - loss: 0.9403 - accuracy: 0.6853 - val_loss: 0.9959 - val_accuracy: 0.6603\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 374us/step - loss: 0.9337 - accuracy: 0.6890 - val_loss: 0.9947 - val_accuracy: 0.6746\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.9304 - accuracy: 0.6901 - val_loss: 0.9352 - val_accuracy: 0.7129\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 317us/step - loss: 0.9289 - accuracy: 0.6826 - val_loss: 0.9185 - val_accuracy: 0.6938\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 327us/step - loss: 0.9139 - accuracy: 0.6933 - val_loss: 0.9456 - val_accuracy: 0.6651\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 0.8873 - accuracy: 0.6954 - val_loss: 0.9389 - val_accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 0.8807 - accuracy: 0.6981 - val_loss: 0.9292 - val_accuracy: 0.6938\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 340us/step - loss: 0.8783 - accuracy: 0.7098 - val_loss: 0.9248 - val_accuracy: 0.6699\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 337us/step - loss: 0.8645 - accuracy: 0.7098 - val_loss: 0.9182 - val_accuracy: 0.6794\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 0.8685 - accuracy: 0.7034 - val_loss: 0.9555 - val_accuracy: 0.6651\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.8584 - accuracy: 0.7082 - val_loss: 0.9037 - val_accuracy: 0.6986\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 323us/step - loss: 0.8383 - accuracy: 0.7210 - val_loss: 0.9451 - val_accuracy: 0.6746\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 338us/step - loss: 0.8381 - accuracy: 0.7183 - val_loss: 0.9030 - val_accuracy: 0.6746\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 361us/step - loss: 0.8331 - accuracy: 0.7146 - val_loss: 0.9130 - val_accuracy: 0.6746\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 0.8323 - accuracy: 0.7162 - val_loss: 0.9257 - val_accuracy: 0.6651\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 346us/step - loss: 0.8139 - accuracy: 0.7263 - val_loss: 0.9222 - val_accuracy: 0.6651\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.8162 - accuracy: 0.7268 - val_loss: 0.9187 - val_accuracy: 0.6746\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 0.7976 - accuracy: 0.7332 - val_loss: 0.9548 - val_accuracy: 0.6459\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 0.8045 - accuracy: 0.7173 - val_loss: 0.9139 - val_accuracy: 0.6746\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.7814 - accuracy: 0.7343 - val_loss: 0.9296 - val_accuracy: 0.6603\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.7786 - accuracy: 0.7322 - val_loss: 0.8916 - val_accuracy: 0.6794\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.7863 - accuracy: 0.7274 - val_loss: 0.9157 - val_accuracy: 0.6890\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 264us/step - loss: 0.7618 - accuracy: 0.7460 - val_loss: 0.9071 - val_accuracy: 0.6842\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.7662 - accuracy: 0.7364 - val_loss: 0.9082 - val_accuracy: 0.6746\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.7658 - accuracy: 0.7316 - val_loss: 0.9229 - val_accuracy: 0.6555\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 0.7596 - accuracy: 0.7316 - val_loss: 0.9059 - val_accuracy: 0.6555\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 0.7455 - accuracy: 0.7449 - val_loss: 0.8982 - val_accuracy: 0.6746\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.7354 - accuracy: 0.7476 - val_loss: 0.8797 - val_accuracy: 0.6986\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.7269 - accuracy: 0.7476 - val_loss: 0.9066 - val_accuracy: 0.6699\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 0.7231 - accuracy: 0.7529 - val_loss: 0.8857 - val_accuracy: 0.6890\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.7197 - accuracy: 0.7476 - val_loss: 0.8773 - val_accuracy: 0.7033\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.7073 - accuracy: 0.7572 - val_loss: 0.8698 - val_accuracy: 0.6986\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.7239 - accuracy: 0.7439 - val_loss: 0.8924 - val_accuracy: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 47/60 [55:16<09:33, 44.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.2564 - accuracy: 0.4712 - val_loss: 1.2628 - val_accuracy: 0.5167\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1606 - accuracy: 0.5490 - val_loss: 1.2242 - val_accuracy: 0.5120\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1260 - accuracy: 0.5490 - val_loss: 1.1821 - val_accuracy: 0.5167\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1110 - accuracy: 0.5580 - val_loss: 1.1560 - val_accuracy: 0.5311\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0939 - accuracy: 0.5591 - val_loss: 1.1248 - val_accuracy: 0.5837\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0844 - accuracy: 0.5905 - val_loss: 1.1103 - val_accuracy: 0.5837\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 957us/step - loss: 1.0655 - accuracy: 0.6097 - val_loss: 1.0870 - val_accuracy: 0.5550\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0501 - accuracy: 0.6102 - val_loss: 1.1160 - val_accuracy: 0.5646\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0405 - accuracy: 0.6092 - val_loss: 1.0687 - val_accuracy: 0.5885\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 998us/step - loss: 1.0260 - accuracy: 0.6241 - val_loss: 1.0489 - val_accuracy: 0.5885\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 916us/step - loss: 1.0127 - accuracy: 0.6337 - val_loss: 1.0340 - val_accuracy: 0.6364\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 977us/step - loss: 1.0108 - accuracy: 0.6411 - val_loss: 1.1244 - val_accuracy: 0.5694\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 910us/step - loss: 0.9933 - accuracy: 0.6400 - val_loss: 1.0338 - val_accuracy: 0.6172\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 916us/step - loss: 0.9843 - accuracy: 0.6416 - val_loss: 1.0447 - val_accuracy: 0.6077\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9686 - accuracy: 0.6576 - val_loss: 0.9793 - val_accuracy: 0.6268\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9488 - accuracy: 0.6683 - val_loss: 0.9876 - val_accuracy: 0.6077\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9535 - accuracy: 0.6592 - val_loss: 1.0008 - val_accuracy: 0.5981\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 886us/step - loss: 0.9347 - accuracy: 0.6523 - val_loss: 0.9674 - val_accuracy: 0.6220\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9177 - accuracy: 0.6731 - val_loss: 0.9548 - val_accuracy: 0.6124\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9183 - accuracy: 0.6677 - val_loss: 0.9846 - val_accuracy: 0.6220\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9013 - accuracy: 0.6842 - val_loss: 0.9612 - val_accuracy: 0.6220\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 4s 2ms/step - loss: 0.9019 - accuracy: 0.6763 - val_loss: 0.9540 - val_accuracy: 0.6555\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9062 - accuracy: 0.6560 - val_loss: 0.9992 - val_accuracy: 0.5837\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8988 - accuracy: 0.6640 - val_loss: 0.9356 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8734 - accuracy: 0.6874 - val_loss: 0.9276 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8691 - accuracy: 0.6906 - val_loss: 0.9188 - val_accuracy: 0.6316\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8392 - accuracy: 0.7045 - val_loss: 0.9280 - val_accuracy: 0.6124\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8729 - accuracy: 0.6715 - val_loss: 0.8810 - val_accuracy: 0.6699\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8556 - accuracy: 0.6880 - val_loss: 0.9128 - val_accuracy: 0.6411\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8349 - accuracy: 0.7002 - val_loss: 0.9115 - val_accuracy: 0.6507\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8304 - accuracy: 0.6960 - val_loss: 0.9024 - val_accuracy: 0.6507\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8234 - accuracy: 0.7066 - val_loss: 0.9235 - val_accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8258 - accuracy: 0.7029 - val_loss: 0.9307 - val_accuracy: 0.6364\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8253 - accuracy: 0.6954 - val_loss: 0.9177 - val_accuracy: 0.6077\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7974 - accuracy: 0.7199 - val_loss: 0.9287 - val_accuracy: 0.6172\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8078 - accuracy: 0.6965 - val_loss: 0.9158 - val_accuracy: 0.6077\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8083 - accuracy: 0.7007 - val_loss: 0.9043 - val_accuracy: 0.6411\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7768 - accuracy: 0.7210 - val_loss: 0.8627 - val_accuracy: 0.6603\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 982us/step - loss: 0.7690 - accuracy: 0.7295 - val_loss: 0.8944 - val_accuracy: 0.6364\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7686 - accuracy: 0.7215 - val_loss: 0.8805 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 977us/step - loss: 0.7606 - accuracy: 0.7215 - val_loss: 0.9129 - val_accuracy: 0.6411\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7529 - accuracy: 0.7274 - val_loss: 0.9027 - val_accuracy: 0.6507\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 862us/step - loss: 0.7575 - accuracy: 0.7226 - val_loss: 0.8903 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7336 - accuracy: 0.7279 - val_loss: 0.8703 - val_accuracy: 0.6651\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7329 - accuracy: 0.7364 - val_loss: 0.8673 - val_accuracy: 0.6507\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7320 - accuracy: 0.7375 - val_loss: 0.8734 - val_accuracy: 0.6364\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7220 - accuracy: 0.7375 - val_loss: 0.8852 - val_accuracy: 0.6555\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7206 - accuracy: 0.7370 - val_loss: 0.8424 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.7068 - accuracy: 0.7508 - val_loss: 0.8371 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 827us/step - loss: 0.7171 - accuracy: 0.7332 - val_loss: 0.8826 - val_accuracy: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 48/60 [57:05<12:44, 63.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 705us/step - loss: 1.4456 - accuracy: 0.1874 - val_loss: 1.4308 - val_accuracy: 0.1340\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 186us/step - loss: 1.3948 - accuracy: 0.2657 - val_loss: 1.4003 - val_accuracy: 0.1340\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 186us/step - loss: 1.3489 - accuracy: 0.3621 - val_loss: 1.3697 - val_accuracy: 0.3206\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 181us/step - loss: 1.3097 - accuracy: 0.4350 - val_loss: 1.3400 - val_accuracy: 0.4450\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 1.2718 - accuracy: 0.4643 - val_loss: 1.3066 - val_accuracy: 0.4641\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 184us/step - loss: 1.2376 - accuracy: 0.5069 - val_loss: 1.2713 - val_accuracy: 0.4641\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.2077 - accuracy: 0.5266 - val_loss: 1.2397 - val_accuracy: 0.5024\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 137us/step - loss: 1.1863 - accuracy: 0.5389 - val_loss: 1.2104 - val_accuracy: 0.5215\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 194us/step - loss: 1.1611 - accuracy: 0.5447 - val_loss: 1.1865 - val_accuracy: 0.5502\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 189us/step - loss: 1.1423 - accuracy: 0.5458 - val_loss: 1.1627 - val_accuracy: 0.5550\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 1.1305 - accuracy: 0.5607 - val_loss: 1.1463 - val_accuracy: 0.5837\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 182us/step - loss: 1.0999 - accuracy: 0.5868 - val_loss: 1.1173 - val_accuracy: 0.5646\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 201us/step - loss: 1.0915 - accuracy: 0.5815 - val_loss: 1.0950 - val_accuracy: 0.5789\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 203us/step - loss: 1.0809 - accuracy: 0.6001 - val_loss: 1.0863 - val_accuracy: 0.5837\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 157us/step - loss: 1.0686 - accuracy: 0.6065 - val_loss: 1.0623 - val_accuracy: 0.6124\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 182us/step - loss: 1.0595 - accuracy: 0.6155 - val_loss: 1.0516 - val_accuracy: 0.6316\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 1.0410 - accuracy: 0.6299 - val_loss: 1.0406 - val_accuracy: 0.6172\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 160us/step - loss: 1.0338 - accuracy: 0.6203 - val_loss: 1.0243 - val_accuracy: 0.6316\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 189us/step - loss: 1.0086 - accuracy: 0.6422 - val_loss: 1.0071 - val_accuracy: 0.6411\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 227us/step - loss: 0.9990 - accuracy: 0.6400 - val_loss: 0.9916 - val_accuracy: 0.6459\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.9909 - accuracy: 0.6422 - val_loss: 0.9719 - val_accuracy: 0.6651\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 199us/step - loss: 0.9827 - accuracy: 0.6480 - val_loss: 0.9686 - val_accuracy: 0.6555\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 0.9778 - accuracy: 0.6438 - val_loss: 0.9640 - val_accuracy: 0.6651\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 243us/step - loss: 0.9671 - accuracy: 0.6480 - val_loss: 0.9503 - val_accuracy: 0.6842\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 0.9634 - accuracy: 0.6486 - val_loss: 0.9484 - val_accuracy: 0.6746\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 195us/step - loss: 0.9524 - accuracy: 0.6528 - val_loss: 0.9354 - val_accuracy: 0.6699\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 163us/step - loss: 0.9498 - accuracy: 0.6523 - val_loss: 0.9397 - val_accuracy: 0.6651\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 143us/step - loss: 0.9327 - accuracy: 0.6677 - val_loss: 0.9266 - val_accuracy: 0.6651\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 150us/step - loss: 0.9368 - accuracy: 0.6597 - val_loss: 0.9219 - val_accuracy: 0.6555\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 232us/step - loss: 0.9228 - accuracy: 0.6624 - val_loss: 0.9221 - val_accuracy: 0.6459\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 138us/step - loss: 0.9306 - accuracy: 0.6635 - val_loss: 0.9236 - val_accuracy: 0.6603\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 167us/step - loss: 0.9220 - accuracy: 0.6720 - val_loss: 0.9158 - val_accuracy: 0.6794\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 144us/step - loss: 0.9131 - accuracy: 0.6752 - val_loss: 0.9067 - val_accuracy: 0.6603\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 138us/step - loss: 0.9019 - accuracy: 0.6784 - val_loss: 0.9163 - val_accuracy: 0.6555\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 138us/step - loss: 0.9083 - accuracy: 0.6693 - val_loss: 0.9150 - val_accuracy: 0.6364\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 140us/step - loss: 0.9053 - accuracy: 0.6704 - val_loss: 0.9184 - val_accuracy: 0.6411\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 139us/step - loss: 0.8862 - accuracy: 0.6784 - val_loss: 0.9157 - val_accuracy: 0.6411\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 137us/step - loss: 0.8819 - accuracy: 0.6768 - val_loss: 0.9035 - val_accuracy: 0.6459\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 128us/step - loss: 0.9036 - accuracy: 0.6635 - val_loss: 0.8955 - val_accuracy: 0.6507\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 236us/step - loss: 0.8776 - accuracy: 0.6768 - val_loss: 0.8882 - val_accuracy: 0.6651\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 195us/step - loss: 0.8904 - accuracy: 0.6624 - val_loss: 0.8926 - val_accuracy: 0.6651\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 144us/step - loss: 0.8863 - accuracy: 0.6725 - val_loss: 0.8954 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 138us/step - loss: 0.8806 - accuracy: 0.6704 - val_loss: 0.8835 - val_accuracy: 0.6603\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 143us/step - loss: 0.8652 - accuracy: 0.6864 - val_loss: 0.8876 - val_accuracy: 0.6459\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 0.8633 - accuracy: 0.6805 - val_loss: 0.8847 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 0.8453 - accuracy: 0.6981 - val_loss: 0.8969 - val_accuracy: 0.6459\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 144us/step - loss: 0.8447 - accuracy: 0.6917 - val_loss: 0.8929 - val_accuracy: 0.6459\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 150us/step - loss: 0.8538 - accuracy: 0.6917 - val_loss: 0.8856 - val_accuracy: 0.6555\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 0.8561 - accuracy: 0.6837 - val_loss: 0.8859 - val_accuracy: 0.6555\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 0.8374 - accuracy: 0.6997 - val_loss: 0.8911 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 49/60 [57:25<09:16, 50.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 744us/step - loss: 1.3288 - accuracy: 0.3967 - val_loss: 1.3668 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 1.2591 - accuracy: 0.4771 - val_loss: 1.3208 - val_accuracy: 0.4354\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 305us/step - loss: 1.2166 - accuracy: 0.5005 - val_loss: 1.2736 - val_accuracy: 0.4641\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 1.1963 - accuracy: 0.5000 - val_loss: 1.2465 - val_accuracy: 0.4545\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 292us/step - loss: 1.1694 - accuracy: 0.5037 - val_loss: 1.2130 - val_accuracy: 0.4593\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 371us/step - loss: 1.1556 - accuracy: 0.5021 - val_loss: 1.1790 - val_accuracy: 0.4641\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 1.1444 - accuracy: 0.5117 - val_loss: 1.1571 - val_accuracy: 0.4785\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 1.1179 - accuracy: 0.5346 - val_loss: 1.1327 - val_accuracy: 0.4737\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 1.1084 - accuracy: 0.5314 - val_loss: 1.1221 - val_accuracy: 0.5167\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 1.0970 - accuracy: 0.5415 - val_loss: 1.0975 - val_accuracy: 0.5885\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 1.0801 - accuracy: 0.5623 - val_loss: 1.0805 - val_accuracy: 0.5742\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 254us/step - loss: 1.0750 - accuracy: 0.5564 - val_loss: 1.0704 - val_accuracy: 0.5789\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 1.0600 - accuracy: 0.5666 - val_loss: 1.0707 - val_accuracy: 0.5933\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 255us/step - loss: 1.0464 - accuracy: 0.5847 - val_loss: 1.0665 - val_accuracy: 0.5885\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 1.0341 - accuracy: 0.5756 - val_loss: 1.0514 - val_accuracy: 0.5789\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 1.0360 - accuracy: 0.5767 - val_loss: 1.0316 - val_accuracy: 0.5885\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 253us/step - loss: 1.0153 - accuracy: 0.6017 - val_loss: 1.0407 - val_accuracy: 0.5933\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 1.0133 - accuracy: 0.5937 - val_loss: 1.0373 - val_accuracy: 0.5694\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 1.0009 - accuracy: 0.5942 - val_loss: 1.0096 - val_accuracy: 0.5981\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.9939 - accuracy: 0.6150 - val_loss: 1.0111 - val_accuracy: 0.5981\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 260us/step - loss: 0.9780 - accuracy: 0.5969 - val_loss: 1.0106 - val_accuracy: 0.5742\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 0.9770 - accuracy: 0.6076 - val_loss: 0.9939 - val_accuracy: 0.5933\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 257us/step - loss: 0.9613 - accuracy: 0.6012 - val_loss: 0.9926 - val_accuracy: 0.6029\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.9660 - accuracy: 0.5895 - val_loss: 0.9996 - val_accuracy: 0.5694\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 264us/step - loss: 0.9418 - accuracy: 0.6491 - val_loss: 0.9954 - val_accuracy: 0.6172\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 250us/step - loss: 0.9440 - accuracy: 0.6443 - val_loss: 0.9752 - val_accuracy: 0.6220\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.9368 - accuracy: 0.6454 - val_loss: 0.9966 - val_accuracy: 0.6172\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 263us/step - loss: 0.9291 - accuracy: 0.6454 - val_loss: 0.9702 - val_accuracy: 0.6268\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 274us/step - loss: 0.9108 - accuracy: 0.6486 - val_loss: 0.9749 - val_accuracy: 0.6172\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 399us/step - loss: 0.9147 - accuracy: 0.6448 - val_loss: 0.9695 - val_accuracy: 0.6316\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.9161 - accuracy: 0.6422 - val_loss: 0.9656 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.8935 - accuracy: 0.6619 - val_loss: 0.9496 - val_accuracy: 0.6316\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 266us/step - loss: 0.8922 - accuracy: 0.6587 - val_loss: 0.9483 - val_accuracy: 0.6124\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 290us/step - loss: 0.8728 - accuracy: 0.6725 - val_loss: 0.9520 - val_accuracy: 0.6268\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.8936 - accuracy: 0.6507 - val_loss: 0.9532 - val_accuracy: 0.6124\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.8487 - accuracy: 0.6784 - val_loss: 0.9491 - val_accuracy: 0.6077\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 282us/step - loss: 0.8546 - accuracy: 0.6725 - val_loss: 0.9334 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.8731 - accuracy: 0.6661 - val_loss: 0.9398 - val_accuracy: 0.6459\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 303us/step - loss: 0.8579 - accuracy: 0.6683 - val_loss: 0.9615 - val_accuracy: 0.6316\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 307us/step - loss: 0.8527 - accuracy: 0.6608 - val_loss: 0.9375 - val_accuracy: 0.6268\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 266us/step - loss: 0.8281 - accuracy: 0.6917 - val_loss: 0.9399 - val_accuracy: 0.6172\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 283us/step - loss: 0.8449 - accuracy: 0.6699 - val_loss: 0.9042 - val_accuracy: 0.6364\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 290us/step - loss: 0.8284 - accuracy: 0.6763 - val_loss: 0.9098 - val_accuracy: 0.6316\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 0.8225 - accuracy: 0.6848 - val_loss: 0.8961 - val_accuracy: 0.6507\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 267us/step - loss: 0.8256 - accuracy: 0.6874 - val_loss: 0.9082 - val_accuracy: 0.6459\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 281us/step - loss: 0.8091 - accuracy: 0.7034 - val_loss: 0.8964 - val_accuracy: 0.6507\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 315us/step - loss: 0.8155 - accuracy: 0.6922 - val_loss: 0.8889 - val_accuracy: 0.6459\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.8024 - accuracy: 0.7029 - val_loss: 0.8814 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 303us/step - loss: 0.7859 - accuracy: 0.7141 - val_loss: 0.8799 - val_accuracy: 0.6746\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.7856 - accuracy: 0.7119 - val_loss: 0.8969 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 50/60 [57:54<07:21, 44.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2779 - accuracy: 0.4473 - val_loss: 1.3018 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 872us/step - loss: 1.2071 - accuracy: 0.5314 - val_loss: 1.2402 - val_accuracy: 0.4928\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 932us/step - loss: 1.1944 - accuracy: 0.5293 - val_loss: 1.2214 - val_accuracy: 0.5167\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 930us/step - loss: 1.1827 - accuracy: 0.5453 - val_loss: 1.2336 - val_accuracy: 0.4402\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 953us/step - loss: 1.1538 - accuracy: 0.5527 - val_loss: 1.1662 - val_accuracy: 0.5694\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 900us/step - loss: 1.1241 - accuracy: 0.6017 - val_loss: 1.1675 - val_accuracy: 0.5550\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 947us/step - loss: 1.1228 - accuracy: 0.5953 - val_loss: 1.1643 - val_accuracy: 0.5598\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1110 - accuracy: 0.6001 - val_loss: 1.1359 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 931us/step - loss: 1.0876 - accuracy: 0.6278 - val_loss: 1.0908 - val_accuracy: 0.6364\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 900us/step - loss: 1.0827 - accuracy: 0.6081 - val_loss: 1.1020 - val_accuracy: 0.5837\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 943us/step - loss: 1.0763 - accuracy: 0.6134 - val_loss: 1.1140 - val_accuracy: 0.5885\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 951us/step - loss: 1.0686 - accuracy: 0.6129 - val_loss: 1.0830 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 976us/step - loss: 1.0467 - accuracy: 0.6363 - val_loss: 1.0675 - val_accuracy: 0.6172\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 832us/step - loss: 1.0681 - accuracy: 0.6028 - val_loss: 1.0822 - val_accuracy: 0.6077\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 875us/step - loss: 1.0362 - accuracy: 0.6353 - val_loss: 1.0571 - val_accuracy: 0.6124\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 993us/step - loss: 1.0256 - accuracy: 0.6294 - val_loss: 1.0609 - val_accuracy: 0.5885\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 898us/step - loss: 1.0189 - accuracy: 0.6294 - val_loss: 1.0403 - val_accuracy: 0.5933\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 902us/step - loss: 1.0168 - accuracy: 0.6443 - val_loss: 1.0420 - val_accuracy: 0.6364\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 842us/step - loss: 1.0083 - accuracy: 0.6470 - val_loss: 1.0150 - val_accuracy: 0.6507\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 871us/step - loss: 0.9878 - accuracy: 0.6587 - val_loss: 1.0131 - val_accuracy: 0.6364\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9949 - accuracy: 0.6480 - val_loss: 0.9865 - val_accuracy: 0.6411\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 980us/step - loss: 0.9898 - accuracy: 0.6400 - val_loss: 1.0214 - val_accuracy: 0.6124\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 947us/step - loss: 0.9851 - accuracy: 0.6534 - val_loss: 0.9890 - val_accuracy: 0.6411\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 997us/step - loss: 0.9627 - accuracy: 0.6560 - val_loss: 0.9944 - val_accuracy: 0.6555\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 920us/step - loss: 0.9656 - accuracy: 0.6560 - val_loss: 0.9972 - val_accuracy: 0.6364\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 894us/step - loss: 0.9679 - accuracy: 0.6518 - val_loss: 0.9724 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 912us/step - loss: 0.9454 - accuracy: 0.6693 - val_loss: 0.9976 - val_accuracy: 0.6268\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 935us/step - loss: 0.9422 - accuracy: 0.6661 - val_loss: 0.9768 - val_accuracy: 0.6603\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9374 - accuracy: 0.6672 - val_loss: 0.9864 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 983us/step - loss: 0.9382 - accuracy: 0.6688 - val_loss: 0.9600 - val_accuracy: 0.6459\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 980us/step - loss: 0.9228 - accuracy: 0.6720 - val_loss: 0.9786 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 933us/step - loss: 0.9162 - accuracy: 0.6688 - val_loss: 0.9853 - val_accuracy: 0.6220\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 853us/step - loss: 0.9296 - accuracy: 0.6608 - val_loss: 0.9791 - val_accuracy: 0.6364\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 853us/step - loss: 0.9211 - accuracy: 0.6699 - val_loss: 0.9972 - val_accuracy: 0.6364\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 861us/step - loss: 0.8978 - accuracy: 0.6832 - val_loss: 0.9698 - val_accuracy: 0.6316\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 868us/step - loss: 0.9105 - accuracy: 0.6768 - val_loss: 0.9596 - val_accuracy: 0.6555\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 933us/step - loss: 0.8849 - accuracy: 0.6880 - val_loss: 0.9437 - val_accuracy: 0.6411\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 889us/step - loss: 0.8891 - accuracy: 0.6816 - val_loss: 0.9902 - val_accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 894us/step - loss: 0.8695 - accuracy: 0.6954 - val_loss: 0.9848 - val_accuracy: 0.6124\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 919us/step - loss: 0.8529 - accuracy: 0.6981 - val_loss: 0.9722 - val_accuracy: 0.6507\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 868us/step - loss: 0.8595 - accuracy: 0.6933 - val_loss: 0.9535 - val_accuracy: 0.6364\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 955us/step - loss: 0.8653 - accuracy: 0.6944 - val_loss: 0.9606 - val_accuracy: 0.6411\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8626 - accuracy: 0.6933 - val_loss: 0.9516 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 886us/step - loss: 0.8429 - accuracy: 0.7018 - val_loss: 0.9597 - val_accuracy: 0.6172\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 891us/step - loss: 0.8323 - accuracy: 0.7141 - val_loss: 0.9733 - val_accuracy: 0.6220\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 947us/step - loss: 0.8081 - accuracy: 0.7226 - val_loss: 0.9556 - val_accuracy: 0.6411\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 932us/step - loss: 0.8300 - accuracy: 0.7109 - val_loss: 0.9448 - val_accuracy: 0.6364\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 939us/step - loss: 0.8119 - accuracy: 0.7162 - val_loss: 0.9386 - val_accuracy: 0.6411\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 969us/step - loss: 0.8209 - accuracy: 0.7125 - val_loss: 0.9250 - val_accuracy: 0.6651\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.7844 - accuracy: 0.7322 - val_loss: 0.9154 - val_accuracy: 0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 51/60 [59:26<08:45, 58.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 695us/step - loss: 1.3557 - accuracy: 0.3435 - val_loss: 1.3622 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 196us/step - loss: 1.3229 - accuracy: 0.4228 - val_loss: 1.3430 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 1.2964 - accuracy: 0.4366 - val_loss: 1.3247 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 148us/step - loss: 1.2741 - accuracy: 0.4547 - val_loss: 1.3089 - val_accuracy: 0.3971\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 213us/step - loss: 1.2536 - accuracy: 0.4633 - val_loss: 1.2911 - val_accuracy: 0.3971\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.2341 - accuracy: 0.4739 - val_loss: 1.2690 - val_accuracy: 0.4306\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 217us/step - loss: 1.2119 - accuracy: 0.5027 - val_loss: 1.2435 - val_accuracy: 0.4737\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 203us/step - loss: 1.1910 - accuracy: 0.5128 - val_loss: 1.2227 - val_accuracy: 0.5024\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 1.1769 - accuracy: 0.5106 - val_loss: 1.2041 - val_accuracy: 0.5072\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 164us/step - loss: 1.1620 - accuracy: 0.5240 - val_loss: 1.1823 - val_accuracy: 0.5215\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 1.1465 - accuracy: 0.5293 - val_loss: 1.1645 - val_accuracy: 0.5167\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.1338 - accuracy: 0.5394 - val_loss: 1.1503 - val_accuracy: 0.5024\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 175us/step - loss: 1.1264 - accuracy: 0.5442 - val_loss: 1.1449 - val_accuracy: 0.5263\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 1.1167 - accuracy: 0.5437 - val_loss: 1.1338 - val_accuracy: 0.5455\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 164us/step - loss: 1.0932 - accuracy: 0.5799 - val_loss: 1.1256 - val_accuracy: 0.5550\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 1.0884 - accuracy: 0.5895 - val_loss: 1.1237 - val_accuracy: 0.5502\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 167us/step - loss: 1.0796 - accuracy: 0.5863 - val_loss: 1.1107 - val_accuracy: 0.5550\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 1.0693 - accuracy: 0.5942 - val_loss: 1.1001 - val_accuracy: 0.5502\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 1.0622 - accuracy: 0.6022 - val_loss: 1.0882 - val_accuracy: 0.5598\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 1.0579 - accuracy: 0.5958 - val_loss: 1.0905 - val_accuracy: 0.5598\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 1.0587 - accuracy: 0.5895 - val_loss: 1.0832 - val_accuracy: 0.5646\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 1.0440 - accuracy: 0.6033 - val_loss: 1.0734 - val_accuracy: 0.5789\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 177us/step - loss: 1.0408 - accuracy: 0.5996 - val_loss: 1.0724 - val_accuracy: 0.5789\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 1.0289 - accuracy: 0.6028 - val_loss: 1.0665 - val_accuracy: 0.5789\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 174us/step - loss: 1.0365 - accuracy: 0.5953 - val_loss: 1.0645 - val_accuracy: 0.5742\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 1.0239 - accuracy: 0.6108 - val_loss: 1.0657 - val_accuracy: 0.5789\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 1.0194 - accuracy: 0.6081 - val_loss: 1.0688 - val_accuracy: 0.5742\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 1.0210 - accuracy: 0.6044 - val_loss: 1.0684 - val_accuracy: 0.5646\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.0100 - accuracy: 0.6081 - val_loss: 1.0512 - val_accuracy: 0.5885\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 1.0026 - accuracy: 0.6182 - val_loss: 1.0408 - val_accuracy: 0.5646\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 1.0054 - accuracy: 0.6070 - val_loss: 1.0396 - val_accuracy: 0.5646\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.9981 - accuracy: 0.6171 - val_loss: 1.0372 - val_accuracy: 0.5694\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 0.9821 - accuracy: 0.6246 - val_loss: 1.0284 - val_accuracy: 0.5742\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 1.0023 - accuracy: 0.6022 - val_loss: 1.0242 - val_accuracy: 0.5789\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 0.9806 - accuracy: 0.6161 - val_loss: 1.0251 - val_accuracy: 0.5742\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 175us/step - loss: 0.9842 - accuracy: 0.6161 - val_loss: 1.0273 - val_accuracy: 0.5742\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 0.9908 - accuracy: 0.6113 - val_loss: 1.0229 - val_accuracy: 0.5789\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 167us/step - loss: 0.9776 - accuracy: 0.6134 - val_loss: 1.0177 - val_accuracy: 0.5789\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 0.9816 - accuracy: 0.6113 - val_loss: 1.0161 - val_accuracy: 0.5789\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 161us/step - loss: 0.9744 - accuracy: 0.6171 - val_loss: 1.0166 - val_accuracy: 0.5694\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 0.9682 - accuracy: 0.6203 - val_loss: 1.0100 - val_accuracy: 0.5885\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 0.9686 - accuracy: 0.6102 - val_loss: 1.0077 - val_accuracy: 0.5885\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.9528 - accuracy: 0.6187 - val_loss: 1.0085 - val_accuracy: 0.5885\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 0.9562 - accuracy: 0.6219 - val_loss: 1.0119 - val_accuracy: 0.5742\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 163us/step - loss: 0.9413 - accuracy: 0.6283 - val_loss: 1.0087 - val_accuracy: 0.5789\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 167us/step - loss: 0.9609 - accuracy: 0.6134 - val_loss: 1.0028 - val_accuracy: 0.5789\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 0.9492 - accuracy: 0.6140 - val_loss: 0.9989 - val_accuracy: 0.5789\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.9277 - accuracy: 0.6219 - val_loss: 0.9960 - val_accuracy: 0.5837\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.9360 - accuracy: 0.6310 - val_loss: 0.9913 - val_accuracy: 0.5885\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 178us/step - loss: 0.9222 - accuracy: 0.6283 - val_loss: 0.9914 - val_accuracy: 0.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 52/60 [59:46<06:14, 46.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 728us/step - loss: 1.3104 - accuracy: 0.3903 - val_loss: 1.3292 - val_accuracy: 0.4258\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 299us/step - loss: 1.1951 - accuracy: 0.5213 - val_loss: 1.2697 - val_accuracy: 0.4450\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 1.1598 - accuracy: 0.5485 - val_loss: 1.2314 - val_accuracy: 0.5215\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 304us/step - loss: 1.1281 - accuracy: 0.5602 - val_loss: 1.1924 - val_accuracy: 0.4976\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: 1.1102 - accuracy: 0.5793 - val_loss: 1.1666 - val_accuracy: 0.5598\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 1.0832 - accuracy: 0.5996 - val_loss: 1.1294 - val_accuracy: 0.5502\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 1.0747 - accuracy: 0.6012 - val_loss: 1.1095 - val_accuracy: 0.5694\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 1.0728 - accuracy: 0.5937 - val_loss: 1.0782 - val_accuracy: 0.5646\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 1.0636 - accuracy: 0.5958 - val_loss: 1.0670 - val_accuracy: 0.6029\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 1.0396 - accuracy: 0.6124 - val_loss: 1.0515 - val_accuracy: 0.6268\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 1.0350 - accuracy: 0.6214 - val_loss: 1.0315 - val_accuracy: 0.6172\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 1.0298 - accuracy: 0.6235 - val_loss: 1.0317 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 1.0071 - accuracy: 0.6315 - val_loss: 1.0413 - val_accuracy: 0.6364\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 302us/step - loss: 0.9943 - accuracy: 0.6337 - val_loss: 1.0230 - val_accuracy: 0.6124\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 300us/step - loss: 0.9903 - accuracy: 0.6374 - val_loss: 1.0182 - val_accuracy: 0.6172\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 0.9742 - accuracy: 0.6454 - val_loss: 1.0037 - val_accuracy: 0.6316\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.9647 - accuracy: 0.6507 - val_loss: 0.9855 - val_accuracy: 0.6220\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.9502 - accuracy: 0.6571 - val_loss: 0.9885 - val_accuracy: 0.6507\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.9441 - accuracy: 0.6672 - val_loss: 0.9782 - val_accuracy: 0.6268\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.9441 - accuracy: 0.6544 - val_loss: 0.9736 - val_accuracy: 0.6411\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 303us/step - loss: 0.9429 - accuracy: 0.6544 - val_loss: 0.9650 - val_accuracy: 0.6364\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.9379 - accuracy: 0.6539 - val_loss: 0.9754 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 305us/step - loss: 0.9304 - accuracy: 0.6699 - val_loss: 0.9532 - val_accuracy: 0.6459\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.9336 - accuracy: 0.6496 - val_loss: 0.9571 - val_accuracy: 0.6507\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 299us/step - loss: 0.9145 - accuracy: 0.6555 - val_loss: 0.9537 - val_accuracy: 0.6555\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.8987 - accuracy: 0.6672 - val_loss: 0.9451 - val_accuracy: 0.6459\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.8956 - accuracy: 0.6534 - val_loss: 0.9336 - val_accuracy: 0.6890\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.8909 - accuracy: 0.6677 - val_loss: 0.9245 - val_accuracy: 0.6651\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 283us/step - loss: 0.8742 - accuracy: 0.6864 - val_loss: 0.9181 - val_accuracy: 0.6699\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.8699 - accuracy: 0.6832 - val_loss: 0.9266 - val_accuracy: 0.6507\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.8571 - accuracy: 0.6869 - val_loss: 0.9169 - val_accuracy: 0.6651\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 313us/step - loss: 0.8669 - accuracy: 0.6736 - val_loss: 0.8961 - val_accuracy: 0.6794\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.8604 - accuracy: 0.6869 - val_loss: 0.9213 - val_accuracy: 0.6651\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 293us/step - loss: 0.8548 - accuracy: 0.6800 - val_loss: 0.9180 - val_accuracy: 0.6603\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.8235 - accuracy: 0.7007 - val_loss: 0.8973 - val_accuracy: 0.6699\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.8194 - accuracy: 0.7061 - val_loss: 0.9086 - val_accuracy: 0.6603\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 0.8283 - accuracy: 0.6917 - val_loss: 0.9022 - val_accuracy: 0.6603\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 0.8140 - accuracy: 0.7007 - val_loss: 0.8944 - val_accuracy: 0.6507\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.8237 - accuracy: 0.6896 - val_loss: 0.8934 - val_accuracy: 0.6651\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 282us/step - loss: 0.8089 - accuracy: 0.7007 - val_loss: 0.8959 - val_accuracy: 0.6651\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 0.8012 - accuracy: 0.7077 - val_loss: 0.8931 - val_accuracy: 0.6555\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 290us/step - loss: 0.8066 - accuracy: 0.6997 - val_loss: 0.8946 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.7934 - accuracy: 0.7045 - val_loss: 0.8811 - val_accuracy: 0.6555\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 306us/step - loss: 0.7896 - accuracy: 0.6997 - val_loss: 0.8799 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.7776 - accuracy: 0.7114 - val_loss: 0.8821 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 304us/step - loss: 0.7771 - accuracy: 0.7050 - val_loss: 0.8738 - val_accuracy: 0.6746\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 303us/step - loss: 0.7690 - accuracy: 0.7125 - val_loss: 0.8769 - val_accuracy: 0.6507\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 0.7637 - accuracy: 0.7130 - val_loss: 0.8511 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.7475 - accuracy: 0.7252 - val_loss: 0.8715 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 302us/step - loss: 0.7486 - accuracy: 0.7247 - val_loss: 0.8770 - val_accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 53/60 [1:00:16<04:53, 41.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.2867 - accuracy: 0.4547 - val_loss: 1.3392 - val_accuracy: 0.4019\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 914us/step - loss: 1.2187 - accuracy: 0.5234 - val_loss: 1.2629 - val_accuracy: 0.4545\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 947us/step - loss: 1.1900 - accuracy: 0.5564 - val_loss: 1.2190 - val_accuracy: 0.5502\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 926us/step - loss: 1.1585 - accuracy: 0.5905 - val_loss: 1.1738 - val_accuracy: 0.5550\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 936us/step - loss: 1.1574 - accuracy: 0.5660 - val_loss: 1.1653 - val_accuracy: 0.5550\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 941us/step - loss: 1.1314 - accuracy: 0.5676 - val_loss: 1.1312 - val_accuracy: 0.5742\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 949us/step - loss: 1.1267 - accuracy: 0.5799 - val_loss: 1.1225 - val_accuracy: 0.5981\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1240 - accuracy: 0.5506 - val_loss: 1.1042 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 960us/step - loss: 1.0978 - accuracy: 0.5911 - val_loss: 1.1054 - val_accuracy: 0.5742\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0948 - accuracy: 0.5985 - val_loss: 1.0846 - val_accuracy: 0.6316\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0786 - accuracy: 0.6028 - val_loss: 1.0691 - val_accuracy: 0.6316\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 975us/step - loss: 1.0708 - accuracy: 0.6065 - val_loss: 1.0533 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 925us/step - loss: 1.0641 - accuracy: 0.5974 - val_loss: 1.0321 - val_accuracy: 0.6411\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 909us/step - loss: 1.0496 - accuracy: 0.6076 - val_loss: 1.0437 - val_accuracy: 0.6220\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 950us/step - loss: 1.0324 - accuracy: 0.6203 - val_loss: 1.0444 - val_accuracy: 0.6316\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 925us/step - loss: 1.0336 - accuracy: 0.6193 - val_loss: 1.0210 - val_accuracy: 0.6459\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 947us/step - loss: 1.0208 - accuracy: 0.6155 - val_loss: 1.0274 - val_accuracy: 0.6459\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 922us/step - loss: 1.0209 - accuracy: 0.6278 - val_loss: 1.0096 - val_accuracy: 0.6268\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 950us/step - loss: 1.0023 - accuracy: 0.6315 - val_loss: 0.9877 - val_accuracy: 0.6699\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 960us/step - loss: 0.9947 - accuracy: 0.6411 - val_loss: 1.0157 - val_accuracy: 0.6316\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 921us/step - loss: 0.9891 - accuracy: 0.6587 - val_loss: 0.9713 - val_accuracy: 0.6555\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 946us/step - loss: 0.9939 - accuracy: 0.6225 - val_loss: 0.9922 - val_accuracy: 0.6459\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 958us/step - loss: 0.9619 - accuracy: 0.6448 - val_loss: 0.9972 - val_accuracy: 0.6172\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 958us/step - loss: 0.9719 - accuracy: 0.6363 - val_loss: 0.9540 - val_accuracy: 0.6699\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 946us/step - loss: 0.9731 - accuracy: 0.6384 - val_loss: 0.9832 - val_accuracy: 0.6364\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 963us/step - loss: 0.9593 - accuracy: 0.6427 - val_loss: 0.9963 - val_accuracy: 0.5981\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 935us/step - loss: 0.9412 - accuracy: 0.6608 - val_loss: 0.9248 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 943us/step - loss: 0.9544 - accuracy: 0.6491 - val_loss: 0.9400 - val_accuracy: 0.6459\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9217 - accuracy: 0.6683 - val_loss: 0.9363 - val_accuracy: 0.6316\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9213 - accuracy: 0.6656 - val_loss: 0.9302 - val_accuracy: 0.6603\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9270 - accuracy: 0.6502 - val_loss: 0.9796 - val_accuracy: 0.6029\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9195 - accuracy: 0.6656 - val_loss: 0.9677 - val_accuracy: 0.6172\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9052 - accuracy: 0.6725 - val_loss: 0.9563 - val_accuracy: 0.6220\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9053 - accuracy: 0.6661 - val_loss: 0.9513 - val_accuracy: 0.6316\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 955us/step - loss: 0.9098 - accuracy: 0.6613 - val_loss: 0.9343 - val_accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9058 - accuracy: 0.6645 - val_loss: 0.9405 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8791 - accuracy: 0.6821 - val_loss: 0.9432 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 961us/step - loss: 0.8962 - accuracy: 0.6677 - val_loss: 0.9105 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8648 - accuracy: 0.6869 - val_loss: 0.9304 - val_accuracy: 0.6411\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8716 - accuracy: 0.6853 - val_loss: 0.9152 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8576 - accuracy: 0.6848 - val_loss: 0.9171 - val_accuracy: 0.6411\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 958us/step - loss: 0.8521 - accuracy: 0.6917 - val_loss: 0.9186 - val_accuracy: 0.6411\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 931us/step - loss: 0.8563 - accuracy: 0.6906 - val_loss: 0.9019 - val_accuracy: 0.6651\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8455 - accuracy: 0.6880 - val_loss: 0.9209 - val_accuracy: 0.6411\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 986us/step - loss: 0.8275 - accuracy: 0.7023 - val_loss: 0.9130 - val_accuracy: 0.6316\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 978us/step - loss: 0.8445 - accuracy: 0.6906 - val_loss: 0.8958 - val_accuracy: 0.6603\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 921us/step - loss: 0.8276 - accuracy: 0.7045 - val_loss: 0.9291 - val_accuracy: 0.6220\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8207 - accuracy: 0.6976 - val_loss: 0.8631 - val_accuracy: 0.6794\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8034 - accuracy: 0.7157 - val_loss: 0.9032 - val_accuracy: 0.6172\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8019 - accuracy: 0.7029 - val_loss: 0.8905 - val_accuracy: 0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 54/60 [1:01:55<05:53, 58.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 817us/step - loss: 1.3778 - accuracy: 0.2401 - val_loss: 1.3540 - val_accuracy: 0.3828\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 200us/step - loss: 1.3533 - accuracy: 0.3839 - val_loss: 1.3416 - val_accuracy: 0.3971\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 233us/step - loss: 1.3292 - accuracy: 0.4436 - val_loss: 1.3296 - val_accuracy: 0.3971\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 196us/step - loss: 1.3123 - accuracy: 0.4553 - val_loss: 1.3171 - val_accuracy: 0.3971\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 183us/step - loss: 1.2944 - accuracy: 0.4601 - val_loss: 1.3023 - val_accuracy: 0.3923\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 185us/step - loss: 1.2753 - accuracy: 0.4723 - val_loss: 1.2831 - val_accuracy: 0.4115\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 184us/step - loss: 1.2579 - accuracy: 0.4808 - val_loss: 1.2615 - val_accuracy: 0.4354\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 185us/step - loss: 1.2430 - accuracy: 0.4947 - val_loss: 1.2378 - val_accuracy: 0.4593\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 234us/step - loss: 1.2211 - accuracy: 0.5043 - val_loss: 1.2181 - val_accuracy: 0.4593\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 234us/step - loss: 1.2070 - accuracy: 0.5101 - val_loss: 1.1969 - val_accuracy: 0.4928\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 195us/step - loss: 1.1893 - accuracy: 0.5261 - val_loss: 1.1855 - val_accuracy: 0.4880\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 222us/step - loss: 1.1767 - accuracy: 0.5224 - val_loss: 1.1636 - val_accuracy: 0.4928\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 248us/step - loss: 1.1647 - accuracy: 0.5245 - val_loss: 1.1444 - val_accuracy: 0.5215\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 229us/step - loss: 1.1544 - accuracy: 0.5298 - val_loss: 1.1294 - val_accuracy: 0.5311\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 222us/step - loss: 1.1470 - accuracy: 0.5341 - val_loss: 1.1181 - val_accuracy: 0.5359\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.1299 - accuracy: 0.5335 - val_loss: 1.1096 - val_accuracy: 0.5359\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 1.1195 - accuracy: 0.5298 - val_loss: 1.0995 - val_accuracy: 0.5359\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 173us/step - loss: 1.1112 - accuracy: 0.5304 - val_loss: 1.0865 - val_accuracy: 0.5455\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 171us/step - loss: 1.0922 - accuracy: 0.5564 - val_loss: 1.0741 - val_accuracy: 0.5646\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 176us/step - loss: 1.0919 - accuracy: 0.5634 - val_loss: 1.0583 - val_accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 166us/step - loss: 1.0785 - accuracy: 0.5831 - val_loss: 1.0505 - val_accuracy: 0.6077\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 166us/step - loss: 1.0742 - accuracy: 0.5857 - val_loss: 1.0435 - val_accuracy: 0.6220\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 155us/step - loss: 1.0649 - accuracy: 0.5964 - val_loss: 1.0311 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 145us/step - loss: 1.0542 - accuracy: 0.5884 - val_loss: 1.0284 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 142us/step - loss: 1.0425 - accuracy: 0.6028 - val_loss: 1.0311 - val_accuracy: 0.6364\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 1.0366 - accuracy: 0.6086 - val_loss: 1.0154 - val_accuracy: 0.6651\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 168us/step - loss: 1.0283 - accuracy: 0.6166 - val_loss: 1.0105 - val_accuracy: 0.6555\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 175us/step - loss: 1.0358 - accuracy: 0.6060 - val_loss: 1.0068 - val_accuracy: 0.6411\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 216us/step - loss: 1.0152 - accuracy: 0.6171 - val_loss: 1.0024 - val_accuracy: 0.6699\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 197us/step - loss: 1.0064 - accuracy: 0.6251 - val_loss: 0.9922 - val_accuracy: 0.6651\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 154us/step - loss: 0.9967 - accuracy: 0.6347 - val_loss: 0.9917 - val_accuracy: 0.6794\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 162us/step - loss: 1.0052 - accuracy: 0.6219 - val_loss: 0.9894 - val_accuracy: 0.6603\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 176us/step - loss: 0.9831 - accuracy: 0.6427 - val_loss: 0.9868 - val_accuracy: 0.6459\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 180us/step - loss: 0.9976 - accuracy: 0.6294 - val_loss: 0.9818 - val_accuracy: 0.6603\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 0.9801 - accuracy: 0.6310 - val_loss: 0.9808 - val_accuracy: 0.6699\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 167us/step - loss: 0.9868 - accuracy: 0.6326 - val_loss: 0.9751 - val_accuracy: 0.6603\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 152us/step - loss: 0.9808 - accuracy: 0.6331 - val_loss: 0.9812 - val_accuracy: 0.6411\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 165us/step - loss: 0.9741 - accuracy: 0.6384 - val_loss: 0.9851 - val_accuracy: 0.6268\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 156us/step - loss: 0.9702 - accuracy: 0.6432 - val_loss: 0.9765 - val_accuracy: 0.6411\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 172us/step - loss: 0.9707 - accuracy: 0.6384 - val_loss: 0.9663 - val_accuracy: 0.6364\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 170us/step - loss: 0.9578 - accuracy: 0.6523 - val_loss: 0.9647 - val_accuracy: 0.6459\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 0.9507 - accuracy: 0.6395 - val_loss: 0.9624 - val_accuracy: 0.6603\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 158us/step - loss: 0.9493 - accuracy: 0.6416 - val_loss: 0.9482 - val_accuracy: 0.6459\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 169us/step - loss: 0.9358 - accuracy: 0.6587 - val_loss: 0.9472 - val_accuracy: 0.6555\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 154us/step - loss: 0.9395 - accuracy: 0.6539 - val_loss: 0.9504 - val_accuracy: 0.6555\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 0.9457 - accuracy: 0.6438 - val_loss: 0.9491 - val_accuracy: 0.6794\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 146us/step - loss: 0.9129 - accuracy: 0.6645 - val_loss: 0.9440 - val_accuracy: 0.6555\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 154us/step - loss: 0.9210 - accuracy: 0.6645 - val_loss: 0.9442 - val_accuracy: 0.6699\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 0.9375 - accuracy: 0.6432 - val_loss: 0.9450 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 156us/step - loss: 0.9226 - accuracy: 0.6555 - val_loss: 0.9426 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 55/60 [1:02:15<03:57, 47.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 700us/step - loss: 1.3044 - accuracy: 0.4574 - val_loss: 1.3212 - val_accuracy: 0.4163\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 309us/step - loss: 1.2373 - accuracy: 0.5208 - val_loss: 1.2796 - val_accuracy: 0.4115\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 293us/step - loss: 1.2036 - accuracy: 0.5186 - val_loss: 1.2489 - val_accuracy: 0.4498\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 330us/step - loss: 1.1751 - accuracy: 0.5431 - val_loss: 1.2139 - val_accuracy: 0.4880\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 299us/step - loss: 1.1509 - accuracy: 0.5479 - val_loss: 1.1948 - val_accuracy: 0.4833\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 289us/step - loss: 1.1369 - accuracy: 0.5554 - val_loss: 1.1590 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 1.1150 - accuracy: 0.5703 - val_loss: 1.1425 - val_accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 304us/step - loss: 1.1012 - accuracy: 0.5761 - val_loss: 1.1299 - val_accuracy: 0.5694\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 1.0978 - accuracy: 0.5628 - val_loss: 1.0988 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 295us/step - loss: 1.0715 - accuracy: 0.5911 - val_loss: 1.0825 - val_accuracy: 0.5885\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 385us/step - loss: 1.0581 - accuracy: 0.5937 - val_loss: 1.0646 - val_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 1.0580 - accuracy: 0.5815 - val_loss: 1.0590 - val_accuracy: 0.5981\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 302us/step - loss: 1.0403 - accuracy: 0.5932 - val_loss: 1.0521 - val_accuracy: 0.5742\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: 1.0349 - accuracy: 0.5889 - val_loss: 1.0615 - val_accuracy: 0.5789\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 1.0323 - accuracy: 0.5836 - val_loss: 1.0461 - val_accuracy: 0.5885\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 1.0139 - accuracy: 0.5911 - val_loss: 1.0434 - val_accuracy: 0.5885\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 1.0090 - accuracy: 0.5900 - val_loss: 1.0311 - val_accuracy: 0.5789\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 296us/step - loss: 1.0066 - accuracy: 0.5895 - val_loss: 1.0189 - val_accuracy: 0.6172\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.9848 - accuracy: 0.6390 - val_loss: 1.0112 - val_accuracy: 0.6316\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 308us/step - loss: 0.9780 - accuracy: 0.6400 - val_loss: 1.0071 - val_accuracy: 0.6555\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 310us/step - loss: 0.9827 - accuracy: 0.6390 - val_loss: 0.9997 - val_accuracy: 0.6507\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 279us/step - loss: 0.9650 - accuracy: 0.6305 - val_loss: 1.0204 - val_accuracy: 0.6172\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 291us/step - loss: 0.9576 - accuracy: 0.6358 - val_loss: 1.0076 - val_accuracy: 0.6124\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 0.9491 - accuracy: 0.6496 - val_loss: 0.9927 - val_accuracy: 0.6364\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 310us/step - loss: 0.9315 - accuracy: 0.6592 - val_loss: 0.9759 - val_accuracy: 0.6507\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 284us/step - loss: 0.9429 - accuracy: 0.6544 - val_loss: 0.9799 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 325us/step - loss: 0.9316 - accuracy: 0.6475 - val_loss: 0.9629 - val_accuracy: 0.6507\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 345us/step - loss: 0.9206 - accuracy: 0.6693 - val_loss: 0.9524 - val_accuracy: 0.6459\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 349us/step - loss: 0.9243 - accuracy: 0.6539 - val_loss: 0.9538 - val_accuracy: 0.6459\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 265us/step - loss: 0.9183 - accuracy: 0.6672 - val_loss: 0.9480 - val_accuracy: 0.6507\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 298us/step - loss: 0.8948 - accuracy: 0.6725 - val_loss: 0.9350 - val_accuracy: 0.6651\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 300us/step - loss: 0.8934 - accuracy: 0.6693 - val_loss: 0.9436 - val_accuracy: 0.6699\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 330us/step - loss: 0.8886 - accuracy: 0.6677 - val_loss: 0.9431 - val_accuracy: 0.6603\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 305us/step - loss: 0.8886 - accuracy: 0.6656 - val_loss: 0.9594 - val_accuracy: 0.6555\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.8745 - accuracy: 0.6747 - val_loss: 0.9493 - val_accuracy: 0.6364\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 287us/step - loss: 0.8772 - accuracy: 0.6747 - val_loss: 0.9348 - val_accuracy: 0.6651\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 301us/step - loss: 0.8556 - accuracy: 0.6826 - val_loss: 0.9373 - val_accuracy: 0.6555\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 0.8650 - accuracy: 0.6816 - val_loss: 0.9312 - val_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 294us/step - loss: 0.8671 - accuracy: 0.6672 - val_loss: 0.9230 - val_accuracy: 0.6746\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 293us/step - loss: 0.8496 - accuracy: 0.6853 - val_loss: 0.9251 - val_accuracy: 0.6746\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 0.8467 - accuracy: 0.6842 - val_loss: 0.9164 - val_accuracy: 0.6699\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.8312 - accuracy: 0.6997 - val_loss: 0.9294 - val_accuracy: 0.6603\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 301us/step - loss: 0.8294 - accuracy: 0.6986 - val_loss: 0.9049 - val_accuracy: 0.6890\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 306us/step - loss: 0.8278 - accuracy: 0.6976 - val_loss: 0.9176 - val_accuracy: 0.6651\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 308us/step - loss: 0.8281 - accuracy: 0.6922 - val_loss: 0.9220 - val_accuracy: 0.6603\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 301us/step - loss: 0.8212 - accuracy: 0.6906 - val_loss: 0.9049 - val_accuracy: 0.6746\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 319us/step - loss: 0.8163 - accuracy: 0.6981 - val_loss: 0.9047 - val_accuracy: 0.6699\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 320us/step - loss: 0.8076 - accuracy: 0.6976 - val_loss: 0.9070 - val_accuracy: 0.6699\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 288us/step - loss: 0.8092 - accuracy: 0.6954 - val_loss: 0.8980 - val_accuracy: 0.6699\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 308us/step - loss: 0.7785 - accuracy: 0.7087 - val_loss: 0.9035 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 56/60 [1:02:47<02:50, 42.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.2900 - accuracy: 0.4318 - val_loss: 1.2998 - val_accuracy: 0.5215\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.2102 - accuracy: 0.5367 - val_loss: 1.2318 - val_accuracy: 0.5215\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 983us/step - loss: 1.1715 - accuracy: 0.5612 - val_loss: 1.1860 - val_accuracy: 0.5455\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 891us/step - loss: 1.1635 - accuracy: 0.5703 - val_loss: 1.1626 - val_accuracy: 0.5359\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 2s 977us/step - loss: 1.1388 - accuracy: 0.5847 - val_loss: 1.1541 - val_accuracy: 0.5407\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1416 - accuracy: 0.5596 - val_loss: 1.1161 - val_accuracy: 0.5694\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 2s 917us/step - loss: 1.1171 - accuracy: 0.5831 - val_loss: 1.0930 - val_accuracy: 0.5885\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 2s 970us/step - loss: 1.1085 - accuracy: 0.5921 - val_loss: 1.0992 - val_accuracy: 0.5598\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 993us/step - loss: 1.1041 - accuracy: 0.5974 - val_loss: 1.0642 - val_accuracy: 0.5981\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 2s 916us/step - loss: 1.0837 - accuracy: 0.6070 - val_loss: 1.0771 - val_accuracy: 0.5789\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 908us/step - loss: 1.0664 - accuracy: 0.6033 - val_loss: 1.0425 - val_accuracy: 0.6124\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 875us/step - loss: 1.0705 - accuracy: 0.6049 - val_loss: 1.0639 - val_accuracy: 0.5837\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 2s 843us/step - loss: 1.0569 - accuracy: 0.6038 - val_loss: 1.0798 - val_accuracy: 0.5502\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 845us/step - loss: 1.0585 - accuracy: 0.5932 - val_loss: 1.0377 - val_accuracy: 0.6124\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 2s 851us/step - loss: 1.0584 - accuracy: 0.5937 - val_loss: 1.0021 - val_accuracy: 0.6459\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 2s 890us/step - loss: 1.0400 - accuracy: 0.6273 - val_loss: 0.9498 - val_accuracy: 0.6890\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0268 - accuracy: 0.6113 - val_loss: 0.9913 - val_accuracy: 0.6603\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 904us/step - loss: 1.0242 - accuracy: 0.6198 - val_loss: 0.9672 - val_accuracy: 0.6507\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 933us/step - loss: 1.0093 - accuracy: 0.6262 - val_loss: 0.9973 - val_accuracy: 0.6459\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 882us/step - loss: 1.0156 - accuracy: 0.6150 - val_loss: 0.9863 - val_accuracy: 0.6220\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 928us/step - loss: 0.9984 - accuracy: 0.6235 - val_loss: 0.9767 - val_accuracy: 0.6364\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 948us/step - loss: 1.0062 - accuracy: 0.6134 - val_loss: 1.0306 - val_accuracy: 0.5837\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 932us/step - loss: 0.9856 - accuracy: 0.6454 - val_loss: 0.9489 - val_accuracy: 0.6507\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 838us/step - loss: 0.9853 - accuracy: 0.6368 - val_loss: 0.9658 - val_accuracy: 0.6172\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 2s 870us/step - loss: 0.9658 - accuracy: 0.6486 - val_loss: 0.9506 - val_accuracy: 0.6699\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 2s 901us/step - loss: 0.9742 - accuracy: 0.6390 - val_loss: 0.9809 - val_accuracy: 0.6364\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 2s 865us/step - loss: 0.9604 - accuracy: 0.6416 - val_loss: 0.9731 - val_accuracy: 0.6316\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 2s 832us/step - loss: 0.9498 - accuracy: 0.6443 - val_loss: 1.0344 - val_accuracy: 0.5789\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 2s 865us/step - loss: 0.9563 - accuracy: 0.6400 - val_loss: 0.9853 - val_accuracy: 0.6172\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 2s 990us/step - loss: 0.9551 - accuracy: 0.6363 - val_loss: 0.9496 - val_accuracy: 0.6316\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9295 - accuracy: 0.6539 - val_loss: 0.9519 - val_accuracy: 0.6555\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 2s 975us/step - loss: 0.9435 - accuracy: 0.6475 - val_loss: 0.9481 - val_accuracy: 0.6268\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9259 - accuracy: 0.6491 - val_loss: 0.9637 - val_accuracy: 0.6411\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 939us/step - loss: 0.8919 - accuracy: 0.6821 - val_loss: 0.9250 - val_accuracy: 0.6411\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 858us/step - loss: 0.9183 - accuracy: 0.6555 - val_loss: 0.9397 - val_accuracy: 0.6411\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 972us/step - loss: 0.9040 - accuracy: 0.6571 - val_loss: 0.9715 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9041 - accuracy: 0.6544 - val_loss: 0.9504 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9007 - accuracy: 0.6629 - val_loss: 0.9360 - val_accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8935 - accuracy: 0.6768 - val_loss: 0.9566 - val_accuracy: 0.6364\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8988 - accuracy: 0.6576 - val_loss: 0.9319 - val_accuracy: 0.6316\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.8858 - accuracy: 0.6597 - val_loss: 0.9675 - val_accuracy: 0.6077\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8893 - accuracy: 0.6603 - val_loss: 0.9171 - val_accuracy: 0.6555\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8720 - accuracy: 0.6794 - val_loss: 0.9233 - val_accuracy: 0.6411\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8615 - accuracy: 0.6821 - val_loss: 0.9212 - val_accuracy: 0.6411\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8790 - accuracy: 0.6757 - val_loss: 0.9115 - val_accuracy: 0.6507\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8511 - accuracy: 0.6784 - val_loss: 0.9277 - val_accuracy: 0.6364\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8404 - accuracy: 0.6906 - val_loss: 0.8975 - val_accuracy: 0.6603\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.8522 - accuracy: 0.6869 - val_loss: 0.9031 - val_accuracy: 0.6507\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8356 - accuracy: 0.6954 - val_loss: 0.9009 - val_accuracy: 0.6603\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8391 - accuracy: 0.6848 - val_loss: 0.9236 - val_accuracy: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 57/60 [1:04:26<02:58, 59.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 653us/step - loss: 1.4051 - accuracy: 0.2236 - val_loss: 1.3824 - val_accuracy: 0.2775\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 0s 186us/step - loss: 1.3708 - accuracy: 0.3190 - val_loss: 1.3635 - val_accuracy: 0.2775\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 1.3424 - accuracy: 0.4121 - val_loss: 1.3477 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 0s 184us/step - loss: 1.3196 - accuracy: 0.4531 - val_loss: 1.3326 - val_accuracy: 0.4019\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 0s 193us/step - loss: 1.3006 - accuracy: 0.4420 - val_loss: 1.3150 - val_accuracy: 0.3971\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 0s 179us/step - loss: 1.2837 - accuracy: 0.4446 - val_loss: 1.2950 - val_accuracy: 0.3971\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 0s 194us/step - loss: 1.2619 - accuracy: 0.4601 - val_loss: 1.2726 - val_accuracy: 0.4019\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 0s 187us/step - loss: 1.2427 - accuracy: 0.4723 - val_loss: 1.2497 - val_accuracy: 0.4258\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 0s 218us/step - loss: 1.2259 - accuracy: 0.4878 - val_loss: 1.2286 - val_accuracy: 0.4737\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 0s 211us/step - loss: 1.2082 - accuracy: 0.5000 - val_loss: 1.2111 - val_accuracy: 0.4976\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 0s 191us/step - loss: 1.1935 - accuracy: 0.5128 - val_loss: 1.1984 - val_accuracy: 0.4976\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 0s 235us/step - loss: 1.1813 - accuracy: 0.5128 - val_loss: 1.1844 - val_accuracy: 0.5072\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 0s 261us/step - loss: 1.1661 - accuracy: 0.5208 - val_loss: 1.1727 - val_accuracy: 0.5407\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 0s 216us/step - loss: 1.1503 - accuracy: 0.5421 - val_loss: 1.1596 - val_accuracy: 0.5455\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 0s 220us/step - loss: 1.1409 - accuracy: 0.5394 - val_loss: 1.1460 - val_accuracy: 0.5311\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 0s 226us/step - loss: 1.1297 - accuracy: 0.5490 - val_loss: 1.1334 - val_accuracy: 0.5215\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 0s 258us/step - loss: 1.1267 - accuracy: 0.5517 - val_loss: 1.1210 - val_accuracy: 0.5311\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 0s 210us/step - loss: 1.1169 - accuracy: 0.5554 - val_loss: 1.1137 - val_accuracy: 0.5407\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 0s 214us/step - loss: 1.1005 - accuracy: 0.5735 - val_loss: 1.1142 - val_accuracy: 0.5359\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 0s 223us/step - loss: 1.0864 - accuracy: 0.5751 - val_loss: 1.1136 - val_accuracy: 0.5359\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 0s 157us/step - loss: 1.0921 - accuracy: 0.5655 - val_loss: 1.0943 - val_accuracy: 0.5598\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 0s 151us/step - loss: 1.0841 - accuracy: 0.5745 - val_loss: 1.0968 - val_accuracy: 0.5598\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 0s 174us/step - loss: 1.0790 - accuracy: 0.5708 - val_loss: 1.0917 - val_accuracy: 0.5502\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 0s 174us/step - loss: 1.0793 - accuracy: 0.5602 - val_loss: 1.0881 - val_accuracy: 0.5455\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 0s 175us/step - loss: 1.0698 - accuracy: 0.5729 - val_loss: 1.0790 - val_accuracy: 0.5502\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 0s 155us/step - loss: 1.0630 - accuracy: 0.5719 - val_loss: 1.0721 - val_accuracy: 0.5502\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 0s 156us/step - loss: 1.0553 - accuracy: 0.5793 - val_loss: 1.0680 - val_accuracy: 0.5359\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 1.0510 - accuracy: 0.5788 - val_loss: 1.0658 - val_accuracy: 0.5598\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 0s 149us/step - loss: 1.0555 - accuracy: 0.5793 - val_loss: 1.0604 - val_accuracy: 0.5598\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 1.0418 - accuracy: 0.5863 - val_loss: 1.0613 - val_accuracy: 0.5502\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 0s 154us/step - loss: 1.0440 - accuracy: 0.5841 - val_loss: 1.0549 - val_accuracy: 0.5502\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 1.0274 - accuracy: 0.5932 - val_loss: 1.0511 - val_accuracy: 0.5502\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 0s 150us/step - loss: 1.0365 - accuracy: 0.5804 - val_loss: 1.0481 - val_accuracy: 0.5550\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 0s 154us/step - loss: 1.0327 - accuracy: 0.5745 - val_loss: 1.0448 - val_accuracy: 0.5550\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 0s 157us/step - loss: 1.0281 - accuracy: 0.5911 - val_loss: 1.0405 - val_accuracy: 0.5550\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 0s 152us/step - loss: 1.0233 - accuracy: 0.5916 - val_loss: 1.0438 - val_accuracy: 0.5502\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 1.0300 - accuracy: 0.5825 - val_loss: 1.0400 - val_accuracy: 0.5407\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 1.0189 - accuracy: 0.5884 - val_loss: 1.0364 - val_accuracy: 0.5550\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 0s 156us/step - loss: 1.0055 - accuracy: 0.5927 - val_loss: 1.0354 - val_accuracy: 0.5694\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 0s 152us/step - loss: 0.9993 - accuracy: 0.6118 - val_loss: 1.0284 - val_accuracy: 0.5694\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 0s 155us/step - loss: 0.9832 - accuracy: 0.6161 - val_loss: 1.0263 - val_accuracy: 0.5742\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 0s 142us/step - loss: 0.9957 - accuracy: 0.6092 - val_loss: 1.0270 - val_accuracy: 0.5837\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 0s 138us/step - loss: 0.9908 - accuracy: 0.6129 - val_loss: 1.0252 - val_accuracy: 0.5837\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 1.0031 - accuracy: 0.6113 - val_loss: 1.0182 - val_accuracy: 0.5981\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 0s 155us/step - loss: 0.9970 - accuracy: 0.6124 - val_loss: 1.0177 - val_accuracy: 0.5885\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 0s 153us/step - loss: 0.9762 - accuracy: 0.6241 - val_loss: 1.0091 - val_accuracy: 0.6172\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 0s 143us/step - loss: 0.9841 - accuracy: 0.6193 - val_loss: 1.0061 - val_accuracy: 0.6172\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 0s 147us/step - loss: 0.9697 - accuracy: 0.6262 - val_loss: 1.0012 - val_accuracy: 0.6268\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 0s 149us/step - loss: 0.9722 - accuracy: 0.6171 - val_loss: 0.9962 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 0s 148us/step - loss: 0.9546 - accuracy: 0.6326 - val_loss: 0.9917 - val_accuracy: 0.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 58/60 [1:04:45<01:35, 47.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 1s 708us/step - loss: 1.3190 - accuracy: 0.4159 - val_loss: 1.3326 - val_accuracy: 0.4593\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 1s 286us/step - loss: 1.2389 - accuracy: 0.5000 - val_loss: 1.2838 - val_accuracy: 0.4545\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 1.2029 - accuracy: 0.5218 - val_loss: 1.2374 - val_accuracy: 0.4785\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 1.1782 - accuracy: 0.5240 - val_loss: 1.2064 - val_accuracy: 0.4689\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 1.1510 - accuracy: 0.5288 - val_loss: 1.1746 - val_accuracy: 0.5407\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 1s 281us/step - loss: 1.1395 - accuracy: 0.5309 - val_loss: 1.1556 - val_accuracy: 0.5311\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 1.1156 - accuracy: 0.5522 - val_loss: 1.1311 - val_accuracy: 0.5598\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 1.1145 - accuracy: 0.5447 - val_loss: 1.1073 - val_accuracy: 0.5263\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 1s 282us/step - loss: 1.0930 - accuracy: 0.5767 - val_loss: 1.0917 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 1s 283us/step - loss: 1.0997 - accuracy: 0.5756 - val_loss: 1.0874 - val_accuracy: 0.5694\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 1.0806 - accuracy: 0.5724 - val_loss: 1.0651 - val_accuracy: 0.5550\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 1.0696 - accuracy: 0.5911 - val_loss: 1.0496 - val_accuracy: 0.5694\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 1.0606 - accuracy: 0.5932 - val_loss: 1.0419 - val_accuracy: 0.5694\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 1.0551 - accuracy: 0.5953 - val_loss: 1.0356 - val_accuracy: 0.5885\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 1.0529 - accuracy: 0.5852 - val_loss: 1.0211 - val_accuracy: 0.5981\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: 1.0380 - accuracy: 0.5942 - val_loss: 1.0168 - val_accuracy: 0.5933\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 1s 278us/step - loss: 1.0251 - accuracy: 0.6070 - val_loss: 1.0206 - val_accuracy: 0.5885\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 1.0229 - accuracy: 0.6070 - val_loss: 1.0098 - val_accuracy: 0.5933\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 1.0041 - accuracy: 0.6044 - val_loss: 0.9929 - val_accuracy: 0.6077\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: 1.0006 - accuracy: 0.6145 - val_loss: 0.9924 - val_accuracy: 0.6268\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 1.0182 - accuracy: 0.6092 - val_loss: 0.9711 - val_accuracy: 0.6029\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 1s 270us/step - loss: 0.9965 - accuracy: 0.6124 - val_loss: 0.9860 - val_accuracy: 0.6124\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.9730 - accuracy: 0.6289 - val_loss: 0.9696 - val_accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.9864 - accuracy: 0.6150 - val_loss: 0.9665 - val_accuracy: 0.6268\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 0.9832 - accuracy: 0.6171 - val_loss: 0.9496 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.9584 - accuracy: 0.6390 - val_loss: 0.9440 - val_accuracy: 0.6411\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 1s 281us/step - loss: 0.9521 - accuracy: 0.6363 - val_loss: 0.9591 - val_accuracy: 0.6459\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.9561 - accuracy: 0.6299 - val_loss: 0.9498 - val_accuracy: 0.6364\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 1s 279us/step - loss: 0.9541 - accuracy: 0.6374 - val_loss: 0.9303 - val_accuracy: 0.6411\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.9377 - accuracy: 0.6528 - val_loss: 0.9269 - val_accuracy: 0.6316\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.9338 - accuracy: 0.6464 - val_loss: 0.9269 - val_accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.9392 - accuracy: 0.6411 - val_loss: 0.9361 - val_accuracy: 0.6124\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.9292 - accuracy: 0.6470 - val_loss: 0.9065 - val_accuracy: 0.6411\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 1s 297us/step - loss: 0.9130 - accuracy: 0.6534 - val_loss: 0.9060 - val_accuracy: 0.6411\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 1s 280us/step - loss: 0.9169 - accuracy: 0.6368 - val_loss: 0.9214 - val_accuracy: 0.6316\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 1s 275us/step - loss: 0.9000 - accuracy: 0.6592 - val_loss: 0.9189 - val_accuracy: 0.6268\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.9153 - accuracy: 0.6400 - val_loss: 0.8908 - val_accuracy: 0.6459\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.8873 - accuracy: 0.6720 - val_loss: 0.9072 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.9060 - accuracy: 0.6512 - val_loss: 0.8865 - val_accuracy: 0.6555\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.9026 - accuracy: 0.6571 - val_loss: 0.9073 - val_accuracy: 0.6651\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.8933 - accuracy: 0.6565 - val_loss: 0.8850 - val_accuracy: 0.6507\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 0.8835 - accuracy: 0.6518 - val_loss: 0.8816 - val_accuracy: 0.6459\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.8823 - accuracy: 0.6693 - val_loss: 0.8871 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 1s 271us/step - loss: 0.8879 - accuracy: 0.6592 - val_loss: 0.8893 - val_accuracy: 0.6411\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 1s 269us/step - loss: 0.8599 - accuracy: 0.6778 - val_loss: 0.8916 - val_accuracy: 0.6507\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 1s 273us/step - loss: 0.8738 - accuracy: 0.6539 - val_loss: 0.8979 - val_accuracy: 0.6268\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 1s 272us/step - loss: 0.8666 - accuracy: 0.6736 - val_loss: 0.8824 - val_accuracy: 0.6364\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 1s 277us/step - loss: 0.8315 - accuracy: 0.6826 - val_loss: 0.8817 - val_accuracy: 0.6603\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 276us/step - loss: 0.8384 - accuracy: 0.6794 - val_loss: 0.8862 - val_accuracy: 0.6220\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 1s 268us/step - loss: 0.8300 - accuracy: 0.6890 - val_loss: 0.8753 - val_accuracy: 0.6268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [1:05:14<00:41, 41.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1878 samples, validate on 209 samples\n",
      "Epoch 1/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.2498 - accuracy: 0.4569 - val_loss: 1.2881 - val_accuracy: 0.3971\n",
      "Epoch 2/50\n",
      "1878/1878 [==============================] - 2s 984us/step - loss: 1.1837 - accuracy: 0.5208 - val_loss: 1.2379 - val_accuracy: 0.4115\n",
      "Epoch 3/50\n",
      "1878/1878 [==============================] - 2s 933us/step - loss: 1.1834 - accuracy: 0.5250 - val_loss: 1.2082 - val_accuracy: 0.5167\n",
      "Epoch 4/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1618 - accuracy: 0.5399 - val_loss: 1.1726 - val_accuracy: 0.5455\n",
      "Epoch 5/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1501 - accuracy: 0.5559 - val_loss: 1.1413 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1438 - accuracy: 0.5607 - val_loss: 1.1419 - val_accuracy: 0.5885\n",
      "Epoch 7/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1419 - accuracy: 0.5538 - val_loss: 1.1452 - val_accuracy: 0.5550\n",
      "Epoch 8/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.1267 - accuracy: 0.5714 - val_loss: 1.1304 - val_accuracy: 0.5646\n",
      "Epoch 9/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.1049 - accuracy: 0.5852 - val_loss: 1.1164 - val_accuracy: 0.5885\n",
      "Epoch 10/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0958 - accuracy: 0.5895 - val_loss: 1.1023 - val_accuracy: 0.5837\n",
      "Epoch 11/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0909 - accuracy: 0.5852 - val_loss: 1.1186 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "1878/1878 [==============================] - 2s 967us/step - loss: 1.0893 - accuracy: 0.5916 - val_loss: 1.0849 - val_accuracy: 0.5933\n",
      "Epoch 13/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0781 - accuracy: 0.5974 - val_loss: 1.0606 - val_accuracy: 0.6268\n",
      "Epoch 14/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0678 - accuracy: 0.5948 - val_loss: 1.0397 - val_accuracy: 0.6459\n",
      "Epoch 15/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0727 - accuracy: 0.5911 - val_loss: 1.0161 - val_accuracy: 0.6507\n",
      "Epoch 16/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0708 - accuracy: 0.5868 - val_loss: 1.0445 - val_accuracy: 0.6220\n",
      "Epoch 17/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 1.0551 - accuracy: 0.6028 - val_loss: 1.0439 - val_accuracy: 0.6029\n",
      "Epoch 18/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0558 - accuracy: 0.5990 - val_loss: 1.0581 - val_accuracy: 0.6077\n",
      "Epoch 19/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0531 - accuracy: 0.5969 - val_loss: 1.0163 - val_accuracy: 0.6220\n",
      "Epoch 20/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0284 - accuracy: 0.6198 - val_loss: 0.9977 - val_accuracy: 0.6268\n",
      "Epoch 21/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0363 - accuracy: 0.6209 - val_loss: 1.0199 - val_accuracy: 0.6172\n",
      "Epoch 22/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0332 - accuracy: 0.6134 - val_loss: 1.0140 - val_accuracy: 0.6077\n",
      "Epoch 23/50\n",
      "1878/1878 [==============================] - 2s 976us/step - loss: 1.0099 - accuracy: 0.6230 - val_loss: 1.0058 - val_accuracy: 0.6268\n",
      "Epoch 24/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 1.0081 - accuracy: 0.6273 - val_loss: 0.9769 - val_accuracy: 0.6603\n",
      "Epoch 25/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0033 - accuracy: 0.6203 - val_loss: 1.0007 - val_accuracy: 0.6507\n",
      "Epoch 26/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 1.0130 - accuracy: 0.6193 - val_loss: 0.9941 - val_accuracy: 0.6268\n",
      "Epoch 27/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9988 - accuracy: 0.6278 - val_loss: 1.0191 - val_accuracy: 0.6124\n",
      "Epoch 28/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9828 - accuracy: 0.6374 - val_loss: 1.0117 - val_accuracy: 0.6124\n",
      "Epoch 29/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9774 - accuracy: 0.6358 - val_loss: 0.9861 - val_accuracy: 0.6364\n",
      "Epoch 30/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9817 - accuracy: 0.6368 - val_loss: 1.0072 - val_accuracy: 0.5981\n",
      "Epoch 31/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9983 - accuracy: 0.6209 - val_loss: 0.9773 - val_accuracy: 0.6172\n",
      "Epoch 32/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9682 - accuracy: 0.6390 - val_loss: 0.9403 - val_accuracy: 0.6794\n",
      "Epoch 33/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9676 - accuracy: 0.6358 - val_loss: 0.9440 - val_accuracy: 0.6555\n",
      "Epoch 34/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9669 - accuracy: 0.6411 - val_loss: 0.9577 - val_accuracy: 0.6459\n",
      "Epoch 35/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9635 - accuracy: 0.6374 - val_loss: 0.9472 - val_accuracy: 0.6364\n",
      "Epoch 36/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9586 - accuracy: 0.6400 - val_loss: 0.9562 - val_accuracy: 0.6411\n",
      "Epoch 37/50\n",
      "1878/1878 [==============================] - 3s 1ms/step - loss: 0.9436 - accuracy: 0.6565 - val_loss: 0.9415 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "1878/1878 [==============================] - 2s 949us/step - loss: 0.9376 - accuracy: 0.6459 - val_loss: 0.9514 - val_accuracy: 0.6124\n",
      "Epoch 39/50\n",
      "1878/1878 [==============================] - 2s 898us/step - loss: 0.9448 - accuracy: 0.6427 - val_loss: 0.9254 - val_accuracy: 0.6316\n",
      "Epoch 40/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9441 - accuracy: 0.6374 - val_loss: 0.9359 - val_accuracy: 0.6459\n",
      "Epoch 41/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9281 - accuracy: 0.6523 - val_loss: 0.9509 - val_accuracy: 0.6316\n",
      "Epoch 42/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9160 - accuracy: 0.6576 - val_loss: 0.9524 - val_accuracy: 0.6316\n",
      "Epoch 43/50\n",
      "1878/1878 [==============================] - 3s 2ms/step - loss: 0.9167 - accuracy: 0.6581 - val_loss: 0.9245 - val_accuracy: 0.6507\n",
      "Epoch 44/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9326 - accuracy: 0.6368 - val_loss: 0.9249 - val_accuracy: 0.6411\n",
      "Epoch 45/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9230 - accuracy: 0.6534 - val_loss: 0.8812 - val_accuracy: 0.6651\n",
      "Epoch 46/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.9036 - accuracy: 0.6613 - val_loss: 0.9415 - val_accuracy: 0.6364\n",
      "Epoch 47/50\n",
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.8901 - accuracy: 0.6629 - val_loss: 0.9226 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "1878/1878 [==============================] - 2s 823us/step - loss: 0.8925 - accuracy: 0.6619 - val_loss: 0.9107 - val_accuracy: 0.6364\n",
      "Epoch 49/50\n",
      "1878/1878 [==============================] - 1s 786us/step - loss: 0.8998 - accuracy: 0.6560 - val_loss: 0.9488 - val_accuracy: 0.6124\n",
      "Epoch 50/50\n",
      "1878/1878 [==============================] - 2s 805us/step - loss: 0.8847 - accuracy: 0.6741 - val_loss: 0.8934 - val_accuracy: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [1:07:13<00:00, 67.22s/it]\n"
     ]
    }
   ],
   "source": [
    "import talos as ta\n",
    "\n",
    "# run the experiment\n",
    "t = ta.Scan(x=x_train,\n",
    "            y=y_train,\n",
    "            model=lstm_model,\n",
    "            params=p,\n",
    "            experiment_name='aspect_prediction_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>hidden_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.962262</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.588671</td>\n",
       "      <td>0.796060</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.925489</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.503031</td>\n",
       "      <td>0.808307</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.967911</td>\n",
       "      <td>0.617225</td>\n",
       "      <td>0.516600</td>\n",
       "      <td>0.797125</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.881225</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.595236</td>\n",
       "      <td>0.780085</td>\n",
       "      <td>32</td>\n",
       "      <td>0.04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.933471</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.519294</td>\n",
       "      <td>0.810969</td>\n",
       "      <td>32</td>\n",
       "      <td>0.04</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.924105</td>\n",
       "      <td>0.679426</td>\n",
       "      <td>0.532716</td>\n",
       "      <td>0.796592</td>\n",
       "      <td>32</td>\n",
       "      <td>0.04</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.896195</td>\n",
       "      <td>0.688995</td>\n",
       "      <td>0.686205</td>\n",
       "      <td>0.735889</td>\n",
       "      <td>32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.546184</td>\n",
       "      <td>0.796060</td>\n",
       "      <td>32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.582657</td>\n",
       "      <td>0.786475</td>\n",
       "      <td>32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.861404</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.720294</td>\n",
       "      <td>0.735889</td>\n",
       "      <td>32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.932369</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.553135</td>\n",
       "      <td>0.803514</td>\n",
       "      <td>32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0.877363</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.583689</td>\n",
       "      <td>0.790735</td>\n",
       "      <td>32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>0.890170</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.766625</td>\n",
       "      <td>0.711928</td>\n",
       "      <td>32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.852305</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.615393</td>\n",
       "      <td>0.765176</td>\n",
       "      <td>32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0.873650</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.636846</td>\n",
       "      <td>0.762513</td>\n",
       "      <td>32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>0.835396</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.773003</td>\n",
       "      <td>0.703940</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>0.838020</td>\n",
       "      <td>0.679426</td>\n",
       "      <td>0.617255</td>\n",
       "      <td>0.766241</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>0.802707</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.663950</td>\n",
       "      <td>0.743876</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>0.907733</td>\n",
       "      <td>0.650718</td>\n",
       "      <td>0.850856</td>\n",
       "      <td>0.673589</td>\n",
       "      <td>32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850228</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.666154</td>\n",
       "      <td>0.755059</td>\n",
       "      <td>32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.715433</td>\n",
       "      <td>0.723110</td>\n",
       "      <td>32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>0.910337</td>\n",
       "      <td>0.626794</td>\n",
       "      <td>0.891217</td>\n",
       "      <td>0.655485</td>\n",
       "      <td>32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>0.869057</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.753807</td>\n",
       "      <td>0.715655</td>\n",
       "      <td>32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>0.873045</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.741086</td>\n",
       "      <td>0.726837</td>\n",
       "      <td>32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>0.913090</td>\n",
       "      <td>0.612440</td>\n",
       "      <td>0.891520</td>\n",
       "      <td>0.653355</td>\n",
       "      <td>32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0.861124</td>\n",
       "      <td>0.650718</td>\n",
       "      <td>0.777096</td>\n",
       "      <td>0.707135</td>\n",
       "      <td>32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>0.815953</td>\n",
       "      <td>0.679426</td>\n",
       "      <td>0.776046</td>\n",
       "      <td>0.702343</td>\n",
       "      <td>32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>0.948689</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.937094</td>\n",
       "      <td>0.640043</td>\n",
       "      <td>32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865182</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.801056</td>\n",
       "      <td>0.685836</td>\n",
       "      <td>32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>0.909574</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.821060</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.895546</td>\n",
       "      <td>0.650718</td>\n",
       "      <td>0.636430</td>\n",
       "      <td>0.790202</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>0.921209</td>\n",
       "      <td>0.650718</td>\n",
       "      <td>0.556373</td>\n",
       "      <td>0.806709</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>0.947738</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.616252</td>\n",
       "      <td>0.799255</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>0.931798</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.690369</td>\n",
       "      <td>0.761448</td>\n",
       "      <td>64</td>\n",
       "      <td>0.04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>0.922218</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.586696</td>\n",
       "      <td>0.811502</td>\n",
       "      <td>64</td>\n",
       "      <td>0.04</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>0.996082</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.589143</td>\n",
       "      <td>0.799255</td>\n",
       "      <td>64</td>\n",
       "      <td>0.04</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.755894</td>\n",
       "      <td>0.732162</td>\n",
       "      <td>64</td>\n",
       "      <td>0.08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>0.944484</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.580217</td>\n",
       "      <td>0.799787</td>\n",
       "      <td>64</td>\n",
       "      <td>0.08</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>0.943063</td>\n",
       "      <td>0.622010</td>\n",
       "      <td>0.636291</td>\n",
       "      <td>0.774228</td>\n",
       "      <td>64</td>\n",
       "      <td>0.08</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>0.859502</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.762518</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>0.876219</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.609732</td>\n",
       "      <td>0.777423</td>\n",
       "      <td>64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>0.846990</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.653253</td>\n",
       "      <td>0.777423</td>\n",
       "      <td>64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.890882</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.784591</td>\n",
       "      <td>0.717785</td>\n",
       "      <td>64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>0.872135</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.668825</td>\n",
       "      <td>0.753994</td>\n",
       "      <td>64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>0.864548</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.695026</td>\n",
       "      <td>0.756124</td>\n",
       "      <td>64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>1.065941</td>\n",
       "      <td>0.559809</td>\n",
       "      <td>0.921515</td>\n",
       "      <td>0.630990</td>\n",
       "      <td>64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892440</td>\n",
       "      <td>0.688995</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.743876</td>\n",
       "      <td>64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>0.882618</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.717061</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>0.891130</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.837439</td>\n",
       "      <td>0.699681</td>\n",
       "      <td>64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>0.896857</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.785566</td>\n",
       "      <td>0.711928</td>\n",
       "      <td>64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.915357</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.784397</td>\n",
       "      <td>0.732162</td>\n",
       "      <td>64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>0.991358</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>0.922161</td>\n",
       "      <td>0.628328</td>\n",
       "      <td>64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>0.877031</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>0.724707</td>\n",
       "      <td>64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>0.890498</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.801859</td>\n",
       "      <td>0.702875</td>\n",
       "      <td>64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>0.942604</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.922623</td>\n",
       "      <td>0.655485</td>\n",
       "      <td>64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>0.903482</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.778497</td>\n",
       "      <td>0.708733</td>\n",
       "      <td>64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>0.923561</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.839112</td>\n",
       "      <td>0.684771</td>\n",
       "      <td>64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.622010</td>\n",
       "      <td>0.954582</td>\n",
       "      <td>0.632588</td>\n",
       "      <td>64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>0.875261</td>\n",
       "      <td>0.626794</td>\n",
       "      <td>0.830038</td>\n",
       "      <td>0.689031</td>\n",
       "      <td>64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>0.893436</td>\n",
       "      <td>0.650718</td>\n",
       "      <td>0.884749</td>\n",
       "      <td>0.674121</td>\n",
       "      <td>64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs  val_loss  val_accuracy      loss  accuracy  batch_size  \\\n",
       "0             50  0.962262      0.631579  0.588671  0.796060          32   \n",
       "1             50  0.925489      0.665072  0.503031  0.808307          32   \n",
       "2             50  0.967911      0.617225  0.516600  0.797125          32   \n",
       "3             50  0.881225      0.645933  0.595236  0.780085          32   \n",
       "4             50  0.933471      0.636364  0.519294  0.810969          32   \n",
       "5             50  0.924105      0.679426  0.532716  0.796592          32   \n",
       "6             50  0.896195      0.688995  0.686205  0.735889          32   \n",
       "7             50  0.962804      0.645933  0.546184  0.796060          32   \n",
       "8             50  0.941400      0.641148  0.582657  0.786475          32   \n",
       "9             50  0.861404      0.684211  0.720294  0.735889          32   \n",
       "10            50  0.932369      0.641148  0.553135  0.803514          32   \n",
       "11            50  0.877363      0.674641  0.583689  0.790735          32   \n",
       "12            50  0.890170      0.655502  0.766625  0.711928          32   \n",
       "13            50  0.852305      0.655502  0.615393  0.765176          32   \n",
       "14            50  0.873650      0.655502  0.636846  0.762513          32   \n",
       "15            50  0.835396      0.645933  0.773003  0.703940          32   \n",
       "16            50  0.838020      0.679426  0.617255  0.766241          32   \n",
       "17            50  0.802707      0.655502  0.663950  0.743876          32   \n",
       "18            50  0.907733      0.650718  0.850856  0.673589          32   \n",
       "19            50  0.850228      0.655502  0.666154  0.755059          32   \n",
       "20            50  0.898063      0.636364  0.715433  0.723110          32   \n",
       "21            50  0.910337      0.626794  0.891217  0.655485          32   \n",
       "22            50  0.869057      0.665072  0.753807  0.715655          32   \n",
       "23            50  0.873045      0.641148  0.741086  0.726837          32   \n",
       "24            50  0.913090      0.612440  0.891520  0.653355          32   \n",
       "25            50  0.861124      0.650718  0.777096  0.707135          32   \n",
       "26            50  0.815953      0.679426  0.776046  0.702343          32   \n",
       "27            50  0.948689      0.645933  0.937094  0.640043          32   \n",
       "28            50  0.865182      0.655502  0.801056  0.685836          32   \n",
       "29            50  0.909574      0.660287  0.821060  0.696486          32   \n",
       "30            50  0.895546      0.650718  0.636430  0.790202          64   \n",
       "31            50  0.921209      0.650718  0.556373  0.806709          64   \n",
       "32            50  0.947738      0.660287  0.616252  0.799255          64   \n",
       "33            50  0.931798      0.636364  0.690369  0.761448          64   \n",
       "34            50  0.922218      0.641148  0.586696  0.811502          64   \n",
       "35            50  0.996082      0.641148  0.589143  0.799255          64   \n",
       "36            50  0.897698      0.645933  0.755894  0.732162          64   \n",
       "37            50  0.944484      0.674641  0.580217  0.799787          64   \n",
       "38            50  0.943063      0.622010  0.636291  0.774228          64   \n",
       "39            50  0.859502      0.684211  0.762518  0.733227          64   \n",
       "40            50  0.876219      0.655502  0.609732  0.777423          64   \n",
       "41            50  0.846990      0.674641  0.653253  0.777423          64   \n",
       "42            50  0.890882      0.674641  0.784591  0.717785          64   \n",
       "43            50  0.872135      0.655502  0.668825  0.753994          64   \n",
       "44            50  0.864548      0.660287  0.695026  0.756124          64   \n",
       "45            50  1.065941      0.559809  0.921515  0.630990          64   \n",
       "46            50  0.892440      0.688995  0.723881  0.743876          64   \n",
       "47            50  0.882618      0.641148  0.717061  0.733227          64   \n",
       "48            50  0.891130      0.660287  0.837439  0.699681          64   \n",
       "49            50  0.896857      0.660287  0.785566  0.711928          64   \n",
       "50            50  0.915357      0.665072  0.784397  0.732162          64   \n",
       "51            50  0.991358      0.583732  0.922161  0.628328          64   \n",
       "52            50  0.877031      0.645933  0.748569  0.724707          64   \n",
       "53            50  0.890498      0.665072  0.801859  0.702875          64   \n",
       "54            50  0.942604      0.655502  0.922623  0.655485          64   \n",
       "55            50  0.903482      0.660287  0.778497  0.708733          64   \n",
       "56            50  0.923561      0.655502  0.839112  0.684771          64   \n",
       "57            50  0.991667      0.622010  0.954582  0.632588          64   \n",
       "58            50  0.875261      0.626794  0.830038  0.689031          64   \n",
       "59            50  0.893436      0.650718  0.884749  0.674121          64   \n",
       "\n",
       "    dropout  hidden_units  \n",
       "0      0.00            10  \n",
       "1      0.00           100  \n",
       "2      0.00           300  \n",
       "3      0.04            10  \n",
       "4      0.04           100  \n",
       "5      0.04           300  \n",
       "6      0.08            10  \n",
       "7      0.08           100  \n",
       "8      0.08           300  \n",
       "9      0.12            10  \n",
       "10     0.12           100  \n",
       "11     0.12           300  \n",
       "12     0.16            10  \n",
       "13     0.16           100  \n",
       "14     0.16           300  \n",
       "15     0.20            10  \n",
       "16     0.20           100  \n",
       "17     0.20           300  \n",
       "18     0.24            10  \n",
       "19     0.24           100  \n",
       "20     0.24           300  \n",
       "21     0.28            10  \n",
       "22     0.28           100  \n",
       "23     0.28           300  \n",
       "24     0.32            10  \n",
       "25     0.32           100  \n",
       "26     0.32           300  \n",
       "27     0.36            10  \n",
       "28     0.36           100  \n",
       "29     0.36           300  \n",
       "30     0.00            10  \n",
       "31     0.00           100  \n",
       "32     0.00           300  \n",
       "33     0.04            10  \n",
       "34     0.04           100  \n",
       "35     0.04           300  \n",
       "36     0.08            10  \n",
       "37     0.08           100  \n",
       "38     0.08           300  \n",
       "39     0.12            10  \n",
       "40     0.12           100  \n",
       "41     0.12           300  \n",
       "42     0.16            10  \n",
       "43     0.16           100  \n",
       "44     0.16           300  \n",
       "45     0.20            10  \n",
       "46     0.20           100  \n",
       "47     0.20           300  \n",
       "48     0.24            10  \n",
       "49     0.24           100  \n",
       "50     0.24           300  \n",
       "51     0.28            10  \n",
       "52     0.28           100  \n",
       "53     0.28           300  \n",
       "54     0.32            10  \n",
       "55     0.32           100  \n",
       "56     0.32           300  \n",
       "57     0.36            10  \n",
       "58     0.36           100  \n",
       "59     0.36           300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a report on the scan\n",
    "r = ta.Reporting(t)\n",
    "# Show the models\n",
    "display(r.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy vs Batch Size')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# read from the csv file that stores all the experiment result \n",
    "# Talos will automatically save it when Scan is called\n",
    "\n",
    "onlyfiles = glob.glob(os.getcwd() + '/aspect_prediction_1/*')\n",
    "latest_file = max(onlyfiles, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file)\n",
    "\n",
    "# draw a boxplot of accuracy vs batch size\n",
    "metric = 'batch_size'\n",
    "ax = sns.boxplot(x=metric, y=\"val_accuracy\", data=df.reset_index())\n",
    "ax.set_title('Accuracy vs Batch Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy vs Dropout Rate')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw a boxplot of accuracy vs dropout rate\n",
    "\n",
    "metric = 'dropout'\n",
    "ax = sns.boxplot(x=metric, y=\"val_accuracy\", data=df.reset_index())\n",
    "ax.set_title('Accuracy vs Dropout Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy vs LSTM hidden units')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw a boxplot of accuracy vs number of hidden units\n",
    "\n",
    "metric = 'hidden_units'\n",
    "ax = sns.boxplot(x=metric, y=\"val_accuracy\", data=df.reset_index())\n",
    "ax.set_title('Accuracy vs LSTM hidden units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy vs dropout/ LSTM hidden units')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw a heatmap of accuracy vs dropout / number of hidden units\n",
    "\n",
    "df_grid = df.reset_index().groupby([\"dropout\", \"hidden_units\"]).val_accuracy.mean().unstack()\n",
    "ax = sns.heatmap(data=df_grid, cmap= (sns.diverging_palette(10, 220, sep=80, n=7)), annot=True)\n",
    "ax.set_title('Accuracy vs dropout/ LSTM hidden units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2683 samples, validate on 299 samples\n",
      "Epoch 1/50\n",
      "2683/2683 [==============================] - 1s 375us/step - loss: 1.3674 - accuracy: 0.3392 - val_loss: 1.3270 - val_accuracy: 0.4849\n",
      "Epoch 2/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.3157 - accuracy: 0.4428 - val_loss: 1.2888 - val_accuracy: 0.4916\n",
      "Epoch 3/50\n",
      "2683/2683 [==============================] - 0s 97us/step - loss: 1.2715 - accuracy: 0.4711 - val_loss: 1.2462 - val_accuracy: 0.5050\n",
      "Epoch 4/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.2413 - accuracy: 0.4853 - val_loss: 1.2073 - val_accuracy: 0.5318\n",
      "Epoch 5/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.2184 - accuracy: 0.4987 - val_loss: 1.1750 - val_accuracy: 0.5485\n",
      "Epoch 6/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.1961 - accuracy: 0.5002 - val_loss: 1.1549 - val_accuracy: 0.5652\n",
      "Epoch 7/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 1.1805 - accuracy: 0.5080 - val_loss: 1.1470 - val_accuracy: 0.5719\n",
      "Epoch 8/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 1.1741 - accuracy: 0.5095 - val_loss: 1.1296 - val_accuracy: 0.5719\n",
      "Epoch 9/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.1583 - accuracy: 0.5151 - val_loss: 1.1192 - val_accuracy: 0.5686\n",
      "Epoch 10/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.1445 - accuracy: 0.5199 - val_loss: 1.1167 - val_accuracy: 0.5719\n",
      "Epoch 11/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.1384 - accuracy: 0.5229 - val_loss: 1.1117 - val_accuracy: 0.5719\n",
      "Epoch 12/50\n",
      "2683/2683 [==============================] - 0s 100us/step - loss: 1.1275 - accuracy: 0.5233 - val_loss: 1.1074 - val_accuracy: 0.5652\n",
      "Epoch 13/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.1211 - accuracy: 0.5270 - val_loss: 1.1010 - val_accuracy: 0.5585\n",
      "Epoch 14/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.1186 - accuracy: 0.5296 - val_loss: 1.1044 - val_accuracy: 0.5753\n",
      "Epoch 15/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 1.1014 - accuracy: 0.5419 - val_loss: 1.1071 - val_accuracy: 0.5619\n",
      "Epoch 16/50\n",
      "2683/2683 [==============================] - 0s 101us/step - loss: 1.0953 - accuracy: 0.5498 - val_loss: 1.1030 - val_accuracy: 0.5485\n",
      "Epoch 17/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0874 - accuracy: 0.5591 - val_loss: 1.1037 - val_accuracy: 0.5552\n",
      "Epoch 18/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 1.0758 - accuracy: 0.5598 - val_loss: 1.0937 - val_accuracy: 0.5585\n",
      "Epoch 19/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0782 - accuracy: 0.5561 - val_loss: 1.0938 - val_accuracy: 0.5552\n",
      "Epoch 20/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0628 - accuracy: 0.5606 - val_loss: 1.0877 - val_accuracy: 0.5518\n",
      "Epoch 21/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0506 - accuracy: 0.5736 - val_loss: 1.0823 - val_accuracy: 0.5518\n",
      "Epoch 22/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 1.0467 - accuracy: 0.5803 - val_loss: 1.0938 - val_accuracy: 0.5518\n",
      "Epoch 23/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0432 - accuracy: 0.5773 - val_loss: 1.0828 - val_accuracy: 0.5518\n",
      "Epoch 24/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0414 - accuracy: 0.5785 - val_loss: 1.0846 - val_accuracy: 0.5518\n",
      "Epoch 25/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0286 - accuracy: 0.5848 - val_loss: 1.0829 - val_accuracy: 0.5518\n",
      "Epoch 26/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 1.0255 - accuracy: 0.5807 - val_loss: 1.0756 - val_accuracy: 0.5452\n",
      "Epoch 27/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0380 - accuracy: 0.5684 - val_loss: 1.0726 - val_accuracy: 0.5585\n",
      "Epoch 28/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0220 - accuracy: 0.5826 - val_loss: 1.0674 - val_accuracy: 0.5585\n",
      "Epoch 29/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 1.0131 - accuracy: 0.5900 - val_loss: 1.0716 - val_accuracy: 0.5686\n",
      "Epoch 30/50\n",
      "2683/2683 [==============================] - 0s 100us/step - loss: 1.0124 - accuracy: 0.5732 - val_loss: 1.0722 - val_accuracy: 0.5686\n",
      "Epoch 31/50\n",
      "2683/2683 [==============================] - 0s 100us/step - loss: 0.9952 - accuracy: 0.5963 - val_loss: 1.0631 - val_accuracy: 0.5686\n",
      "Epoch 32/50\n",
      "2683/2683 [==============================] - 0s 110us/step - loss: 0.9922 - accuracy: 0.5963 - val_loss: 1.0643 - val_accuracy: 0.5518\n",
      "Epoch 33/50\n",
      "2683/2683 [==============================] - 0s 111us/step - loss: 0.9909 - accuracy: 0.6019 - val_loss: 1.0588 - val_accuracy: 0.5552\n",
      "Epoch 34/50\n",
      "2683/2683 [==============================] - 0s 105us/step - loss: 0.9843 - accuracy: 0.6031 - val_loss: 1.0545 - val_accuracy: 0.5552\n",
      "Epoch 35/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 0.9809 - accuracy: 0.6142 - val_loss: 1.0508 - val_accuracy: 0.5786\n",
      "Epoch 36/50\n",
      "2683/2683 [==============================] - 0s 97us/step - loss: 0.9848 - accuracy: 0.6165 - val_loss: 1.0493 - val_accuracy: 0.5686\n",
      "Epoch 37/50\n",
      "2683/2683 [==============================] - 0s 102us/step - loss: 0.9618 - accuracy: 0.6165 - val_loss: 1.0601 - val_accuracy: 0.5819\n",
      "Epoch 38/50\n",
      "2683/2683 [==============================] - 0s 101us/step - loss: 0.9825 - accuracy: 0.6068 - val_loss: 1.0533 - val_accuracy: 0.5819\n",
      "Epoch 39/50\n",
      "2683/2683 [==============================] - 0s 108us/step - loss: 0.9665 - accuracy: 0.6168 - val_loss: 1.0486 - val_accuracy: 0.5753\n",
      "Epoch 40/50\n",
      "2683/2683 [==============================] - 0s 119us/step - loss: 0.9582 - accuracy: 0.6340 - val_loss: 1.0478 - val_accuracy: 0.5819\n",
      "Epoch 41/50\n",
      "2683/2683 [==============================] - 0s 100us/step - loss: 0.9470 - accuracy: 0.6172 - val_loss: 1.0384 - val_accuracy: 0.5953\n",
      "Epoch 42/50\n",
      "2683/2683 [==============================] - 0s 107us/step - loss: 0.9493 - accuracy: 0.6403 - val_loss: 1.0338 - val_accuracy: 0.5987\n",
      "Epoch 43/50\n",
      "2683/2683 [==============================] - 0s 102us/step - loss: 0.9543 - accuracy: 0.6247 - val_loss: 1.0286 - val_accuracy: 0.5920\n",
      "Epoch 44/50\n",
      "2683/2683 [==============================] - 0s 114us/step - loss: 0.9468 - accuracy: 0.6291 - val_loss: 1.0233 - val_accuracy: 0.5853\n",
      "Epoch 45/50\n",
      "2683/2683 [==============================] - 0s 112us/step - loss: 0.9485 - accuracy: 0.6277 - val_loss: 1.0163 - val_accuracy: 0.5953\n",
      "Epoch 46/50\n",
      "2683/2683 [==============================] - 0s 106us/step - loss: 0.9314 - accuracy: 0.6355 - val_loss: 1.0197 - val_accuracy: 0.5886\n",
      "Epoch 47/50\n",
      "2683/2683 [==============================] - 0s 111us/step - loss: 0.9300 - accuracy: 0.6385 - val_loss: 1.0176 - val_accuracy: 0.5920\n",
      "Epoch 48/50\n",
      "2683/2683 [==============================] - 0s 100us/step - loss: 0.9315 - accuracy: 0.6400 - val_loss: 1.0040 - val_accuracy: 0.5987\n",
      "Epoch 49/50\n",
      "2683/2683 [==============================] - 0s 99us/step - loss: 0.9322 - accuracy: 0.6321 - val_loss: 1.0105 - val_accuracy: 0.5953\n",
      "Epoch 50/50\n",
      "2683/2683 [==============================] - 0s 98us/step - loss: 0.9213 - accuracy: 0.6370 - val_loss: 1.0017 - val_accuracy: 0.5987\n",
      "Time taken for model training: 16.491902828216553\n"
     ]
    }
   ],
   "source": [
    "# manually choose the model with best hyperparameter\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "lstm_out = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.36))\n",
    "model.add(LSTM(lstm_out, dropout= 0.36, recurrent_dropout=0.36))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation='softmax'))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= optimizer, metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,  # 80% as training data\n",
    "      validation_split=0.1,\n",
    "      batch_size=64,\n",
    "      epochs=50, class_weight = class_weights)\n",
    "\n",
    "print(\"Time taken for model training: \" + str(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# plot for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# plot for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# save the model into a sav file\n",
    "\n",
    "filename = 'finalized_lstm_aspect.sav'\n",
    "joblib.dump(model, filename)\n",
    "\n",
    "loaded_model_aspect = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate using test data\n",
      "745/745 [==============================] - 0s 215us/step\n",
      "test loss, test acc: [0.8309584062371478, 0.6979866027832031]\n"
     ]
    }
   ],
   "source": [
    "print('\\n# Evaluate using test data')\n",
    "results = loaded_model_aspect.evaluate(x_test, y_test, batch_size=64)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "output = loaded_model_aspect.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "predicted_output = []\n",
    "\n",
    "# look at the probability of each class and convert them back into the predicted class category\n",
    "for ot in output:\n",
    "    a = ot.tolist()\n",
    "    predicted_output.append(a.index(max(a)))\n",
    "predicted_output = label_encoder.inverse_transform(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id\n",
       "2114    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2115               FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY\n",
       "2127                                         FOOD#QUALITY\n",
       "2130                                         FOOD#QUALITY\n",
       "2135    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2136                                         FOOD#QUALITY\n",
       "2138                                         FOOD#QUALITY\n",
       "2140                                         FOOD#QUALITY\n",
       "2141                                         FOOD#QUALITY\n",
       "2142                                         FOOD#QUALITY\n",
       "2144                                         FOOD#QUALITY\n",
       "2146                                         FOOD#QUALITY\n",
       "2148                                         FOOD#QUALITY\n",
       "2149                                         FOOD#QUALITY\n",
       "2151                                         FOOD#QUALITY\n",
       "2152                                      SERVICE#GENERAL\n",
       "2154                RESTAURANT#GENERAL,RESTAURANT#GENERAL\n",
       "2155                                      SERVICE#GENERAL\n",
       "2156                                      SERVICE#GENERAL\n",
       "2157                                         FOOD#QUALITY\n",
       "2158                                     AMBIENCE#GENERAL\n",
       "2159                                   RESTAURANT#GENERAL\n",
       "2160                                   RESTAURANT#GENERAL\n",
       "2161                                      SERVICE#GENERAL\n",
       "2163    AMBIENCE#GENERAL,AMBIENCE#GENERAL,AMBIENCE#GEN...\n",
       "2164                                      SERVICE#GENERAL\n",
       "2165    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2169    AMBIENCE#GENERAL,FOOD#QUALITY,FOOD#QUALITY,FOO...\n",
       "2170    AMBIENCE#GENERAL,FOOD#QUALITY,FOOD#QUALITY,FOO...\n",
       "2172                                      SERVICE#GENERAL\n",
       "                              ...                        \n",
       "2750    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2753    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2754    SERVICE#GENERAL,RESTAURANT#GENERAL,RESTAURANT#...\n",
       "2755    SERVICE#GENERAL,RESTAURANT#GENERAL,RESTAURANT#...\n",
       "2760                                      SERVICE#GENERAL\n",
       "2761                                   RESTAURANT#GENERAL\n",
       "2762    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2764                                         FOOD#QUALITY\n",
       "2765    SERVICE#GENERAL,SERVICE#GENERAL,SERVICE#GENERA...\n",
       "2766                                         FOOD#QUALITY\n",
       "2767                                         FOOD#QUALITY\n",
       "2771                                     AMBIENCE#GENERAL\n",
       "2772                                   RESTAURANT#GENERAL\n",
       "2773                                         FOOD#QUALITY\n",
       "2775                                         FOOD#QUALITY\n",
       "2777                                     AMBIENCE#GENERAL\n",
       "2779    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2781                                   RESTAURANT#GENERAL\n",
       "2782    FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY,FOOD#QU...\n",
       "2786               FOOD#QUALITY,FOOD#QUALITY,FOOD#QUALITY\n",
       "2787                                   RESTAURANT#GENERAL\n",
       "2788                                   RESTAURANT#GENERAL\n",
       "2789                                   RESTAURANT#GENERAL\n",
       "2790                                   RESTAURANT#GENERAL\n",
       "2798                                      SERVICE#GENERAL\n",
       "2800                                         FOOD#QUALITY\n",
       "2801                                         FOOD#QUALITY\n",
       "2802                                         FOOD#QUALITY\n",
       "2805                                         FOOD#QUALITY\n",
       "2807                                         FOOD#QUALITY\n",
       "Name: predicted_category, Length: 404, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put it into a dataframe, group those that belongs to same sentence (same review id) into one row\n",
    "\n",
    "df = pd.DataFrame({'review_id': id_test,\n",
    "     'predicted_category': predicted_output})\n",
    "predicted_category = df.groupby('review_id')['predicted_category'].apply(lambda x: ','.join(x))\n",
    "predicted_category  # this is in series format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both actual category and predicted category into two different csv files\n",
    "# will be used to the calculation of sentiment prediction accuracy in another notebook file\n",
    "\n",
    "actual_category.to_csv(\"actual_category.csv\")\n",
    "predicted_category.to_csv(\"predicted_category.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7599009900990099\n"
     ]
    }
   ],
   "source": [
    "# to see how many sentence got all the categories right\n",
    "\n",
    "no_of_sentence = predicted_category.size\n",
    "no_of_sentence_correct = 0\n",
    "\n",
    "# for each sentence\n",
    "for index, value in predicted_category.items():\n",
    "    match = True\n",
    "    \n",
    "    # all the predicted categories for each sentence\n",
    "    predicted_value = value.split(',')\n",
    "    \n",
    "    # all the actual ground truth categories for each sentence\n",
    "    actual_value = actual_category[actual_category['review_id'] == index]['category']\n",
    "    actual_value = actual_value.tolist()[0].split(',')\n",
    "    \n",
    "    # for each actual category\n",
    "    for elem in actual_value:\n",
    "        \n",
    "        # if not being predicted\n",
    "        if elem not in predicted_value:\n",
    "            match = False\n",
    "            break\n",
    "            \n",
    "    if match:\n",
    "        # if all actual categories are correctly predicted\n",
    "        no_of_sentence_correct += 1\n",
    "\n",
    "# print the accuracy value\n",
    "print(no_of_sentence_correct/no_of_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
